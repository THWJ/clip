---
title: Big Data Industry Predictions for 2023
date: 2023-08-01T06:46:29.000Z
updated: 2023-08-01T06:46:29.000Z
taxonomies:
  tags:
    - Tech
extra:
  source: https://insidebigdata.com/2022/12/14/big-data-industry-predictions-for-2023/
  hostname: insidebigdata.com
  author: Daniel Gutierrez
  original_title: Big Data Industry Predictions for 2023 - insideBIGDATA
  original_lang: en

---

![](BigData_shutterstock_1156276606.jpg)

_Welcome to insideBIGDATA’s annual technology predictions round-up! The big data industry has significant inertia moving into 2023. In order to give our valued readers a pulse on important new trends leading into next year, we here at insideBIGDATA heard from all our friends across the vendor ecosystem to get their insights, reflections and predictions for what may be coming. We were very encouraged to hear such exciting perspectives. Even if only half actually come true, Big Data in the next year is destined to be quite an exciting ride. Enjoy!  

欢迎来到insideBIGDATA的年度技术预测综述！大数据行业在进入2023年时具有显著的惯性。为了给予我们尊贵的读者了解明年的重要新趋势，我们在insideBIGDATA听取了供应商生态系统中所有朋友的意见，以获得他们对未来可能发生的事情的见解、思考和预测。听到这些令人兴奋的观点，我们感到非常鼓舞。即使只有一半真正实现，未来一年的大数据也注定会是一个令人兴奋的旅程。好好享受吧！_

**\[NOTE: please check back often as we’ll be adding new content to this feature article into February 2023\]  

\[NOTE：请经常回来查看，因为我们将在2023年2月为这篇专题文章添加新内容\]**

_Daniel D. Gutierrez –_ Editor-in-Chief & Resident Data Scientist  

丹尼尔·D Gutierrez -主编兼常驻数据科学家

**Analytics 数据分析**

Multi-Cloud Analytics. There are many reasons why a customer would choose to implement their architecture on multiple clouds whether it’s technology, market, or business-driven. When this happens, many times this leads to transactional and operational data being stored on multiple cloud platforms. The challenge this brings is how to gain insight into these without resorting to implementing multiple disparate data platforms. Historically data virtualization tools have been introduced to solve this style of problem, but it gets challenging when working across cloud environments. We are seeing increased emphasis from vendors on this message ([Google’s BigQuery Omni](https://cloud.google.com/bigquery/docs/omni-introduction) is one example) and expect customer adoption to pick up in order to quickly unlock value across data platforms without having to perform migrations. – Brian Suk, Associate CTO at [SADA](https://sada.com/)  

多云分析。客户选择在多云上实施其架构的原因有很多，无论是技术、市场还是业务驱动。当这种情况发生时，很多时候这会导致事务和运营数据存储在多个云平台上。这带来的挑战是如何深入了解这些数据，而无需实施多个不同的数据平台。历史上，数据虚拟化工具已经被引入来解决这种类型的问题，但当跨云环境工作时，它变得具有挑战性。我们看到供应商越来越重视这一消息（Google的BigQuery Omni就是一个例子），并希望客户采用率会提高，以便在无需执行迁移的情况下快速释放跨数据平台的价值。- Brian Suk，SADA副首席技术官

Augmentation of data quality, data preparation, metadata management and analytics. While the end result of many data management efforts is to feed advanced analytics and support AI and ML efforts, proper data management itself is pivotal to an organizations’ success. Data is often being called the new oil, because data- and analytics-based insights are constantly propelling business innovation. As organizations accelerate their usage of data, it’s critical for companies to keep a close eye on data governance, data quality and metadata management. Yet, with the growing amount of volume, variety, and velocity of data continues, these various aspects of data management have become too complex to manage at scale. Consider the amount of time data scientists and data engineers spend finding and preparing the data, before they can start utilizing it. That is why augmented data management has recently been embraced by various data management vendors where, with the application of AI, organizations are able to automate many data management tasks. According to some of the top analyst firms, each layer of a data fabric — namely data ingestion, data processing, data orchestration, data governance, etc. should have AI/ML baked into it, to automate each stage of the data management process. In 2023, augmented data management will find strong market traction, helping data management professionals focus on delivering data driven insights rather than being held back with routine administrative tasks. While these are the five most important trends in our mind, there are other areas of data and analytics practice which will shape up how digital business will not only survive but thrive in 2023 and beyond. The last two to three years have definitely taught us that digital business is not really a fall back option when the world cannot meet in person, but that is where the future lies. Hopefully your organization can gain some insights from these article as you lay out your digital business plan. – Angel Viña, CEO and founder of [Denodo](https://www.denodo.com/en)  

提高数据质量、数据准备、元数据管理和分析。虽然许多数据管理工作的最终结果是为高级分析提供支持并支持AI和ML工作，但适当的数据管理本身是组织成功的关键。数据通常被称为新的石油，因为基于数据和分析的洞察力正在不断推动业务创新。随着组织加速使用数据，公司密切关注数据治理、数据质量和元数据管理至关重要。然而，随着数据的数量、种类和速度的不断增长，数据管理的这些不同方面已经变得太复杂而无法大规模管理。考虑一下数据科学家和数据工程师在开始使用数据之前花费的时间。 这就是为什么增强数据管理最近被各种数据管理供应商所接受的原因，其中通过AI的应用，组织能够自动化许多数据管理任务。根据一些顶级分析公司的说法，数据结构的每一层--即数据摄取、数据处理、数据编排、数据治理等。应该将AI/ML融入其中，以自动化数据管理流程的每个阶段。到2023年，增强型数据管理将在市场上找到强大的吸引力，帮助数据管理专业人员专注于提供数据驱动的见解，而不是被常规的管理任务所束缚。虽然这些是我们心目中最重要的五个趋势，但数据和分析实践的其他领域将塑造数字业务在2023年及以后的生存和发展方式。 过去两三年的经验告诉我们，当世界无法面对面时，数字业务并不是真正的倒退选择，但这才是未来的所在。希望您的组织可以从这些文章中获得一些见解，因为您制定了数字业务计划。 - Angel Viña，Denodo首席执行官兼创始人

Not only will companies _rely_ on analytics to track their productivity, down-time, budget, and performance KPIs, but companies will also _solicit_ new areas to implement analytics for better tracking and precision. As the saying goes, you can’t manage what you can’t measure – and especially in today’s volatile economic climate (e.g. inflation, supply chain, geopolitical tensions), business leaders are increasingly keen to track as many facets of their business as possible so they can do more with less and become more adaptable. I’d predict that companies who already use analytics will be eager to use even more, and companies/industries that haven’t traditionally been as dependent on analytics will jump into the game. – Eddy Azad, CEO, [Parsec Automation](https://parsec-corp.com/)  

企业不仅依赖分析来跟踪其生产力、停机时间、预算和绩效KPI，而且还将寻求新的领域来实施分析，以实现更好的跟踪和精确度。常言道，你无法管理你无法衡量的东西--尤其是在当今动荡的经济环境下（例如：随着经济增长、通货膨胀、供应链、地缘政治紧张局势等因素的影响，企业领导者越来越热衷于跟踪业务的尽可能多的方面，以便他们能够以更少的资源做更多的事情，并变得更具适应性。我预测，已经使用分析的公司将渴望使用更多的分析，而传统上不依赖分析的公司/行业将加入游戏。- Eddy Azad，Parsec Automation首席执行官

Data analytics are increasingly being asked to drive greater data freedom in the multicloud: Data freedom is data’s ability to be accessed and to move, and therefore the freedom to deliver insights and the business value that comes from these insights. It means a frictionless flow—unobstructed by structural, economic, and other barriers. One way in which analytics can drive data freedom is via open data lake architectures that leverage open-source frameworks. – Vamsi Paladugu, Senior Director, Lyve Cloud Analytics at [Seagate Technology](https://www.seagate.com/)  

数据分析越来越多地被要求在多云中推动更大的数据自由：数据自由是指数据被访问和移动的能力，因此也是提供洞察力和这些洞察力所带来的业务价值的自由。这意味着无摩擦的流动不受结构性、经济和其他障碍的阻碍。分析可以推动数据自由的一种方式是通过利用开源框架的开放数据湖架构。- Vamsi Paladugu，Seagate Technology Lyve Cloud Analytics高级总监

More knowledge workers in non-data science roles will turn to advanced analytic techniques: Thirty years ago, a marketing professional didn’t need to know about the internet. Fast forward to today and it’s an integral part of just about any job, including marketing. Analytics is on a similar trajectory, and that will become even clearer in the coming year. We’ll see more companies enable knowledge workers throughout their business to garner impactful insights from their data. The combination of no-code/code-friendly cloud analytics solutions and increased investments in data literacy and upskilling will take data analytics out of the realm of specialty roles and into the entire organization. – Alan Jacobson, Chief Data & Analytic Officer at [Alteryx](https://www.alteryx.com/)  

更多非数据科学角色的知识工作者将转向高级分析技术：三十年前，营销专业人士不需要了解互联网。快进到今天，它是几乎任何工作的一个组成部分，包括营销。分析也处于类似的轨道上，这一点在未来一年将变得更加清晰。我们将看到更多的公司让知识型员工在整个业务中从他们的数据中获得有影响力的见解。无代码/代码友好的云分析解决方案与增加对数据素养和技能提升的投资相结合，将使数据分析走出专业角色的领域，进入整个组织。Alteryx首席数据分析官Alan Jacobson

Data Analysis Will Be Continuous: Data warehouses are becoming “always on” analytics environments. In the years ahead, the flow of data into and out of data warehouses will be not only faster, but continuous. Technology strategists have long sought to utilize real-time data for business decision-making, but architectural and system limitations have made that a challenge, if not impossible. Also, consumption-based pricing could make continuous data cost prohibitive. Increasingly, however, data warehouses and other infrastructure are offering new ways to stream data for real-time applications and use cases. Popular examples of real-time data in action include stock-ticker feeds, ATM transactions, and interactive games. Now, emerging use cases such as IoT sensor networks, robotic automation, and self-driving vehicles are generating ever more real-time data, which needs to be monitored, analyzed, and utilized. – Chris Gladwin, CEO and Co-founder of [Ocient](https://www.ocient.com/)  

数据分析将是连续的：数据仓库正在成为“始终在线”的分析环境。在未来几年中，数据流入和流出数据仓库的速度不仅会更快，而且会持续。长期以来，技术战略家一直在寻求利用实时数据进行业务决策，但架构和系统的限制使其成为一个挑战，如果不是不可能的话。此外，基于消费的定价可能会使连续数据成本过高。然而，数据仓库和其他基础设施正在为实时应用程序和用例提供新的数据流传输方式。实时数据的流行例子包括股票行情、ATM交易和互动游戏。现在，物联网传感器网络、机器人自动化和自动驾驶汽车等新兴用例正在生成越来越多的实时数据，这些数据需要被监控、分析和利用。- Chris Gladwin，Ocient首席执行官兼联合创始人

Google considers shedding Google Analytics: In the past few years, Google Analytics has been a thorn in the side of Google. Google Analytics continues to cause legal and privacy issues for Google and may eventually put Google’s advertising revenue (its “cash cow”) at risk. The marketplace has spoken and told Google that privacy is important and that website/app users don’t want to be tracked by Google. Add to this the fact that the latest version of Google Analytics (GA4) has been perceived by the marketplace as a flawed product. If Google Analytics continues to subject the larger Google to legal scrutiny and puts its advertising business at risk, there is a possibility (albeit a remote one) that Google spins off the GA unit so that it is no longer connected to Google. If that were to happen, Google Analytics would have a difficult time surviving since it likely loses money on an annual basis and is currently supported by the Google Ads business. – Adam Greco, product evangelist, [Amplitude](https://amplitude.com/)  

Google正在考虑放弃Google Analytics：在过去的几年里，Google Analytics一直是Google的眼中钉。Google Analytics继续给Google带来法律的和隐私问题，并可能最终危及Google的广告收入（其“摇钱树”）。该市场已经发言并告诉谷歌，隐私很重要，网站/应用程序用户不希望被谷歌跟踪。此外，最新版本的Google Analytics（GA 4）已被市场视为有缺陷的产品。如果Google Analytics继续让规模更大的Google接受法律的审查，并使其广告业务处于风险之中，那么Google就有可能剥离GA部门，使其不再与Google连接。如果发生这种情况，Google Analytics将很难生存下去，因为它可能每年亏损，并且目前由Google Ads业务支持。 - Adam Greco，Amplitude产品宣传员

Organizations will need to shift to confidential computing analytic platforms that do not compromise data security: The massive organizational need to protect data throughout its lifecycle will lead to the rapid adoption of confidential AI and analytics platforms that enable data analysts and machine learning practitioners to securely analyze data without ever having to expose it unencrypted during processing. The adoption will be driven by the rise of business use cases that mandate confidential analytics on sensitive data and the hefty costs associated with a data breach or failure to meet data privacy regulations and compliance policies. – Rishabh Poddar, CEO and Co-Founder of [Opaque Systems](https://opaque.co/)  

组织需要转向不影响数据安全的保密计算分析平台：组织在整个生命周期中保护数据的巨大需求将导致机密AI和分析平台的快速采用，使数据分析师和机器学习从业者能够安全地分析数据，而不必在处理过程中暴露未加密的数据。这种采用将受到要求对敏感数据进行保密分析的业务用例的兴起以及与数据泄露或未能满足数据隐私法规和合规政策相关的巨额成本的推动。- Rishabh Poddar，Opaque Systems首席执行官兼联合创始人

Data & Analytics ROI is Key Metric: Data and analytics continue to be the focus of IT transformation for many organizations, but as the market evolves–and in an environment of economic uncertainty–most will demand that their investments in analytics show a path to a clear return on investment in the near-term. Lessons learned during the pandemic and from the experiences of organizations that are already a good distance down the analytics road, show that producing faster, more accurate business intelligence is an attainable goal. That puts an emphasis on production rather than proof-of-concept, and ROI is a key metric for enterprises to consider before adopting any analytics platform or product. – [Kyligence](http://www.kyligence.io/)‘s CEO Luke Han  

数据和分析ROI是关键指标：数据和分析仍然是许多组织IT转型的重点，但随着市场的发展，以及在经济不确定的环境中，大多数组织将要求他们在分析方面的投资显示出一条在短期内获得明确的投资回报的路径。在疫情期间吸取的教训以及在分析道路上已经有很大距离的组织的经验表明，生成更快、更准确的商业智能是一个可以实现的目标。这强调了生产而不是概念验证，投资回报率是企业在采用任何分析平台或产品之前需要考虑的关键指标。- Kyigence首席执行官Luke Han

SaaS Free Forever is the New Open Source in 2023: When open-source software hit the data analytics scene, interest and adoption skyrocketed as organizations cited the benefits of cost effectiveness, speed and agility, community, and avoiding vendor lock in.  What most companies learned was that many projects required extensive set up, integration, and maintenance that slowed both innovation and migration to the cloud.  SaaS models will continue delivering on the promise and speed and agility, while reducing switching costs.  Emerging Free Forever SaaS models will further make these offerings cost effective and facilitate robust developer communities. – Nima Negahban, CEO and Cofounder, [Kinetica](http://www.kinetica.com/)  

SaaS Free Forever是2023年的新开源：当开源软件进入数据分析领域时，随着组织提到成本效益、速度和敏捷性、社区以及避免供应商锁定的好处，人们的兴趣和采用率飙升。大多数公司了解到，许多项目需要大量的设置、集成和维护，这减缓了创新和向云迁移的速度。SaaS模式将继续实现承诺、速度和敏捷性，同时降低转换成本。新兴的免费永远SaaS模式将进一步使这些产品具有成本效益，并促进强大的开发者社区。- Nima Negahban，Kinetica首席执行官兼联合创始人

Data and Analytics Will Knock Down Silos, Providing a Holistic Look at the Customer Journey: New contact center technologies are emerging that knock down silos and walls and offer an end-to-end look at the holistic customer journey. This will change the customer experience as we know it. For instance, in a traditional environment, an end-user customer may visit a company’s website, then call in to make a purchase or resolve an issue via an agent. Instead, in a modern contact center environment, the conversational AI agent will already know the end user has been on the company’s website and immediately present them with customized offers based on cookies that recreate their browsing journey. Data and analytics will evolve to create that holistic customer journey coupled with software that helps organizations shorten the time needed to serve their customer – all while being smarter about it. – [Waterfield](https://www.waterfieldtech.com/) CEO Steve Kezirian   

数据和分析将打破孤岛，全面审视客户之旅：新的联络中心技术正在涌现，这些技术打破了孤岛和壁垒，并提供了全面客户旅程的端到端视角。这将改变我们所知道的客户体验。例如，在传统环境中，最终用户客户可以访问公司的网站，然后打电话来进行购买或通过代理解决问题。相反，在现代联络中心环境中，对话式AI代理将已经知道最终用户已经在公司的网站上，并立即为他们提供基于cookie的定制优惠，以重现他们的浏览旅程。数据和分析将不断发展，以创建全面的客户旅程，并结合软件，帮助组织缩短为客户服务所需的时间-同时更明智地处理这一问题。- Waterfield首席执行官Steve Kezirian

2023 will see the shift from traditional business intelligence to modern business intelligence: The data analytics space is advancing with AI/ML, driving faster decision making and allowing companies to focus on their success through business intelligence. As the implementation of automation increases, business intelligence will be furthered as well. For example, to scale and democratize automation, robotic process automation will evolve into an as-a-service offering, allowing enterprises and small businesses alike to take advantage and automate business processes to move the business forward. – Ali Ahmed, GM, Enterprise Applications at [Cloud Software Group](https://www.cloud.com/)  

2023年将见证从传统商业智能向现代商业智能的转变：数据分析领域正在随着AI/ML的发展而进步，推动更快的决策制定，并允许公司通过商业智能专注于成功。随着自动化实施的增加，商业智能也将得到进一步发展。例如，为了扩展和民主化自动化，机器人流程自动化将演变为一种即服务产品，允许企业和小型企业利用并自动化业务流程以推动业务向前发展。- Ali Ahmed，云软件集团企业应用总经理

Teams use self-service analytics to revolt against the HiPPO: According to IDC research sponsored by Heap, 69% of digital product teams reported that decisions were often driven by the highest paid person in the room (HIPPO). Letting HIPPOs base critical decisions on instinct can lead to volatility in an organization, and with the state of the current economic market, it can be catastrophic. In 2023, more teams will revolt and use data to fight executive “gut” decisions. Utilizing self-service analytics tooling will become more readily available on the market to better drive investments and business results. The same IDC survey revealed that organizations that rely on data had a 2.5X increase in overall business outcomes. – Rachel Obstler, EVP of Product at Heap  

团队使用自助服务分析来反抗HiPPO：根据Heap赞助的IDC研究，69%的数字产品团队报告说，决策往往是由房间里薪酬最高的人（HIPPO）驱动的。让HIPPO基于本能做出关键决策可能会导致组织的波动，而在当前的经济市场状况下，这可能是灾难性的。到2023年，更多的团队将反抗，并使用数据来对抗高管的“直觉”决策。利用自助服务分析工具将在市场上变得更容易获得，以更好地推动投资和业务成果。IDC的同一项调查显示，依赖数据的组织的整体业务成果增长了2.5倍。- Rachel Obstler，Heap产品执行副总裁

Dashboards are Dead: Experienced business intelligence and data engineers have long been aware that dashboards–often counted as a business asset–tend to generate a great deal of technical debt that accrues over time, hampering performance. That’s because, for all the ease-of-use glitz and democratization acclaim, dashboards are just dirty tools for connecting data silos. With enterprises rushing to adopt public cloud applications and services, using business intelligence dashboards for managing processes and reviewing results will create more problems than they solve. But while BI dashboards die off, the metrics store concept will displace them as the preferred method for efficiently  managing data on one platform across the entire  enterprise. – [Kyligence](http://www.kyligence.io/)‘s CEO Luke Han  

仪表板已死：经验丰富的商业智能和数据工程师早就意识到，仪表板通常被视为一种商业资产，往往会产生大量的技术债务，随着时间的推移，影响性能。这是因为，对于所有易用的浮华和民主化的赞誉，仪表板只是连接数据孤岛的肮脏工具。随着企业急于采用公共云应用程序和服务，使用商业智能仪表板来管理流程和审查结果将产生比解决更多的问题。但是，虽然BI仪表板逐渐消失，但指标存储概念将取代它们，成为在整个企业的一个平台上高效管理数据的首选方法。- Kyigence首席执行官Luke Han

Tighter integration of managed cloud services and object storage will deliver better AI/ML and analytics performance: Application vendors will publish their own extended storage APIs for enhanced monitoring, reporting, performance acceleration and optimal data placement. This will be embraced by leading object storage solutions to deliver even more compelling solutions and ROI for enterprise and mid-market customers in data protection (backup and ransomware protection), big data analytics and AI/ML. In addition, because customers value cloud-like storage services but show a preference for them from the comfort of their own data center infrastructure, we will see increasing partnerships between object storage vendors and large OEMs or managed service providers (MSPs) to provide fully integrated, private-cloud S3 storage-as-a-service offerings. – Paul Speciale, CMO, [Scality](http://www.scality.com/)托管云服务和对象存储的更紧密集成将提供更好的AI/ML和分析性能：应用程序供应商将发布自己的扩展存储API，以增强监控、报告、性能加速和优化数据放置。这将被领先的对象存储解决方案所接受，为企业和中端市场客户提供更有吸引力的解决方案和投资回报率，包括数据保护（备份和勒索软件保护）、大数据分析和AI/ML。此外，由于客户重视云类存储服务，但出于对自己数据中心基础设施的舒适感，他们更倾向于使用这些服务，因此，我们将看到对象存储供应商与大型OEM或托管服务提供商（MSP）之间的合作日益加强，以提供完全集成的私有云S3存储即服务产品。- Paul Speciale，Scality首席营销官  

Companies should adopt real-time analytics in 2023: In 2023, companies should focus on making real-time analytics the center of all their activities.  We are in the Industrial Revolution 4.0 (4IR), a time when the boundaries between the physical, digital, and biological worlds are blurred, with data being a shared output of all three. Data in the 4IR is fast, accessible and immediate — it’s **modern data.** The difference in milliseconds drives customers from your organization to a competing one. Every industry needs to focus on becoming an “on-demand” service provider to meet rising customer expectations. As real-time becomes the mainstream expectation in 2023, businesses need to reevaluate their data strategies to include real-time applications that allow for scale and will enhance customer experiences. Data movement causes latency, which is why a unified database will prevail – a singleverse. Real-time will not only play an important role for businesses, but the world as a whole will benefit if transactions happen in real time across all functions, including banking, healthcare and cybersecurity. In order to be victorious in the new year, companies should reimagine their data strategies to meet the real-time demands of society. – Raj Verma, CEO, [SingleStore](https://www.singlestore.com/)企业应该在2023年采用实时分析：在2023年，企业应该专注于将实时分析作为其所有活动的中心。我们正处于工业革命4.0（4 IR），物理世界、数字世界和生物世界之间的界限变得模糊，数据是三者的共同输出。4 IR中的数据是快速、可访问和即时的-这是现代数据。以毫秒为单位的差异促使客户从您的组织转向竞争组织。每个行业都需要专注于成为“按需”服务提供商，以满足不断增长的客户期望。随着实时成为2023年的主流期望，企业需要重新评估其数据战略，以纳入允许规模并将增强客户体验的实时应用程序。数据移动会导致延迟，这就是为什么统一的数据库会占上风-一个单一的世界。 实时不仅对企业发挥重要作用，而且如果交易在银行、医疗保健和网络安全等所有功能上实时发生，整个世界都将受益。为了在新的一年中取得胜利，企业应该重新规划他们的数据战略，以满足社会的实时需求。 - Raj Verma，SingleStore首席执行官   

**Artificial Intelligence 人工智能**

AI model explainability stays hot. As AI becomes increasingly important in the lives of everyday people, more people want to know exactly how the models work. This is being driven by internal stakeholders, consumers, and regulators. – Anupam Datta, co-founder, president and chief scientist at [TruEra](https://truera.com/)AI模型的可解释性仍然很热。随着人工智能在日常生活中变得越来越重要，越来越多的人想要确切地知道模型是如何工作的。这是由内部利益相关者、消费者和监管机构推动的。- Anupam Datta，TruEra联合创始人、总裁兼首席科学家  

AIOps is placing more emphasis on cyber asset management for tagging and classification of assets – AIOps is on the rise as companies embrace automation to help with alert management and auto resolution of issues to maximize operational reliability and uptime. Along with this, we’re seeing a rise in advanced tagging and metadata management of assets to ensure AIOps algorithms can manage these assets effectively in automated processes. – Keith Neilson, Technical Evangelist at [CloudSphere](https://cloudsphere.com/)AIOps越来越重视网络资产管理，用于资产的标记和分类- AIOps正在上升，因为公司采用自动化来帮助警报管理和自动解决问题，以最大限度地提高运营可靠性和正常运行时间。与此沿着，我们看到资产的高级标记和元数据管理的兴起，以确保AIOps算法可以在自动化流程中有效地管理这些资产。- 基思Neilson，CloudSphere的技术布道者  

Formal regulation of AI use in the U.S.  U.S. regulatory agencies have been studying the challenges and impacts of AI, but have yet to make a significant move, unlike the European Commission.  I anticipate that to change in 2023, with the U.S. finally drafting its own rules at the federal level, similar to those already in effect in the EU and Asia. Guardrails are good for everyone in this market, and will ultimately help build trust in AI. U.S. regulations are not far off, and business should get ready. Anupam Datta, co-founder, president and chief scientist at [TruEra](https://truera.com/) 

We will see an AI Maturity divide, in which there will be AI Haves and Have Nots; the economic situation will exacerbate that. Modern data architecture will be the underpinning of that split. – Peak’s CEO Rich Potter  

我们将看到AI成熟度的划分，其中将有AI有和没有;经济形势将加剧这种情况。现代数据架构将是这种分裂的基础。- Peak首席执行官Rich Potter

AI Becomes Democratized. While AI has traditionally been seen as a complicated and challenging innovation, in 2023, artificial intelligence will be spread to a wider user base that includes those without specialized knowledge of AI. This change will put the power in the hands of customers, not just developers. Companies will seek self-service tools to create their own custom machine learning models that examine business-specific attributes. – Monish Darda, Co-Founder and Chief Technology Officer at [Icertis](https://www.icertis.com/)  

AI变得民主化。虽然人工智能传统上被视为一项复杂而具有挑战性的创新，但到2023年，人工智能将扩展到更广泛的用户群，包括那些没有人工智能专业知识的用户。这一变化将把权力交到客户手中，而不仅仅是开发商。公司将寻求自助服务工具来创建自己的定制机器学习模型，以检查特定于业务的属性。- Monish Darda，Icertis联合创始人兼首席技术官

Companies will address looming AI Regulations with Responsible AI. Governments in the EU and US plan to impose new regulation to protect consumers (i.e., the EU’s [liability rules on products and AI](https://ec.europa.eu/commission/presscorner/detail/en/ip_22_5807?tpcc=nleyeonai) and the White House’s [AI Bill of Rights](https://www.whitehouse.gov/ostp/ai-bill-of-rights/)). Surprisingly though, many organizations view AI regulation as a boon versus a barrier to success: Almost [two thirds](https://www.accenture.com/_acnmedia/PDF-179/Accenture-Responsible-by-Design-Report.pdf#zoom=40) (57%) of companies regard AI as a critical enabler of their strategic priorities. 2023 will see many organizations shifting from a reactive AI compliance strategy to a proactive development of Responsible AI capabilities – in order to build solid foundations for adapting to new regulations and guidance. – Accenture  

公司将通过负责任的AI解决迫在眉睫的AI法规。欧盟和美国政府计划实施新法规以保护消费者（即欧盟关于产品和人工智能的责任规则以及白宫的人工智能权利法案）。令人惊讶的是，许多组织认为人工智能监管是成功的布恩，而不是成功的障碍：近三分之二（57%）的公司将人工智能视为其战略优先事项的关键推动因素。2023年，许多组织将从被动式人工智能合规战略转向积极发展负责任的人工智能能力，以便为适应新法规和指导奠定坚实的基础。- 埃森哲

More debate about AI and bias. Is AI a friend or foe to fairness?  In 2021 and 2022, people were concerned that AI was causing bias, due to factors such as bad training data. In 2023, we’ll see a growing realization that AI can help eliminate bias by bypassing the historical points where bias came into play. People are often more biased than machines. We’re starting to see ways that AI can reduce bias rather than to introduce it. – Anupam Datta, co-founder, president and chief scientist at [TruEra](https://truera.com/)更多关于AI和偏见的讨论。AI是公平的朋友还是敌人？在2021年和2022年，人们担心人工智能会造成偏见，原因是训练数据不佳等因素。到2023年，我们将看到越来越多的人意识到，人工智能可以通过绕过偏见发挥作用的历史点来帮助消除偏见。人往往比机器更有偏见。我们开始看到人工智能可以减少偏见而不是引入偏见的方法。- Anupam Datta，TruEra联合创始人、总裁兼首席科学家  

Geopolitical shifts will slow AI adoption as fear and protectionism create barriers to data movement and processing locations. Macroeconomic instability, including rising energy costs and a looming recession, will hobble the advancement of AI initiatives as companies struggle just to keep the lights on. – Peak’s CEO Rich Potter  

地缘政治的变化将减缓人工智能的采用，因为恐惧和保护主义为数据移动和处理地点制造了障碍。宏观经济不稳定，包括能源成本上升和迫在眉睫的衰退，将阻碍人工智能计划的推进，因为公司努力保持灯亮着。- Peak首席执行官Rich Potter

Focus on ethical AI practices. In 2023, organizations will focus on eliminating bias from automated decision-making systems. The development of ethical and explanable AI models have been priorities for Icertis in recent years. Now, with the release of the blueprint for an [AI Bill of Rights](https://www.whitehouse.gov/ostp/ai-bill-of-rights/), the technology industry as a whole will work to eliminate unfairness in AI. The machine will never have all the data, which is why keeping the human in the loop is so important. – Monish Darda, Co-Founder and Chief Technology Officer at [Icertis](https://www.icertis.com/)  

专注于道德AI实践。到2023年，组织将专注于消除自动化决策系统的偏见。近年来，开发道德和可解释的AI模型一直是Icertis的优先事项。现在，随着人工智能权利法案蓝图的发布，整个技术行业将努力消除人工智能中的不公平。机器永远不会拥有所有的数据，这就是为什么让人参与循环是如此重要。- Monish Darda，Icertis联合创始人兼首席技术官

Augmented Data Management: Augmented data management will rise in importance as AI becomes more integrated with data quality, metadata management, and master data management. This means that manual data management tasks will be lessened thanks to ML and AI developments, which enable specialists to take care of more high-value tasks. – Founder and CEO of [Nexla](https://www.nexla.com/), Saket Saurabh  

增强数据管理：随着人工智能与数据质量、元数据管理和主数据管理更加集成，增强数据管理将变得越来越重要。这意味着人工数据管理任务将减少，这要归功于机器学习和人工智能的发展，使专家能够处理更多高价值的任务。- Nexla创始人兼首席执行官Saket Saurabh

The battle between AI speed & quality will come to a head: For as long as businesses have leveraged AI, executives have been focused on prioritizing one of two things: speed to deploy AI or quality of AI data. Technology, combined with human oversight to help spot areas of improvement along the way, will help merge speed and quality and help companies make their AI moonshot goals a reality in the coming year. – Sujatha Sagiraju, CPO at [Appen](https://appen.com/)  

AI速度和质量之间的战斗将达到顶点：只要企业利用人工智能，高管们就一直专注于优先考虑以下两件事情之一：AI部署速度或AI数据质量。技术与人工监督相结合，帮助发现一路沿着需要改进的领域，将有助于融合速度和质量，并帮助企业在未来一年实现他们的人工智能登月目标。- Sujatha Sagiraju，Appen首席执行官

AI will prove recession-proof. The demand for AI and other kinds of resource-intensive workloads and applications requiring specialized and high-performance computing platforms WON’T slow down because of economics, and, will in fact, increase. AI has become critical to almost every business, government agency, and organization on the planet. And its importance grows every day. But AI will add complexity to IT decisions – see Prediction 1 – and will compel CIOs to execute strategies that include a mix of cloud repatriation of AI apps and more complex multicloud, multiplatform distributed architectures. – Holland Barry, SVP and Field CTO, [Cyxtera](https://www.cyxtera.com/)

Businesses will have the ability to use AI within their organization to better suit their individual, specific business needs. One of the biggest trends that we’re going to see in the AI space in 2023 will be the shift from being an artisanal sport for data scientists and quant-jockey’s, to more of an industrialized, embedded type of construct where actual business users are able to start using and working with algorithms. It will no longer be strictly the domain of data scientists, and it is going to move away from the standard, laboratory type of black-box construct. We’re really going to start to see more industrialization within these programs. What we are going to see is, you have all of these models – the kind that you’ve done POCs on and have figured out the values – and now, you are putting it out into the field. It’ll be more focused on letting business users figure out how to use AI in a very non-prescriptive way. To put it in other terms, you’re sitting down and saying, “okay, here are the things that AI can do: predictive analytics, anomaly detection, etc,” but now you’re putting it into the hands of first-time users. By eliminating these data silos and putting AI directly into the organization, we can then enable information to be more democratized within the organization. This will also benefit from a low-code no-code type of environment where users can start configuring what data sets they want to work on and how they themselves can figure out and utilize this data to create predictions, fine-tune it, and make it work for them. – Bikram Singh, Founder and CEO at [EZOPS](https://www.ezops.com/)企业将有能力在其组织内使用人工智能，以更好地满足其个人的特定业务需求。2023年，我们将在人工智能领域看到的最大趋势之一将是从数据科学家和定量骑师的手工运动转变为更多的工业化嵌入式结构，实际的商业用户能够开始使用和使用算法。它将不再是严格意义上的数据科学家的领域，它将远离标准的实验室类型的黑盒结构。我们真的会在这些项目中看到更多的工业化。我们将要看到的是，你有了所有这些模型--你已经做了POC并计算出了值的那种--现在，你将把它应用到现场。它将更专注于让业务用户弄清楚如何以一种非常非规范的方式使用AI。 换句话说，你坐下来说，“好吧，以下是人工智能可以做的事情：预测分析、异常检测等，“但现在你把它交给了首次使用的用户。通过消除这些数据孤岛并将人工智能直接引入组织，我们可以使信息在组织内更加民主化。这也将受益于低代码无代码类型的环境，用户可以开始配置他们想要工作的数据集，以及他们自己如何计算和利用这些数据来创建预测，微调它，并使其为他们工作。 - Bikram Singh，EZOPS创始人兼首席执行官  

The AI industry will offer more tools that can be operated directly by business users. Companies have been hiring more and more data scientists and MLEs but net AI adoption in production has not increased at the same rate. While a lot of research and trials are being executed, companies are not benefiting from production AI solutions that can be scaled and managed easily as the business climate evolves. In the coming year, AI will start to become more democratized such that less technical people can directly leverage tools that abstract _all_ the machine learning complexity. Knowledge workers and citizen “data scientists” without formal training in advanced statistics and/or mathematics will be extracting high-value insights from data using these self-service tools allowing them to perform advanced analytics and solve specific business problems at the speed of the business. – Ryan Welsh, Founder and CEO of [Kyndi](https://www.kyndi.com/)  

AI行业将提供更多可以由企业用户直接操作的工具。公司一直在雇佣越来越多的数据科学家和MLE，但生产中的人工智能净采用率并没有以同样的速度增长。虽然正在进行大量的研究和试验，但公司并没有从生产AI解决方案中受益，这些解决方案可以随着商业环境的发展而轻松扩展和管理。在未来的一年里，人工智能将开始变得更加民主化，技术含量不高的人可以直接利用抽象所有机器学习复杂性的工具。没有受过高级统计学和/或数学正规培训的知识工作者和公民“数据科学家”将使用这些自助服务工具从数据中提取高价值见解，使他们能够执行高级分析并以业务速度解决特定业务问题。- Ryan Welsh，Kyndi创始人兼首席执行官

AI is advancing rapidly. Look no further than Google Translate’s evolution over the past five years for proof of that. And as data significantly increases, creating new AI and ML opportunities, early AI investors will soon establish a clear lead in their respective industries. Companies that cannot prove themselves quickly and establish a market position will fall behind, leaving a group of clear winners capable of delivering top-tier solutions. – [TealBook](https://www.tealbook.com/) Chief Technology Officer Arnold Liwanag  

AI正在快速发展。谷歌翻译在过去五年中的发展就可以证明这一点。随着数据的显著增加，创造了新的人工智能和机器学习机会，早期的人工智能投资者将很快在各自的行业中建立明显的领先地位。不能迅速证明自己并建立市场地位的公司将落后，留下一批能够提供顶级解决方案的明确赢家。- TealBook首席技术官Arnold Liwanag

Ethical AI becomes paramount as commercial adoption of AI-based decision making increases. Companies across industries are accelerating the usage of AI for their data-based decision making. Whether it’s about social media platforms suppressing posts, connecting healthcare professionals with patients, or large wealth management banks granting credits to their end consumers; However, when artificial intelligence decides the end result, currently there is no way to suppress the inherent bias in the algorithm. That is why emerging regulations such as the proposed EU Artificial Intelligence Act, and Canada’s Bill C-27 (which may become the Artificial Intelligence and Data Act if enacted) are starting to put a regulatory framework around the use of AI in commercial organizations. These new regulations classify the risk of AI applications as unacceptable, high, medium, or low risk and prohibit or manage the use of  these applications accordingly. In 2023, Organizations will need to be able to comply with these proposed regulations, including ensuring privacy and data governance, algorithmic transparency, fairness and non-discrimination, accountability, and auditability. With this in mind, organizations have to implement their own frameworks to support ethical AI e.g. guidelines for trustworthy AI, peer review frameworks, and AI Ethics committees. As more and more companies put AI to work, ethical AI is bound to become more important than ever in the coming year. – Angel Viña, CEO and founder of [Denodo](https://www.denodo.com/en)  

随着基于人工智能的决策在商业上采用的增加，道德人工智能变得至关重要。各行各业的公司都在加速使用人工智能进行基于数据的决策。无论是社交媒体平台压制帖子、连接医疗保健专业人士与患者，还是大型理财银行向其终端消费者发放信贷;然而，当人工智能决定最终结果时，目前还没有办法抑制算法中固有的偏差。这就是为什么拟议的欧盟人工智能法案和加拿大的C-27法案（如果颁布，可能会成为人工智能和数据法案）等新兴法规开始围绕商业组织中人工智能的使用制定监管框架。这些新法规将人工智能应用的风险分为不可接受、高、中或低风险，并相应地禁止或管理这些应用的使用。 到2023年，组织将需要能够遵守这些拟议的法规，包括确保隐私和数据治理、算法透明度、公平性和非歧视性、问责制和可审计性。考虑到这一点，组织必须实施自己的框架来支持道德AI，例如。值得信赖的人工智能、同行评审框架和人工智能伦理委员会的指南。随着越来越多的公司将人工智能投入工作，道德人工智能必将在未来一年变得比以往任何时候都更加重要。 - Angel Viña，Denodo首席执行官兼创始人

2023 Will Be The Year of Embedded Innovation: Embedded innovation is key for digital transformation. If businesses are siloed, they’ll never achieve the goals they set for themselves. For most organizations, AI is currently an IT project not integrated into the business processes. With embedded systems, you also need the right data and machine learning algorithms to drive the AI to make the right decisions. As companies increase the value of the data in their ERP/ERM solutions and couple it with other external sources (i.e. weather patterns) you start to build a better pool of data that will drive better decision making. The best sources for this data come directly from the production floor, from the bottom up. What we’re seeing the start of is increasingly more accessibility to public-sourced data, which allows businesses to have a wider scope of information on things affecting their suppliers or customers that they can then use to inform their own business decisions. In the future, companies will be able to calculate the probability of a disruption in their supply chain or build a better profile for marketing campaigns based on this data. It extends the value of traditional ERP in decision making past what is currently in use. – Kevin Miller, Interim CTO, [IFS](http://www.ifs.com/) 

Powers of AI & ML to Improve Workflows & Alleviate Resource Constraints. At a time when organizations face constant waves of sophisticated threats across multiple vectors, cloud security will increasingly harness AI and ML capabilities to not only alleviate skills shortages and resourcing challenges, but also automate powerful workflows to help enterprises stay ahead of attackers. – Rodman Ramezanian, the Global Cloud Threat Lead at Skyhigh Security

Adversarial learning – CIOs need to understand this technique: bad actors training neural networks to fool predictive algorithms. For example, adversarial algorithms have been used to dupe cars into driving through lanes and render a stop sign invisible to classification algorithms. The same technique is applied to image and audio samples to trick prediction algorithms. – John McClurg, Sr. Vice President and CISO at BlackBerry  

对抗学习-CIO需要了解这种技术：坏人训练神经网络来欺骗预测算法。例如，对抗算法已经被用来欺骗汽车通过车道并使停车标志对分类算法不可见。将相同的技术应用于图像和音频样本以进行特技预测算法。- John McClurg，Sr.黑莓副总裁兼首席信息官

In an increasingly data-centric world, edge computing will fuel the evolution of reliable AI: AI is ubiquitous in our everyday lives. It suggests what to buy and the news we read. It could determine the emails we receive and augment the cars we drive. Moving forward, AI will be even more embedded in our world. It’ll go through a maturation phase that enables us to rely on it more. Predictability and explainability of AI will improve dramatically as we move forward. Moreover, AI will evolve from being algorithm driven to being more data driven. In order for this to be effective, more and more computation will happen at the edge for AI to be reliable, responsive and cost-effective. This trend of more data influencing the algorithms will determine how AI will evolve to be a tool that is relied upon heavily in this data centric future. – Ravi Mayuram, CTO, [Couchbase](https://www.couchbase.com/)  

在一个日益以数据为中心的世界中，边缘计算将推动可靠AI的发展：AI在我们的日常生活中无处不在。它建议买什么和我们读的新闻。它可以确定我们收到的电子邮件，并增加我们驾驶的汽车。展望未来，AI将更多地嵌入我们的世界。它将经历一个成熟阶段，使我们能够更多地依赖它。随着我们的前进，人工智能的可预测性和可解释性将大大提高。此外，人工智能将从算法驱动演变为更多的数据驱动。为了使这一点有效，越来越多的计算将发生在AI的边缘，以使AI变得可靠、响应迅速和具有成本效益。更多数据影响算法的趋势将决定人工智能将如何演变为在这个以数据为中心的未来中受到严重依赖的工具。- Ravi Mayuram，Couchbase首席技术官

The Battle Between Speed and Quality Will Come To a Head: For as long as businesses have leveraged AI, executives have been focused on prioritizing one of two things: speed to deploy AI or quality of AI data.These two have not been mutually exclusive things in the past, which has led to fundamental problems in how companies build, scale, deploy, and maintain their AI systems. In the future, however, companies should no longer find themselves in a position where they are sacrificing speed for quality or vice versa. To avoid this problem, we will see companies continue to deploy solutions that help them both source quality data and scale AI systems more efficiently and effectively than ever before. Technology, combined with human oversight to help spot areas of improvement along the way, will help merge speed and quality and help companies make their AI moonshot goals a reality in the coming year. – Sujatha Sagiraju, CPO, [Appen](https://appen.com/)  

速度与质量的战斗即将到来：只要企业利用人工智能，高管们就一直专注于优先考虑以下两件事情之一：部署AI的速度或AI数据的质量。这两者在过去并不相互排斥，这导致了企业如何构建、扩展、部署和维护AI系统的根本问题。然而，在未来，公司不应该再发现自己处于牺牲速度以换取质量的境地，反之亦然。为了避免这个问题，我们将看到公司继续部署解决方案，帮助他们获得高质量的数据，并比以往任何时候都更有效地扩展AI系统。技术与人工监督相结合，帮助发现一路沿着需要改进的领域，将有助于融合速度和质量，并帮助企业在未来一年实现他们的人工智能登月目标。- Sujatha Sagiraju，首席执行官，Appen

AI moves deeper into the pipeline: As concerns about a recession and economic uncertainty rise, many will see a pull back on investment and hiring. However, with the global skills shortage continuing to impact companies of all sizes, ensuring technologies such as Artificial Intelligence (AI) and Machine Learning (ML) are able to automate some of the more menial data preparation tasks will be crucial. By moving AI deeper into the data pipeline before an application or dashboard has even been built, we can finally start to shift the breakdown of time spent on data preparation versus data analytics. Right now, [less than 20% of time is spent analyzing data, while just over 80% of the time is spent collectively on searching for, preparing, and governing the appropriate data](https://blogs.idc.com/2018/08/23/time-crunch-equalizing-time-spent-on-data-management-vs-analytics/). Doing this would enable hard-to-come-by data talent to focus on the value-add; cross-pollinating and generating new insights that weren’t possible before. A far more productive use of their time. That’s why Gartner estimates that by 2024 manual data integration tasks will be reduced by up to 50%, and why this is set to be a key trend for 2023. – Dan Sommer, former Gartner analyst and Qlik’s Global Market Intelligence Lead  

AI更深入地进入管道：随着对经济衰退和经济不确定性的担忧加剧，许多人将看到投资和招聘的回落。然而，随着全球技能短缺继续影响各种规模的公司，确保人工智能（AI）和机器学习（ML）等技术能够自动化一些较为卑微的数据准备任务将至关重要。通过在构建应用程序或仪表板之前将人工智能更深入地推进数据管道，我们最终可以开始将数据准备和数据分析所花费的时间分解转移到数据分析上。目前，不到20%的时间用于分析数据，而超过80%的时间用于搜索、准备和管理适当的数据。这样做可以让来之不易的数据人才专注于增值;交叉授粉并产生以前不可能的新见解。更有效地利用时间。 这就是为什么Gartner预计，到2024年，手动数据集成任务将减少多达50%，以及为什么这将成为2023年的一个关键趋势。 - Dan Sommer，前Gartner分析师和Qlik全球市场情报主管

Defining Hybrid AI in 2023: 2023 will be the year we define what hybrid AI really is. Hype for hybrid AI has grown exponentially, but there’s been some debate over what it is. Some say it’s a physical simulator tied to machine learning; some say it uses a hybrid cloud — as of late, no clear definition has emerged. In the new year, the industry will reach a consensus, and once it does, an explosion of new tools will emerge as organizations take action. – Michael Krause, the AI Solutions Director at [Beyond Limits](https://www.beyond.ai/)2023年定义混合AI：2023年将是我们定义混合AI真正是什么的一年。对混合AI的炒作呈指数级增长，但关于它是什么存在一些争论。有人说这是一个与机器学习绑定的物理模拟器;有人说它使用混合云--到最近为止，还没有明确的定义。在新的一年里，行业将达成共识，一旦达成共识，随着组织采取行动，新工具将出现爆炸式增长。Michael Krause，Beyond Limits的AI解决方案总监  

AI-Powered decision-making will take data analysis to the next level, but the technology is still nascent: AI (artificial intelligence) and ML (machine learning) models have been crucial in highlighting underlying correlations in data which is not obvious to human interpretation usually. In the next two to three years, these models will further evolve to suggest corrective action based on the analysis. Actionable insights will be accompanied by recommendations towards possible actions. Such recommendation engines will be highly vertical-specific and use case-specific to begin with before becoming vertical agnostic. Take IT workload and SLA balance for instance. AI-powered analytical engines will be able to provide insights on why you’re unable to improve SLAs by taking into account in several factors such as how are your SLAs as compared to industry trends, what is your ticket-to-technicians ratio, how the total workload is split among your technicians, who are your busiest technicians, who are the ones who struggle to hit SLAs, and how has cost-cutting measures impacted your SLAs. The suggestions can range from ideas to reshuffle workload to adding more technicians or upskilling technicians. This is an example of vertical-specific suggestion. This can help senior management (CIOs or CTOs), who may not be experts with analytics tools, gain actionable insights that can put them on the fast track to implementing solutions instead of hunting for answers within data. – Rakesh Jayaprakash, Head of Product Management at ManageEngine  

人工智能决策将把数据分析提升到一个新的水平，但这项技术仍处于萌芽状态：AI（人工智能）和ML（机器学习）模型在突出数据中的潜在相关性方面至关重要，这些相关性通常对人类解释并不明显。在未来两到三年内，这些模型将进一步发展，以根据分析提出纠正措施。可采取行动的见解将伴随着对可能采取的行动的建议。这样的推荐引擎将是高度垂直特定的，并且在变得垂直不可知之前开始是特定于用例的。以IT工作负载和SLA平衡为例。 人工智能驱动的分析引擎将能够通过考虑几个因素来提供关于为什么您无法改善SLA的见解，例如与行业趋势相比，您的SLA如何，您的票据与技术人员的比率是多少，总工作量如何在您的技术人员之间分配，谁是您最繁忙的技术人员，谁是难以达到SLA的人，以及成本削减措施如何影响您的SLA。这些建议可以从想法到重新安排工作量，再到增加更多的技术人员或提高技术人员的技能。这是垂直特定建议的示例。这可以帮助高级管理人员（首席信息官或首席技术官），他们可能不是分析工具的专家，获得可操作的见解，可以让他们快速实施解决方案，而不是在数据中寻找答案。 - ManageEngine产品管理主管Rakesh Jayaprakash

AI ethics will be a key consideration for DevOps leaders: Organizations that leverage AI have gotten caught up in the benefits it provides while ignoring the implicit bias that naturally infiltrates data sets. With brands being held to higher customer standards and governance pressure than ever before, it is imperative to consider AI and data ethics from the start. This approach will require an increased level of human and machine-based collaboration, ultimately resulting in an ethics-based approach to driving business outcomes with unbiased data at the forefront, satisfying a wide variety of stakeholders. – Vamsi Paladugu, Senior Director, Lyve Cloud Analytics at [Seagate Technology](https://www.seagate.com/) 

ERP Systems Need to be “AI-ified”: While ERP systems are strategic for entering, storing, and tracking data related to various business transactions, CIOs, COOs, and business analysis teams have struggled over decades to extract, transform, and load data from ERP systems and utilize it for AI/ML applications. As enterprises spearhead digital transformation journeys and look to implement AI, the demand to connect to enterprise data across the organization has never been more paramount. In 2023, the market is starting to support the concept of AI micro-products or toolkits that can be used to connect to ERP systems through middleware. These middleware toolkits must have the ability to link to data both within the organizations from the ERP systems as well as CRM or HR platforms and external data (such as news or social media). The middleware can then feed into the leading AI platform to develop, select, and deploy ML models to provide highly accurate predictions and forecasting. – Anand Mahukar, CEO, Findability  

ERP系统需要“AI化”：虽然ERP系统对于输入、存储和跟踪与各种业务交易相关的数据具有战略意义，但CIO、COO和业务分析团队几十年来一直在努力从ERP系统中提取、转换和加载数据，并将其用于AI/ML应用程序。随着企业引领数字化转型之旅并寻求实施人工智能，连接整个组织的企业数据的需求从未如此重要。2023年，市场开始支持AI微产品或工具包的概念，这些产品可用于通过中间件连接ERP系统。这些中间件工具包必须能够链接到企业内部的ERP系统以及CRM或HR平台和外部数据（如新闻或社交媒体）的数据。然后，中间件可以输入领先的AI平台，以开发、选择和部署ML模型，以提供高度准确的预测和预测。 - Anand Mahukar，Findability首席执行官

Bias is Overhyped: Bias is a concept that gets a lot of attention– and will continue to get more with the AI Bill of Rights– it’s not something that many ML practitioners are concerned with day-to-day. Of course, they account for it, but sound ML practitioners understand the issues and know what to do to prevent bias from adversely affecting outcomes. – Gideon Mendels, CEO and co-founder of MLOps platform [Comet](http://comet.ml/)  

偏见被夸大了：偏见是一个得到很多关注的概念-并且将继续随着AI权利法案得到更多关注-它不是许多ML从业者日常关注的事情。当然，他们解释了这一点，但健全的ML从业者理解这些问题，并知道如何防止偏见对结果产生不利影响。- Gideon Mendels，MLOps平台Comet首席执行官兼联合创始人

IT teams will prioritize AI/ML applications that automate tasks to save cost and human effort: With high labor costs and a recession looming, AI/ML solutions that solve practical use cases will take priority in 2023. IT organizations will look to build or purchase autonomous solutions that bring them cost savings, provide operational efficiency, and reduce or eliminate human effort. – Preethi Srinivasan, Director of Innovation at Druva  

IT团队将优先考虑自动化任务的AI/ML应用程序，以保存成本和人力：随着劳动力成本高企和经济衰退的临近，解决实际用例的AI/ML解决方案将在2023年成为优先事项。IT组织将寻求构建或购买自主解决方案，以节省成本，提高运营效率，并减少或消除人力。- Preethi Srinivasan，Druva创新总监

Organizations have rapidly and successfully adopted AI for wide-ranging use cases in recent years, but a majority of AI today can be described as ‘narrow’ – it replicates human actions for highly specific purposes, such as answering common customer questions, and exists mostly in siloes. As more and more organizations introduce AI and automation throughout the enterprise, they will move away from deploying disparate applications and begin building connected ecosystems with AI at their core. This enables organizations to take data from throughout the enterprise to strengthen machine learning models across applications, effectively creating learning systems that continually improve outcomes. AI becomes a business multiplier, rather than simply an optimizer. – Vinod Bidarkoppa, Chief Technology Officer, Sam’s Club and Senior Vice President, Walmart  

近年来，企业已经迅速成功地将人工智能应用于广泛的用例，但今天的大多数人工智能可以被描述为“狭隘”-它复制人类行为，用于高度特定的目的，例如回答常见的客户问题，并且大多存在于孤岛中。随着越来越多的组织在整个企业中引入人工智能和自动化，他们将不再部署不同的应用程序，而是开始构建以人工智能为核心的互联生态系统。这使组织能够从整个企业中获取数据，以加强跨应用程序的机器学习模型，有效地创建持续改进结果的学习系统。人工智能将成为业务倍增器，而不仅仅是优化器。- Vinod Bidarkoppa，山姆会员俱乐部首席技术官兼沃尔玛高级副总裁

AI goes ROI: The slowdown in tech spending will show up in AI and machine learning in two ways: major new AI methodologies and breakthroughs will slow down, while innovation in AI moves toward “productization.” We’ll see AI get faster and cheaper as the innovation moves into techniques to make deep learning less expensive to apply and faster through models like DistilBERT, where accuracy goes down a bit, but the need for GPU’s is reduced. – Jeff Catlin, Head of [Lexalytics](https://www.lexalytics.com/), an InMoment Company  

AI Goes ROI：科技支出的放缓将以两种方式体现在人工智能和机器学习方面：主要的人工智能新方法和突破将放缓，而人工智能的创新将走向“产品化”。我们将看到人工智能变得更快，更便宜，因为创新进入技术，使深度学习的应用成本更低，并通过DistilBERT等模型更快，准确度下降了一点，但对GPU的需求减少了。- Jeff Catlin，Lexalytics负责人，InMoment公司

State, local, federal governments will focus on skill-building for AI adoption, aided by new federal funding: Government investment in AI at all levels will increase AI integration and job creation. Agencies with limited technical skills will deploy AI-as-a-Service so municipalities can better support the public. While US AI infrastructure remains competitive against peer and near-peer states, the country is currently lagging behind AI powerhouses like China in qualified STEM professionals, (source: Brookings Institution). – Rodrigo Liang, Co-Founder and CEO of [SambaNova](https://sambanova.ai/)  

州，地方和联邦政府将专注于人工智能采用的技能建设，并得到新的联邦资金的帮助：各级政府对人工智能的投资将促进人工智能的整合和创造就业机会。技术能力有限的机构将部署人工智能即服务，以便市政当局能够更好地支持公众。虽然美国的人工智能基础设施与同行和接近同行的国家相比仍然具有竞争力，但该国目前在合格的STEM专业人员方面落后于像中国这样的人工智能强国。布鲁金斯学会）。- Rodrigo Liang，SambaNova联合创始人兼首席执行官

After years of growth in AI adoption, the technology has now hit an inflection point where AI is no longer just for enterprises with the most advanced technology stacks. Today, more and more mainstream businesses are seeing the value AI can bring to help solve their most critical problems and are embracing AI, and I expect to see more and more AI on “Main Street” in the coming year. As these organizations adopt AI, I expect them to start using more pre-trained models and fine-tune the model with additional data as they go rather than starting to build models from scratch, since there are more pre-trained AI models available in the market than ever before. I also expect to see these companies opting for open data ecosystems versus proprietary data stacks so that as they continue on their AI journeys they have the flexibility to innovate and scale faster. – June Yang, Vice President, Cloud AI and Industry Solutions, Google Cloud  

经过多年的人工智能采用率增长，该技术现在已经达到了一个拐点，人工智能不再仅仅适用于拥有最先进技术堆栈的企业。如今，越来越多的主流企业看到了AI可以带来的价值，帮助他们解决最关键的问题，并正在拥抱AI，我预计在未来一年，“大街上”会有越来越多的AI出现。随着这些组织采用人工智能，我希望他们开始使用更多的预训练模型，并在使用额外数据时微调模型，而不是从头开始构建模型，因为市场上的预训练人工智能模型比以往任何时候都多。我还希望看到这些公司选择开放的数据生态系统而不是专有的数据堆栈，以便在他们继续进行人工智能之旅时，他们能够灵活地进行创新和更快地扩展。- June Yang，Google Cloud云AI和行业解决方案副总裁

AI on the Offense: Deepfake technology to date has resulted in political confusion, internet chatter, and some amusing mashup videos, but expect this to change in the near term. Security experts have warned for years about the possibility of social engineering attacks with deepfakes, and the technology has matured enough for 2023 to see hackers successfully leverage it. We will see an increase in image generation, generated audio, and conversations that appear realistic, designed to trick recipients into sharing personal data or other sensitive information. The deepfake threat isn’t relegated solely to consumers; we’ll likely see threat actors spoof a Fortune 100 CEO in an attempt to defraud or otherwise damage the organization. – Scott Register, VP Security Solutions at [Keysight Technologies](http://keysight.com/)

AI Will Supplement Virtual Sales Training to Create Top Performers: The applications for AI in sales have only begun to scratch the surface. In the coming years, we’ll see new use cases—starting with virtual training and coaching. Of the 75% of organizations that provided practice opportunities during the pandemic, 90% found effectiveness in doing so. Coaching is in demand, but few sales managers have time for it with large, dispersed teams. As a solution, more sales teams will use AI-powered virtual actors to simulate live conversations for practice and feedback in 2023. As AI becomes more sophisticated, companies that use this tech to stay on the cutting edge will attract, train and retain top sales reps. – from Andre Black, Chief Product Officer of [Allego](https://www.allego.com/)

In 2023, many companies will seek Artificial Intelligence-powered (AI) solutions that modernize their business processes, and improve productivity and employee morale while growing the bottom line. I believe that, as AI applications become more widespread, the common misunderstanding that ‘AI takes jobs from people’ will dissipate. Over time, the understanding that technologies denoted as AI help employees focus on more strategic tasks will grow. In my opinion, the widening of AI applications mirrors other historical inventions that were originally suspected to “take jobs”. Let us draw an analogy with the steam engine – this advancement did not prove disastrous for workers. It reduced their workloads and enabled them to do more. Advances in Machine Learning (ML), like Intelligent Document Processing (IDP) that handles all data entry and processing from a cloud-based platform, is one of the technological advancements happening today. Manual data entry is the _modern equivalent_ of physical tasks in the workplace, and ML is here to help. – Milan Šulc, Head of AI Lab at [Rossum](https://rossum.ai/)

Implementing AI & Data for better digital adoption products & solutions: Artificial intelligence and machine learning will grow as crucial tools of a successful digital adoption platform. They will help focus and improve the customer experience by greater organization of the learning journey. This will be done by enabling more data-driven processes, which will highlight and predict what customers will use on the platform, and what needs to be improved. – Uzi Dvir, Global CIO at [WalkMe](http://www.walkme.com/)

Foundation models are AI’s next frontier: We’ve seen recent and rapid growth of generative AI models and expect that they will change business operations across a variety of industries in 2023. Foundation models are enabling many of these breakthrough AI capabilities that are delivering value that was not previously possible. Given the economic climate we’re in, we foresee the government and the most forward-looking organizations (banks, research organizations, oil and gas companies) leveraging AI to drive ROI and cost savings in text-heavy workflows like fraud and compliance, customer service, and operational efficiency. – Rodrigo Liang, Co-Founder and CEO of [SambaNova](https://sambanova.ai/)基础模型是人工智能的下一个前沿：我们已经看到生成人工智能模型最近的快速增长，并预计它们将在2023年改变各个行业的业务运营。基础模型正在实现许多这些突破性的人工智能能力，这些能力正在提供以前不可能的价值。考虑到我们所处的经济环境，我们预计政府和最具前瞻性的组织（银行、研究机构、石油和天然气公司）将利用人工智能来推动文本繁重的工作流程（如欺诈和合规、客户服务和运营效率）中的ROI和成本节约。- Rodrigo Liang，SambaNova联合创始人兼首席执行官  

Investment in data will continue to open organizations to new possibilities and drive transformation in decision-making. Data compliance, security, and mobilization will continue to be principal drivers of new investment in 2023, with data becoming more central to _mission-critical_ operations. Businesses’ most significant challenge remains staying competitive in an increasingly complicated world. Successful adopters will find solutions that uplift existing tech stacks and staff with solutions tailored specifically to their industry or vertical instead of trying to squeeze onto platforms not designed for them. AI should target opportunities for new business growth and is not a one size fits all. – Sasha Grujicic, Chief Operating Officer, [NowVertical Group Inc](http://www.nowvertical.com/)  

数据投资将继续为组织打开新的可能性，并推动决策转型。数据合规性、安全性和移动性将继续成为2023年新投资的主要驱动力，数据对关键任务运营变得更加重要。企业面临的最大挑战仍然是在日益复杂的世界中保持竞争力。成功的采用者将找到能够提升现有技术堆栈和员工的解决方案，这些解决方案专门针对他们的行业或垂直领域定制，而不是试图挤进不为他们设计的平台。人工智能应该瞄准新业务增长的机会，而不是一刀切。- Sasha Grujicic，NowVertical Group Inc.首席运营官

More debate about AI and bias: Is AI a friend or foe to fairness?  In 2021 and 2022, people were concerned that AI was causing bias, due to factors such as bad training data. In 2023, we’ll see a growing realization that AI can help eliminate bias by bypassing the historical points where bias came into play. People are often more biased than machines. We’re starting to see ways that AI can reduce bias rather than to introduce it. – Anupam Datta, co-founder, president and chief scientist at [TruEra](https://truera.com/)  

更多关于AI和偏见的讨论：AI是公平的朋友还是敌人？在2021年和2022年，人们担心人工智能会造成偏见，原因是训练数据不佳等因素。到2023年，我们将看到越来越多的人意识到，人工智能可以通过绕过偏见发挥作用的历史点来帮助消除偏见。人往往比机器更有偏见。我们开始看到人工智能可以减少偏见而不是引入偏见的方法。- Anupam Datta，TruEra联合创始人、总裁兼首席科学家

Organizations Will Prioritize AI/ML Expertise, but Finding IT Talent Won’t be Easy: To truly take advantage of AI is a long journey; one that will continue to be bottlenecked by a lack of IT talent. Organizations need data scientists, people who are technically capable and cognizant of AI/ML technologies, however labor market shortages have caused them to pull back on growth plans. While layoffs may continue in 2023, organizations will hold onto the technologists working in areas of AI/ML that have the ability to provide far-reaching benefits in the future. – Amy Fowler, VP of FlashBlade Strategy and Operations, Pure Storage  

组织将优先考虑AI/ML专业知识，但寻找IT人才并不容易：要真正利用AI是一个漫长的旅程;这将继续受到IT人才缺乏的瓶颈。组织需要数据科学家，这些人有技术能力并了解AI/ML技术，但劳动力市场短缺导致他们撤回了增长计划。虽然裁员可能会在2023年继续，但组织将保留在AI/ML领域工作的技术人员，这些领域有能力在未来提供深远的利益。- Amy Fowler，Pure Storage公司FlashBlade战略与运营副总裁

AI-powered advertisements: Whether companies bringing their mascots to life, or avatars engaging with us via AI-powered billboards and signage, AI will enable advertisers to take their efforts up a notch. Soon, instead of a person handing out flyers, individuals will get specific, targeted solicitations as they’re waiting for the streetlight to change, walking towards an ATM, or refueling their car at a gas station. All of this will be made possible via Facial Recognition and for those of us who have ever placed an Xbox game, watched Netflix, or ordered anything from Amazon, these daily encounters will know how to capture your specific attention. – David Ly – CEO and founder of [Iveda](https://www.iveda.com/)  

人工智能广告：无论是公司将吉祥物带入生活，还是通过人工智能驱动的广告牌和标牌与我们互动的化身，人工智能都将使广告商能够更上一层楼。很快，人们就不再是一个人分发传单，而是在等待路灯改变、走向自动取款机或在加油站加油时，得到具体的、有针对性的招揽。所有这一切都将通过面部识别实现，对于我们这些曾经放置过Xbox游戏、观看过Netflix或从亚马逊订购过任何东西的人来说，这些日常遭遇将知道如何吸引你的特定注意力。- 大卫Ly -Iveda首席执行官兼创始人

AI will be increasingly augmented by automation to enhance its impact on the business. AI and automation make a powerful combination, opening up more capabilities that can unlock new value. From Communications Mining to NLP to Document Processing, AI and automation can tackle entirely new realms of work. – Ted Kummert, Executive Vice President of Products & Engineering at [UiPath](https://www.uipath.com/)  

人工智能将越来越多地通过自动化来增强其对业务的影响。人工智能和自动化形成了强大的结合，开启了更多可以释放新价值的能力。从通信挖掘到NLP再到文档处理，人工智能和自动化可以解决全新的工作领域。- Ted Kummert，UiPath产品与工程执行副总裁

Generative AI Transforms Enterprise Applications: The hype about generative AI becomes reality in 2023. That’s because the foundations for true generative AI are finally in place, with software that can transform large language models and recommender systems into production applications that go beyond images to intelligently answer questions, create content and even spark discoveries. This new creative era will fuel massive advances in personalized customer service, drive new business models and pave the way for breakthroughs in healthcare. – MANUVIR DAS  

Senior Vice President, Enterprise Computing, [NVIDIA](https://www.nvidia.com/)

We will start to see a democratization of AI: AI can be a scary tool but it is an integration businesses must get on board with to simplify and integrate their processes – and this can be accomplished with no code at all. No to low code opens the door to customization at a better price and opens the door to less technical people to use it. It also creates an easy starting point so users are not scared off. It’s what everyone has been waiting for – really making a proper intelligent model to answer the companies questions. Democratization of AI offers more than just an answer, it provides a direct extraction of the answer from the source content. – Daniel Fallman, CEO and founder of [Mindbreeze](https://inspire.mindbreeze.com/)

AI May Not Be Sentient (Yet), But It’s Smart Enough to Put Your Dark Data to Work: True discovery will be found through AI and advanced data analytics, by assigning more tasks to AI. Organizations are awash with dark data. In the legal world, dark data can be a treasure trove for the finding. What was once thought of as a burden of data is now either an asset or a risk in the age of AI: in those dark spaces there are breadcrumbs for AI to follow. AI has the cycles to mine insights from vast quantities of data and uncover patterns in the haystack. This may finally fully unlock the value of dark data to chart a faster path to the truth. – Chuck Kellner, Strategic Discovery Advisor at [Everlaw](https://www.everlaw.com/)

AI is going to continue to be easier to add. You’re going to see companies stop trying to build their own because they can’t compete with the technology and the dollars invested by the big cloud services providers. Everyone is going to consolidate their AI tooling onto the big cloud service providers in favor of utilizing their infrastructure in the most effective way. – Troy Pospisil, CEO of [Ontra](https://www.ontra.ai/)

The last of the data-generating or data-consuming companies that haven’t already adopted AI will do so next year. In an era where data is growing so fast, a business will become obsolete if it does not have tools to automate repetitive decisions, process internal data, and/or take advantage of external data. At the end of the day, the role of automation is not only to accelerate existing processes, but to enable the maximum potential of human productivity. In 2023, when a turbulent economic climate will continue to force enterprises to reduce their workforces, intelligent automation will mitigate the onus on remaining talent, transforming operations and creating more engaged employees. Moreover, companies will see incredible value on the customer side, with intelligent automation enabling heightened demand predictive capabilities and more efficient data pipelines. The key to adopting this critical technology is to ensure all users understand how the automated decisions are being made, creating trust in the system and optimizing implementation. – Farshad Kheiri, Head of AI and Data Science at [Legion Technologies](http://legion.co/)

AI model explainability stays hot. As AI becomes increasingly important in the lives of everyday people, more people want to know exactly how the models work. This is being driven by internal stakeholders, consumers, and regulators. – Anupam Datta, co-founder, president and chief scientist at [TruEra](https://truera.com/)

Generalist AI Agents: AI agents will solve open-ended tasks with natural language instructions and large-scale reinforcement learning, while harnessing foundation models — those large AI models trained on a vast quantity of unlabeled data at scale — to enable agents that can parse any type of request and adapt to new types of questions over time. – ANIMA ANANDKUMAR  

Director of ML Research at [NVIDIA](https://www.nvidia.com/), and Bren Professor at Caltech

In 2023, AI-driven tools are going to augment human efforts in virtually every function. Workers from marketing to sales to support to finance will have AI tools that are capable of completing half or more of their daily tasks and the human role will be to build on, enhance, polish or focus AI output to complete their duties. The routine minutiae will be stripped out of the work day, allowing people to spend their time applying judgment and insight. In that sense, AI should stand for Augmented Intelligence, where its best use is in automating tasks with assumptions being made through pattern analysis, but ultimately vetted by human intuition and guidance. – Ramon Chen, chief product officer, [ActivTrak](http://www.activtrak.com/)  

到2023年，人工智能驱动的工具将在几乎所有功能中增强人类的努力。从营销到销售到支持再到财务的员工将拥有能够完成一半或更多日常任务的人工智能工具，而人类的角色将是建立、增强、完善或集中人工智能输出以完成他们的职责。日常琐事将从工作日中剥离出来，让人们花时间应用判断和洞察力。从这个意义上说，人工智能应该代表增强智能（Augmented Intelligence），它的最佳用途是自动化任务，假设是通过模式分析做出的，但最终由人类直觉和指导进行审查。- Ramon Chen，ActivTrak首席产品官

Fewer keywords, greater understanding: In years past, AI has relied heavily on keywords to search a database or maintain a conversation. Being this literal is, of course, limiting: if the AI didn’t receive the right keyword, it could fumble a chatbot conversation or come up with the wrong search results, or have no results at all. In 2023 we’ll see AI continue to move further away from keywords, and progress toward actual comprehension and understanding. Language-agnostic AI, already existent within certain AI and chatbot platforms, will understand hundreds of languages — and even interchange them within a single search or conversation — because it’s not learning language like you or I would. This advanced AI instead focuses on meaning, and attaches code to words accordingly, so language is more of a finishing touch than the crux of a conversation or search query. Language-agnostic AI will power stronger search results — both from external (the Internet) and internal (a company database) sources — and less robotic chatbot conversations, enabling companies to lean on automation to reduce resources and strain on staff and truly trust their AI … Or no words at all: This same concept extends to images as well. With AI that actually understands language, rather than piecing it together one word at a time, we’ll also be able to describe an image that we’re looking for, and the AI can spit out the correct image. Similarly, this AI can also handle image-to-image search: we provide it with an image, and the AI finds another image resembling the first. Beyond its consumer search engine applications, this technology can be applied commercially. For example, retail brands can use it to show customers exactly what they are looking for (even if they can’t remember what it’s called). – Dr. Pieter Buteneers, Director of Engineering in ML and AI, Sinch  

更少的关键词，更好的理解：在过去的几年里，人工智能在很大程度上依赖于关键字来搜索数据库或维护对话。当然，这种字面意思是限制：如果AI没有接收到正确的关键词，它可能会在聊天机器人对话中摸索，或者给出错误的搜索结果，或者根本没有结果。在2023年，我们将看到人工智能继续远离关键词，并朝着实际的理解和理解迈进。语言不可知的人工智能，已经存在于某些人工智能和聊天机器人平台中，将理解数百种语言，甚至在一次搜索或对话中交换它们，因为它不像你或我那样学习语言。这种先进的人工智能专注于意义，并相应地将代码附加到单词上，因此语言更像是点睛之笔，而不是对话或搜索查询的关键。 与语言无关的人工智能将提供更强大的搜索结果-包括来自外部（互联网）和内部（公司数据库）的资源-以及更少的机器人对话，使公司能够依靠自动化来减少资源和员工的压力，真正信任他们的人工智能......或者根本不用言语：同样的概念也延伸到图像上。有了真正理解语言的人工智能，而不是一次拼凑一个单词，我们还可以描述我们正在寻找的图像，人工智能可以吐出正确的图像。同样，这个AI也可以处理图像到图像的搜索：我们给它提供一张图像，AI找到另一张类似于第一张的图像。除了其消费者搜索引擎应用之外，这项技术还可以在商业上应用。例如，零售品牌可以用它向顾客展示他们想要的东西（即使他们不记得它叫什么）。- 医生 Pieter Buteneers，Sinch ML和AI工程总监

Companies Will Leverage AI to Shed Some Light on Dark Data: The lack of insight caused by the “black hole” of dark data will continue to plague companies in 2023, including the loss of “tribal” knowledge every time an employee leaves the company. This knowledge gap will lead organizations to leverage AI to classify employee knowledge, making sure everything is captured and searchable, thus enabling team members and new employees to quickly ramp up rather than starting from ground zero. – [PFU America’s](https://www.pfu.ricoh.com/us/) Technology Evangelist Scott Francis  

公司将利用人工智能来揭示暗数据：暗数据“黑洞”导致的洞察力缺失将在2023年继续困扰企业，包括员工每次离职时都会丢失“部落”知识。这种知识差距将导致组织利用人工智能对员工知识进行分类，确保所有内容都被捕获和搜索，从而使团队成员和新员工能够快速提升，而不是从零开始。- PFU美国技术布道家Scott弗朗西斯

Explainability Will Create More Trustworthy AI for Enterprise Users: As individuals continue to worry about how businesses and employers will use AI and machine learning technology, it will become more important than ever for companies to provide transparency into how their AI is applied to worker and finance data. Explainable AI will increasingly help to advance enterprise AI adoption by establishing greater trust. More providers will start to disclose how their machine learning models lead to their outputs (e.g. recommendations) and predictions, and we’ll see this expand even further to the individual user level with explainability built right into the application being used. – Workday’s CTO, Jim Stratton  

可解释性将为企业用户创造更值得信赖的AI：随着个人继续担心企业和雇主将如何使用人工智能和机器学习技术，公司将其人工智能应用于员工和财务数据的透明度变得比以往任何时候都更加重要。可解释的人工智能将通过建立更大的信任来越来越多地帮助推进企业人工智能的采用。更多的供应商将开始披露他们的机器学习模型如何导致他们的输出（例如，建议）和预测，我们将看到这进一步扩展到个人用户级别，并将解释性直接内置到正在使用的应用程序中。- Workday首席技术官Jim Stratton

One of the most exciting developments in 2022 was the introduction of Data Creation as an approach. This is the process of intentionally creating data to power AI and advanced data applications, as opposed to data exhaust, which is the byproduct of data emitted from existing systems. Data Contracts have been a much-discussed topic in the data community this year. In the context of the Modern Data Stack, this sensible idea has been controversial primarily because practitioners are stuck in the ‘data is oil’ paradigm, in which they assume that data is extracted and not intentionally created. We expect the ‘data product manager’ role and ‘data product management’ skill set to continue to gain traction in 2023. They are instrumental for organizations to successfully treat data as a product, design and implement the right data contracts (as part of data products) and enable them to build out a ‘data mesh.’ – Yali Sassoon, Co-Founder, Snowplow

Open source and AI realize their shared potential in 2023, but it gets complicated in a hurry: The massive potential of open source-powered AI efforts will quickly beget itself in 2023, as new machine learning models find an ever-growing set of important use cases. Yet it could be a bumpy road, as questions such as who owns the code when written with a machine learning model based on open source, is that use compatible with open source licenses, and is it a derived product will all need to be addressed in the year ahead. – Luis Villa, co-founder, [Tidelift](http://www.tidelift.com/)

AI in Mainstream Business: Most businesses are still in the exploration stage when it comes to AI, but they are experimenting with what this technology can do for them specifically. At this point, many businesses are running POC (proof of concept) trials in specific use cases to further investigate the benefits. As they continue to explore and understand how AI can be utilized, the level of maturity and commitment continues to differ across industries. For example, organizations in the manufacturing sector are further along in their AI journeys than organizations in the retail sector. In 2023, more businesses will invest in the development and testing the benefits of AI in their organizations. – Marieke Wijtkamp, SVP of Product at [Librestream](https://librestream.com/)  

Responsible AI solutions – that address trust, risk, ethics, security, transparency – will gradually begin to become more mainstream. Solutions that target personalized insights – whether it is related to aspects such as credit risk, underwriting or simply recommendation engines for dynamic pricing or influencing buying decisions. – Nicolas Sekkaki, [Kyndryl](https://www.kyndryl.com/us/en)’s GM of Applications, Data & AI

AI Gets Smarter in 2023: AI will not only grow smarter in 2023, it will become more affordable, simple, and accessible. Companies will automate many processes done manually before, such as invoicing, transcriptions, medical charting, and resume processing. As companies digitize their document archives and historic data, they will use Natural Language Processing (NLP) to make it searchable in real-time. This will increase employee productivity and accelerate the availability of information to business units, delivering richer insights and stronger ROI. – [PFU America’s](https://www.pfu.ricoh.com/us/) Technology Evangelist Scott Francis

Businesses leveraging AI to do more with less during challenging times will win in the long term: Microsoft CEO Satya Nadella [recently said](https://news.yahoo.com/microsoft-ceo-the-cloud-will-drive-economic-growth-111900406.html), “software is ultimately the biggest deflationary force.” And I would add that out of all software, AI is the most deflationary force.  Deflation basically means getting the same amount of output with less money — and the way to accomplish that is to a large degree through automation and AI. AI allows you to take something that costs a lot of human time and resources and turn it into computer time, which is dramatically cheaper — directly impacting productivity.  While many companies are facing budget crunches amid a tough market, it will be important to continue at least some AI and automation efforts in order to get back on track and realize cost savings and productivity enhancements in the future. – Varun Ganapathi, Ph.D., CTO and co,-founder at [AKASA](http://akasa.com/)

Embedded AI expands the potential of operational applications: In 2023, IDC is [forecasting](https://aibusiness.com/document.asp?doc_id=775354), AI spending will go past half-trillion-dollar mark. However, this will only be possible if AI is generally available to customers and organizations across all industries. One of the most significant barriers to the wide adoption of AI has been the skills gap. Now, AI has become more accessible with the ever-growing number of apps that include AI functionality, like predictive text suggestions. This, combined with the ease of use that stems from the growth of AI capabilities, will bring the utility of AI within reach for all. Operationalizing ML algorithms within databases has been a harder challenge and that will see a change in 2023, and finally don’t worry, GPT-4 is not going to create skynet ![🙂](1f642.svg) – Shireesh Thota, SVP of Engineering, SingleStore

Human-Centered AI will come to focus in 2023: The outdated idea of AI replacing people is giving way to a more [human-centered vision of AI](https://hcil.umd.edu/human-centered-ai/) with tools to augment human intelligence, creativity and well-being in 2023. AI has moved from black-box models beyond human comprehension, to emphasize transparency and model explainability – at population and individual levels.  Instead of making decisions for people, algorithms can recommend a number of good options, allowing them to choose using their experience and knowledge. – Michael O’Connell, Chief Analytics Officer at [TIBCO](https://www.tibco.com/) 

In 2023, many companies will seek AI-powered solutions that modernize their business processes, and improve productivity and employee morale while growing the bottom line. I believe that, as AI applications become more widespread, the common misunderstanding that “AI takes jobs from people” will dissipate. Over time, the understanding that technologies denoted as AI help employees focus on more strategic tasks will grow. In my opinion, the widening of AI applications mirrors other historical inventions that were originally suspected to “take jobs.” Let us draw an analogy with the steam engine – this advancement did not prove disastrous for workers. It reduced their workloads and enabled them to do more. Advances in Machine Learning (ML), like Intelligent Document Processing (IDP) that handles all data entry and processing from a cloud-based platform, is one of the technological advancements happening today. Manual data entry is the modern equivalent of physical tasks in the workplace, and ML is here to help. – Milan Šulc, Head of AI Lab at [Rossum](https://rossum.ai/)  

到2023年，许多公司将寻求AI驱动的解决方案，使其业务流程现代化，并提高生产力和员工士气，同时提高利润。我相信，随着人工智能应用的越来越广泛，“人工智能从人身上夺走工作”的普遍误解将会消失。随着时间的推移，人们会越来越理解AI技术有助于员工专注于更具战略性的任务。在我看来，AI应用的拓宽反映了其他原本被怀疑“抢饭碗”的历史发明让我们拿蒸汽机做个类比吧--这种进步对工人来说并不是灾难性的。它减少了他们的工作量，使他们能够做更多的事情。机器学习（ML）的进步，如智能文档处理（IDP），它可以从基于云的平台处理所有数据输入和处理，是当今正在发生的技术进步之一。 手动数据输入相当于现代工作场所中的物理任务，ML可以提供帮助。 - -Rossum人工智能实验室负责人Milan Šulc

The testing and experimenting with AI systems and machine learning tools to perform all aspects from everything between “art-to-documentation” to “code assistance”. These integrated innovations are truly driving more sophisticated intelligence into cloud systems which helps accelerate development, support, customer interaction and adaptive tooling.  Artificial intelligence and machine learning (AI/ML) is an exploding innovation which is pushing breakthrough services for the cloud. – Chris Chapman, CTO at [MacStadium](https://www.macstadium.com/)  

测试和实验人工智能系统和机器学习工具，以执行从“艺术到文档”到“代码辅助”的所有方面。这些集成创新真正推动了云系统中更复杂的智能化，有助于加快开发、支持、客户交互和自适应工具的速度。人工智能和机器学习（AI/ML）是一项爆炸性的创新，正在推动云计算的突破性服务。- Chris Chapman，MacStadium CTO

Between the increasing complexity of systems and the huge shortage of tech talent, organizations will need a much greater reliance on automation just to keep up in 2023 and beyond. Organizations have been collecting telemetry data for a long time, but that data has not historically been structured enough for good automation. Now, organizations are increasingly able to collect data at full fidelity. That’s going to change things dramatically, because the much higher quality data lets us build the models we need essentially to automate processes right. Moving forward, this trend will contribute toward the increased adoption of AIOps, which leverages data to automate the prediction, prevention and resolution of incidents. There simply aren’t enough individuals in the workforce to do this manually — especially as data volumes continue to skyrocket — and more enterprise leaders are beginning to view AIOps as a sustainable path forward. Additionally, business leaders will begin to leverage AIOps for solutions that extend beyond the traditional IT use cases. Believe it or not, AIOps can be applied to KPI business metrics such as revenue, transitions or e-commerce. By taking purely business metrics and tying them back to underlying software infrastructure, companies can understand where KPIs are trending, plot their evolution, and make early, informed decisions. In 2023, expect automated solutions to become commonplace in the enterprise, and look out for AIOps use cases to expand significantly. – Spiros Xanthos, General Manager of Observability, [Splunk](https://www.splunk.com/)  

在系统日益复杂和技术人才的巨大短缺之间，组织将需要更多地依赖自动化，以便在2023年及以后跟上。组织收集遥测数据已有很长一段时间，但这些数据在历史上并没有被足够的结构化来实现良好的自动化。现在，组织越来越能够以完全保真度收集数据。这将极大地改变事情，因为更高质量的数据使我们能够构建我们所需的模型，以实现流程的自动化。展望未来，这一趋势将有助于AIOps的采用，AIOps利用数据自动化预测、预防和解决事件。劳动力中根本没有足够的人来手动完成这一任务-特别是在数据量持续飙升的情况下-越来越多的企业领导者开始将AIOps视为一条可持续的前进道路。 此外，业务领导者将开始利用AIOps来实现超越传统IT用例的解决方案。信不信由你，AIOps可以应用于KPI业务指标，如收入、转型或电子商务。通过采用纯业务指标并将其与底层软件基础设施联系起来，公司可以了解KPI的趋势，绘制其演变趋势，并尽早做出明智的决策。到2023年，预计自动化解决方案将在企业中变得普遍，并期待AIOps用例大幅扩展。 Spiros Xanthos，Splunk可观测性总经理

For CIOs, deciding how and where AI workloads will be placed is about to get infinitely more complicated, due to the double whammy of skyrocketing cloud costs and inflation. AI in the cloud remains ‘the easy button,’ but you pay a big premium for it with diminishing performance as you scale – a premium that only gets bigger with inflation. So after years of increasing AI workloads in the cloud, some companies will rethink those decisions in 2023. In fact, we predict that a vast majority of companies will move quickly to undo a big percentage of their previous (expensive) decisions to put AI workloads in the cloud. – Holland Barry, SVP and Field CTO, [Cyxtera](https://www.cyxtera.com/)  

对于首席信息官来说，决定人工智能工作负载将如何以及在何处放置将变得更加复杂，这是由于云成本飙升和通货膨胀的双重打击。云中的人工智能仍然是“简单的按钮”，但随着规模的扩大，你为它支付了很大的溢价，性能下降-这种溢价只会随着通货膨胀而变大。因此，在多年来不断增加云端人工智能工作量之后，一些公司将在2023年重新考虑这些决定。事实上，我们预测绝大多数公司将迅速采取行动，撤销他们之前做出的将人工智能工作负载放到云中的大部分决策。- Holland巴里，Cyxtera高级副总裁兼现场CTO

As AI becomes cheaper and easier to build, train and maintain, there will be much more adoption of AI and breadth of AI use cases in 2023. For example, the CX industry is becoming AI-first as the technology extends beyond reactive service and becomes embedded across the entire customer journey, including proactive and preventative service. To prepare for this future where the majority of front line customer interactions are completely automated with AI, businesses will double down on AI in 2023 and start to use AI in completely new use cases. – Adrian McDermott, Zendesk CTO  

随着人工智能变得更便宜，更容易构建、训练和维护，到2023年，人工智能的采用和AI用例的广度将大大增加。例如，CX行业正在成为AI优先的技术，因为该技术超越了被动式服务，并嵌入到整个客户旅程中，包括主动和预防性服务。为了迎接未来，大多数一线客户交互都将通过人工智能实现完全自动化，企业将在2023年加倍使用人工智能，并开始在全新的用例中使用人工智能。- Adrian McDermott，Zendesk CTO

In 2023, AI Testing Will Become Prevalent as the Technology Catches Up to Advanced AI: CX complexity is increasing because the technology underpinning customer experiences, customer expectations and interactions is evolving. As contact centers move to the cloud, complexity shifts from technology-driven to business-driven such as processes, integration with APIs and channels. The nature of the complexity is changing. When complexity becomes too great, manual testing is no longer sufficient. The only way to test this level of complexity is with AI coming to the delivery of CX. As CX business applications become more complex and increasingly utilize AI more, automated testing will keep pace by leveraging AI to keep up with the scope and pace of testing. – Max Lipovetsky, VP of Products, [Cyara](https://cyara.com/)  

2023年，随着技术赶上先进的AI，AI测试将变得普遍：客户体验的复杂性正在增加，因为支撑客户体验、客户期望和交互的技术正在不断发展。随着联络中心迁移到云端，复杂性从技术驱动转向业务驱动，例如流程、与API和渠道的集成。复杂性的本质正在发生变化。当复杂性变得太大时，手动测试就不再足够了。测试这种复杂性水平的唯一方法是使用AI来交付CX。随着CX业务应用程序变得越来越复杂，越来越多地利用AI，自动化测试将通过利用AI跟上测试的范围和速度。- Max Lipovetsky，Cyara产品副总裁

Enterprises embrace AI to gain resiliency among economic uncertainty: During economic uncertainty, enterprises want improved business uptime, productivity gains and revenue assurance. To gain an advantage, they will have to build an autonomous enterprise that is built on the pillars of AI, ML and intelligent automation. This will help with business scaling and resiliency and creating competitive differentiation needed during uncertain times. The importance of being able to demonstrate business value that during economic downtime will be key. Gartner, at a recent keynote in London, stated that just 17 percent of organizations are consistently able to demonstrate the business value of IT. That percentage has to get better moving into the new year. In 2023, organizations will increasingly use automation to maximize productivity. Expect greater adoption of AI to make IT systems more resilient without growing costs. Using AI, businesses can automate some of the most essential and elemental IT operations tasks, such as monitoring alerts managing employee onboarding and offboarding. In doing so, companies not only make their IT systems stronger, they also free up skilled IT staff to focus on higher value projects. Expect greater adoption of cloud and multi-cloud operations. Sustainability metrics are also a major focus, so AI has a role to play there in supporting organizational efforts to meet their goals. – Akhilesh Tripathi, CEO, Digitate

AI will become table stakes for how organizations and IT departments run their business: AI has evolved from a sideline experiment to a core part of how most organizations run their business. It’s no longer about whether or not to use AI, but how to realize its value to drive outcomes. Looking ahead 2023, we will continue to see a fundamental shift from experimental to ubiquitous and pervasive AI deployments across IT. Many AI projects often fail to deliver on the value they promise. The success of these deployments will rely on choosing the right use cases that optimize core processes within the organization and selecting the right toolkit for the job. – Stephen Franchetti, Chief Information Officer, Samsara 

Opening up to AI: Learning to trust our AI colleagues:  With AI tools increasingly standardized, organizations are realizing that competitive gains will best be achieved when there is high confidence that AI is delivering the right analytics and insights. To build trust, AI algorithms must be visible, auditable and explainable, and workers must be involved in AI design and output. – Deloitte’s Chief Futurist [**Mike Bechtel**](https://www2.deloitte.com/us/en/profiles/michael-bechtel.html)

AI/ML Gets Grounded: While AI is the new buzzword, using it in most content production organizations has been messy. Cool AI tools to up-res or transcribe video are scattered across web tools, custom applications, or embedded in editing suites. Looking forward, beyond the “standard” actions of these tools, content producers will work with data scientists and computer vision experts to customize these tools to meet their specialized content domain and needs, and to automate actions that take content loggers ages to complete. As content leaders realize they are in a critical race to develop and implement these tools, they will look to centralize this development and connect it to powerful GPU pipelines. – Skip Levens, Product, Media and Entertainment, [Quantum](http://www.quantum.com/)

Organizations will face greater pressure to realize AI’s value: While AI has become firmly entrenched in all industries – from financial services to healthcare and others – many organizations still struggle to shift AI proofs-of-concept to full-scale production. In 2023, business/IT decision makers will focus on tighter collaboration to truly address company issues and needs. – Keshav Pingali, co-founder and CEO of [Katana Graph](https://katanagraph.com/)

AI Will Become a DevOps Competitive Advantage in 2023: The future of enterprise DevOps is being able to turn data into actionable, predictive insights so enterprises can learn from past historical trends to make higher-quality software at greater speed and AI/ML has finally reached a tipping point to enable this. A machine learning model can now capture thousands of monthly change events, including who the team is, what infrastructure changed, what testing was done during development, who the developer or team was, defects that were found during testing, and other factors. In 2023, this information will increasingly be correlated to the success and failure of past changes so teams can learn from these past issues – and plan to avoid them. – Wing To, Vice President of Engineering for Value Stream Delivery Platform & DevOps at [Digital.ai](https://digital.ai/)

2023 will be a pivotal year for mobilizing AI solutions across several business verticals. With machine learning quickly becoming ubiquitous across the business landscape, how businesses create trust with usable and explainable AI will separate the leaders from the pack in the coming year. To achieve this, many organizations will pivot focus beyond the algorithm with things such as business-ready predictive dashboards, visualizations, and applications that demystify how AI systems work and reach conclusions — this will help business leaders understand the impact on their business and take action quickly with confidence. – Santiago Giraldo, Senior Product Director at Cloudera 

AI is ‘coming of age’ in terms of its maturity, and while there continues to be some resistance towards it, AI will grow in acceptance as a valuable tool for businesses. AI, for instance in the legal setting, gives legal departments the ability to reduce the amount of “low-value work” being done by team members by replacing mundane tasks with technology, giving the employee back the time for more fulfilling work and enabling legal teams to do more with less. Additionally, we’ll see an increase of business leaders recognizing how efficient and time-saving AI technology can be in keeping teams engaged, efficient and focused on high-value work, especially as departments get stretched thin. This is what will drive businesses towards more AI-powered tools in 2023. – Matt Gould, General Counsel, [ContractPodAi](https://contractpodai.com/)

AI and Machine Learning Make Data Lifecycle Management More Intelligent: Data is the driving force of artificial intelligence (AI) and machine learning. Vast quantities of training data enhance accuracy in the search for potentially predictive relationships. In the past, security solutions were predominantly reactive but that is changing. Machine learning and AI algorithms play a key role in this shift. While they are not a one-stop solution for all cybersecurity concerns, they are incredibly useful for rapidly automating decision-making processes and inferring patterns from data. These algorithms work by first learning from real-world data, analyzing normal behavior patterns and responding to deviations from that baseline norm. Traditional methodologies of backup to tape are also going away due to the level of effort and time it takes to restore from tape. Additionally with rich data and history stored in backup files, organizations will start to realize the benefits of backing up their data to either on-premises or cloud object storage and continuously analyzing that data to make it more useful to business decisions. – Jimmy Tam, CEO of Peer Software  

AI和机器学习让数据生命周期管理更加智能：数据是人工智能（AI）和机器学习的驱动力。大量的训练数据增强了搜索潜在预测关系的准确性。过去，安全解决方案主要是被动式的，但这种情况正在发生变化。机器学习和AI算法在这一转变中发挥了关键作用。虽然它们不是所有网络安全问题的一站式解决方案，但它们对于快速自动化决策过程和从数据推断模式非常有用。这些算法首先从现实世界的数据中学习，分析正常的行为模式，并对偏离基线规范的情况做出反应。由于从磁带恢复所需的工作量和时间，传统的磁带备份方法也正在消失。 此外，随着备份文件中存储的丰富数据和历史记录，企业将开始意识到将数据备份到本地或云对象存储并持续分析数据以使其对业务决策更有用的好处。 - Jimmy Tam，Peer Software首席执行官

Use of AI/ML to drive data management will be a foundational requirement (vs. a nice to have) to meet the ever changing data landscape as well as, reduction in resources and budget freezes. Companies will be looking to go from best of breed tools to tools that can accelerate automation and provide core capabilities. Focus will go from evaluation of having every capability in each tool to understanding foundation capabilities required to deliver shorter term value. The goal will be to reduce management of vendors, tools, costs, training, and integrations across tools. Moving to cloud SaaS applications will continue to reduce management of infrastructure and focus on utilization of toolsets to obtain value. Companies will leave it up to the vendors to manage performance, upgrades, and general troubleshooting. – Stephen Gatchell, Director of Data Advisory at [BigID](http://bigid.com/)  

使用AI/ML来推动数据管理将是一项基本要求（相对于一个很好的拥有），以满足不断变化的数据格局以及，减少资源和预算冻结。公司将寻求从同类最好的工具转向能够加速自动化并提供核心功能的工具。重点将从评估每种工具中的每种功能转向理解交付短期价值所需的基础功能。目标是减少对供应商、工具、成本、培训和工具集成的管理。迁移到云SaaS应用程序将继续减少对基础设施的管理，并专注于利用工具集来获得价值。公司将把它留给供应商来管理性能、升级和常规故障排除。- Stephen Gatchell，BigID数据咨询总监

Photos, icons and other visual materials created by AI will make their way out of the lab and into mainstream business. This year, we saw major companies like Microsoft and Canva begin experimenting with AI-powered algorithms to build digital images from plain text. In 2023, text-to-image processes will become accessible to everyday companies, eliminating their dependency on overused stock images and visuals—which often don’t fully communicate the ideas they want to convey about their businesses. We’ll see more digital imagery, app-making, art and even entertainment created by AI rather than through manual design processes, opening up an entirely new market and revenue streams. – Roman Reznikov, VP of Delivery, Head of Digital Segment at [Intellias](https://intellias.com/)  

AI创建的照片、图标和其他视觉材料将走出实验室，进入主流业务。今年，我们看到微软和Canva等大公司开始试验人工智能算法，从纯文本构建数字图像。到2023年，文本到图像的流程将成为日常公司所能使用的，从而消除他们对过度使用的库存图像和视觉的依赖，这些图像和视觉通常不能完全传达他们想要传达的关于他们业务的想法。我们将看到更多的数字图像、应用程序制作、艺术甚至娱乐由人工智能创造，而不是通过人工设计过程，开辟一个全新的市场和收入来源。- Roman Reznikov，交付副总裁，Intellias数字市场负责人

Never-Before-Possible AI and ML Use Cases Will Emerge–and Ultimately Become Mainstream: As companies break free from the constraints of legacy systems and are able to bring together massive data sets from disparate systems, we’ll see a slew of never-before-possible use cases for AI and machine learning. In auto manufacturing, for instance, we’re just starting to see the emergence of next generation manufacturing data platforms–or single unified cloud-based platforms where manufacturers are aggregating all data across their entire organizations. Once the data’s in there, they can start building AI-enabled applications against that. Here are a few that we expect to begin seeing more of in the coming year: (i) Visual inspection with computer vision to detect anomalies on the assembly line; (ii) Natural Language Processing – Using voice as an interface in the manufacturing process and across operations to control software systems; (iii) Introduction of predictive and preventive maintenance via anomalies in machines that signal mechanical failure before it happens. – Marco Santos, CEO USA and LATAM at [GFT](https://www.gft.com/us/en)  

前所未有的AI和ML用例将出现，并最终成为主流：随着公司摆脱传统系统的限制，能够将来自不同系统的大量数据集整合在一起，我们将看到一系列前所未有的AI和机器学习用例。例如，在汽车制造业中，我们刚刚开始看到下一代制造业数据平台的出现，或者说是基于云的单一统一平台，制造商可以将整个组织中的所有数据聚合在一起。一旦数据在那里，他们就可以开始构建支持AI的应用程序。 以下是一些我们预计在明年开始看到更多的：㈠用计算机视觉进行目视检查，以发现装配线上的异常情况;（ii）自然语言处理-在制造过程中和跨操作中使用语音作为接口，以控制软件系统; ㈢通过在机械故障发生前发出信号的机器异常情况，实行预测性和预防性维修。 - Marco桑托斯，GFT美国和拉丁美洲首席执行官

AI will need to go beyond a buzzword to be valuable: Artificial intelligence (AI) has long been a buzzword that technologies have used to drum up interest in a product, but companies will begin to look beyond the buzzword itself for value from the technology. In 2023, companies will look to AI for two distinct reasons: 1) help them do more with less people and 2) drive more revenue. It will become less about using technology with AI and more about how AI drives efficiency for digital marketing teams and critical business outcomes. And if it does not drive outcomes – companies will look to other technologies that can. – Deniz Ibrahim, VP of Product Marketing, [Bluecore](https://www.bluecore.com/)  

AI需要超越流行语才能有价值：人工智能（AI）长期以来一直是技术用来激发人们对产品的兴趣的一个流行词，但公司将开始超越流行词本身，从技术中寻找价值。到2023年，企业将出于两个不同的原因关注AI：1）帮助他们用更少的人做更多的事情; 2）增加收入。它将不再是将技术与人工智能结合使用，而是更多地关注人工智能如何提高数字营销团队的效率和关键业务成果。如果它不能推动结果-公司将寻求其他可以的技术。- Deniz Ibrahim，Bluecore产品营销副总裁

Alignment will bring the concept of adversarial machine learning into the public consciousness: AI Alignment is the study of the behavior of sophisticated AI models, considered by some as precursors to transformative AI (TAI) or artificial general intelligence (AGI), and whether such models might behave in undesirable ways that are potentially detrimental to society or life on this planet. This discipline can essentially be considered adversarial machine learning, since it involves determining what sort of conditions lead to undesirable outputs and actions that fall outside of expected distribution of a model. The process involves fine-tuning models using techniques such as RLHF – Reinforcement Learning from Human Preferences. Alignment research leads to better AI models will be discussed a lot more in 2023, and will likely become a mainstream topic, bringing the idea of adversarial machine learning into the public consciousness. – Andrew Patel, Senior Researcher, [WithSecure Intelligence](https://www.withsecure.com/)

Unethical AI practices and AI abuse/misuse will increase while AI legislation is still being developed and debated: Use of unethical AI practices and the biases that come with them will continue and will only really be addressed when they start happening _en mass_ or for incidents with larger impact. As some of the larger industries start making it mainstream, there will be more data and more potential for abuse/misuse. The EU AI act will help, but the real data about us historically, the apps we use and the data we have produced are not located, processed or monetized in Europe for the most part. Based on the above, we will have increased cases of “run away data” where on paper and for auditors the data is in a certain location but is enriched outside of certain legislated jurisdictions when it comes to ML/AI. In the same way that we currently do CO2 book-keeping to “buy clean air” from other countries, so too will there be an economy for data enrichment once the first legislation gets passed in certain regions of the world. In the metal industry, companies spend millions shipping raw aluminum ore to Iceland because of the low cost of geothermal energy. So too will we have countries where data can be “shipped to” digitally, enriched and exported. The more moving parts and data, the more potential for misuse and abuse and thus leaks and real societal impact. The insurance industry along with special legislation will grow and be further introduced to the market to help manage the risk of data misclassification, prosecution and other data driven decisions coming from ML/AI. Systematic probing of AI/ML will become mainstream and detection for safeguarding AI algorithms will be required to protect the quality of outcome and data as well as detection of manipulation of the algorithms. – Tom Van de Wiele, Principal Technology & Threat Researcher, [WithSecure](https://www.withsecure.com/)

AI is a Game Changer: Even though the industry has been talking about AI for many years, the trifecta of massive amounts of data available through the rise of the internet, the dramatic increase in processing power fueled by GPU’s originally designed for gaming and steady advances in software algorithms to analyze and use that data will result in the power of AI being more fully realized across almost all markets. AI is 100% the number one game changer in the coming years – it will change the way we interact with computers just as Google Search did 20 years ago. Generative Design is one great example. Being able to use text prompts, leverage huge datasets and natural language recognition is now driving increased use of generative design, and I think we’ll see much more of that in 2023. But it goes beyond generative design and will have a big impact on Computer Aided Engineering (CAE) in general. For example, you will be able to generate large data sets and then have the system learn from it, and predict the outcome of deformations or anything else, give advance preview of post-processing results and even suggest certain workflows for optimum efficiency. Or give the system a basic 2D image and then it generates a 3D design from scratch. In addition to CAE, AI will completely revolutionize how realistic digital-twin assets are created. For example, designers would sit for hours generating and applying complex repeating textures on objects and environments. This can now be done with AI and will result in far greater volume and variety of assets. – Jonathan Girroir, Technical Evangelist at [Tech Soft 3D](https://www.techsoft3d.com/)

AI solutions that directly impact the top line (versus just reducing cost with a focus on the bottom line) – closing new business and retaining existing customers – are the ones that will win out in 2023: However, it’s still in the early adopter category. Next year, expansion is the new retention. Businesses must prepare for a cold winter that will likely subside in the 3rd and 4th quarters. During economic slowdowns, companies will need to reduce costs and protect revenue, and AI automation is a suitable answer for that because it scales at a cost that is way more effective during times when companies do not have the resources to expand human capital. – Jim Kaskade, CEO of [Conversica](https://www.conversica.com/)

Vendors need AI to keep up with volume of data: Machine data analytics is the future of data analytics. With machines increasing their capacity at a high rate, their data output is growing exponentially. It’s going to be essential for vendors to manage this unstructured log data as increased data will place stress on processes and resources. AI will help reduce false positives, as well as detect and fix problems faster. – Erez Barak, VP of Product Development for Observability, Sumo Logic

Companies will have to win users’ trust by ensuring that operations are ethical—this includes handling customer data and ensuring energy efficiency. To do this, those operating in this field will need to work on their ability to explain AI algorithms as well as highlight the value of the technology within a wider context. An example of this could be the evolution of self-driving autonomous cars, which are expected to achieve 40% to 50% more fuel efficiency than manual driving by 2050. – Bal Heroor, CEO of [Mactores](https://mactores.com/)

Having access to AI is no longer enough, AI needs to be adaptive in order to ensure agility within contract management: It seems everyone has or is claiming to have AI capabilities, but simply having AI is not necessarily enough to meet business key performance indicators (KPIs) and deliver on promises to customers. In order to take AI a step further, enterprises will need to invest in adaptive AI. [Gartner](https://t.nylas.com/t1/43/3i9l71jhseonx43to8q06zu57/1/fc58ebf2ebedaa0e678b50fc24cd44afe7430a8e4fdb28beed8319970a135fc7) predicts this technology to be one of the top trends that focus on business model changes, accelerated responses and opportunities. Adaptive AI allows businesses to change their model behavior after deployment using real-time feedback. Based on new data and adjusted goals, it will be possible to remain agile when faced with challenges in the real world. This adaptability will be vital when looking beyond problems to find solutions that leverage the vast knowledge and expertise available, empowering enterprises to act proactively rather than reactively. – Scott Quinn, Vice President – Customer Success at SirionLabs  

In the market, AI is primarily utilized for extraction. This is an important use case of AI as it creates visibility into the key data of an organization. Although this will continue to grow, extracting data out of legal documents is only the first step. In order to maximize outcomes and create strategic value, businesses must ask themselves what they can do with the data that’s extracted. In 2023, the approach to AI-driven data will shift, and enterprises will turn their attention to making this data more consumable and actionable to provide insights for strategic decisions across the business. – Atena Reyhani, SVP Product Management, [ContractPodAi](https://contractpodai.com/)

**Big Data**

The Rise of Data-as-a-Product. In 2023, data-as-a-product will reach maturity resulting in increased quality and trust in data at companies. This will lead to more robust data organizations within enterprises that require an increased need for data modeling technologies and data teams/engineers. – Armon Petrossian, CEO and co-founder of [Coalesce](https://coalesce.io/) 

The Data Market will Evolve as Large Enterprises Drive Change. The last ten years has been all about cloud and modern data stacks with the rise of technologies like dbt, Snowflake, Databricks, and others. While this trend is extremely impactful for smaller and mid-size organizations since they have a really simple way to start a data platform in minutes, larger enterprises have a different set of challenges mostly around modernization, change management, and governance. This is where data lineage is beginning to play a critical role. The data market today is extremely fragmented and one of the big questions, especially considering the recession, is if and how it will consolidate. We may see a lot more mergers and acquisitions in 2023. Additionally, we expect more evolution on the non-technology side with data contracts, data mesh, and/or advanced federated governance processes, as that seems to be the next obvious step on the data journey for any mature data organization. – VP of Research and Education at MANTA, Jan Ulrych

Data Complexity Will Increase: The nature of data is changing. There are both more data types and more complex data types with the lines continuing to blur between structured and semi-structured data. At the same time, the software and platforms used to manage and analyze data are evolving. A new class of purpose-built databases specialize in different data types—graphs, vectors, spatial, documents, lists, video, and many others. Next-generation cloud data warehouses must be versatile—able to support multimodal data natively, to ensure performance and flexibility in the workloads they handle. The Ocient Hyperscale Data Warehouse, for example, supports arrays, tuples, matrixes, lines, polygons, geospatial data, IP addresses, and large variable-length character fields, or VARCHARs. The need to analyze new and more complex data types, including semi-structured data, will gain strength in the years ahead, driven by digital transformation and global business requirements. For example, a telecommunications network operator may look to analyze network metadata for visibility into the health of its switches and routers. Or an ocean shipping company may want to run geospatial analysis for logistics and route optimization. – Chris Gladwin, CEO and Co-founder of [Ocient](https://www.ocient.com/)数据复杂性将增加：数据的性质正在发生变化。既有更多的数据类型，也有更复杂的数据类型，结构化数据和半结构化数据之间的界限继续模糊。与此同时，用于管理和分析数据的软件和平台也在不断发展。一类新的专门构建的数据库专门处理不同的数据类型-图形、矢量、空间、文档、列表、视频和许多其他类型。下一代云数据仓库必须是多功能的，能够本地支持多模式数据，以确保其处理工作负载的性能和灵活性。例如，Ocent Hyperscale Data Warehouse支持数组、元组、矩阵、线、多边形、地理空间数据、IP地址和大型可变长度字符字段（VARCHAR）。在数字化转型和全球业务需求的推动下，分析新的和更复杂的数据类型（包括半结构化数据）的需求将在未来几年内变得越来越强大。 例如，电信网络运营商可以考虑分析网络元数据以了解其交换机和路由器的健康状况。或者海运公司可能希望运行地理空间分析以进行物流和路线优化。 - Chris Gladwin，Ocient首席执行官兼联合创始人  

Data Reduction: There is an exponentially increasing amount of data, but I believe we will see rise of solutions that deduce the meaningful bits of data from the overall mass of data collected, or even reduce the footprint of data using new technologies beyond current classic data storage techniques. – Dan Spurling, SVP Product Engineering, Teradata  

数据缩减：数据量呈指数级增长，但我相信我们将看到解决方案的兴起，这些解决方案从收集的总体数据中推断出有意义的数据位，甚至使用超越当前经典数据存储技术的新技术来减少数据占用。- Dan Spurling，Teradata产品工程高级副总裁

It was a year of fast-moving discussions around the modern data stack. Lots of new vendors popped up, and major ones like Snowflake and Databricks continue their journey to take over many technical components, despite the challenging economic situation. But at the same time, voices emerged who questioned the modern data stack as such, whose decoupled approach often leads to many tools and high costs, let alone the complexity of getting it all together. The discussions around the ‘postmodern data stack’ (as just one out of many terms) were started, and we’re all eager to see where this will lead us in the coming years. – Chris Lubasch, Chief Data Officer (CDO) & RVP DACH, Snowplow  

这是围绕现代数据堆栈快速讨论的一年。许多新的供应商冒了出来，像Snowflake和Databricks这样的主要供应商继续他们的旅程，接管了许多技术组件，尽管经济形势充满挑战。但与此同时，出现了质疑现代数据堆栈的声音，其解耦方法往往导致许多工具和高成本，更不用说将其组合在一起的复杂性了。围绕“后现代数据堆栈”（只是众多术语中的一个）的讨论已经开始，我们都渴望看到它在未来几年将引领我们。- Chris Lubasch，Snowplow首席数据官（CDO）兼RVP DACH

2023 will be put up or shut up time for data teams. Companies have maintained investment in IT despite wide variance in the quality of returns. With widespread confusion in the economy, it is time for data teams to shine by providing actionable insight because executive intuition is less reliable when markets are in flux. The best data teams will grow and become more central in importance. Data teams that do not generate actionable insight will see increased budget pressure. – Alexander Lovell, Head of Product at [Fivetran](https://fivetran.com/)  

2023年将是数据团队成立或关闭的时间。尽管回报的质量差异很大，但各公司仍保持在IT方面的投资。随着经济中普遍存在的混乱，现在是数据团队通过提供可操作的洞察力来发挥作用的时候了，因为当市场处于波动状态时，高管直觉不太可靠。最好的数据团队将会成长，并变得更加重要。无法产生可操作洞察力的数据团队将面临更大的预算压力。- 亚历山大Lovell，Fivetran产品主管

Metadata Will be Driven by Data Lineage. Metadata is the most notable data strategy trend today. However, it’s not just about collecting metadata, but unlocking its power through activation. Data lineage is the foundational type of metadata, with the ability to deliver the most powerful benefits. When done right, it can enable automated and intelligent data management practices. – VP of Research and Education at MANTA, Jan Ulrych  

元数据将由数据谱系驱动。元数据是当今最显著的数据战略趋势。然而，这不仅仅是收集元数据，而是通过激活来释放其力量。数据沿袭是元数据的基本类型，具有提供最强大优势的能力。如果做得正确，它可以实现自动化和智能化的数据管理实践。曼塔研究和教育副总裁Jan Ulrych

In 2023, I expect Data Creation to go big! There will be a rise of the ‘data product manager’ and ‘data product management’ as the key persona/key skill sets required to treat data as a product, design and implement the right data contracts (as part of data products) and the enablement of organizations to build out a ‘data mesh.’ Furthermore, I expect more organizations to build operational (including real-time) use cases on top of cloud data warehouses and data lakes, supported by better tooling from the core vendors (e.g. Databricks and Snowflake) and companies in the ecosystem. Finally, I predict there will be more thoughtful approaches/technology architectures for managing the tension between data democratization and data compliance for personally identifiable data. Increased focus on measuring ROI on data investments. – Yali Sassoon, Co-Founder, Snowplow  

在2023年，我期待数据创造会变得更大！“数据产品经理”和“数据产品管理”将成为将数据视为产品、设计和实施正确的数据合同（作为数据产品的一部分）以及使组织能够构建“数据网格”所需的关键人物/关键技能集。此外，我希望更多的组织能够在云数据仓库和数据湖之上构建可操作的（包括实时的）用例，并得到核心供应商提供的更好工具的支持（例如Databricks和Snowflake）和生态系统中的公司。最后，我预测将有更周到的方法/技术架构来管理个人身份数据的数据民主化和数据合规性之间的紧张关系。更加注重衡量数据投资的ROI。- Yali Sassoon，Snowplow联合创始人

Iteration Replaces Big-Bang: For large-scale modernization projects with high complexity, business leaders might be looking for the “easy button” but CTOs and software architects know that the reality is much different. Carving out microservices from a monolith is an iterative process often requiring refactoring and replatforming. Unless your application is fairly simple, the “one-at-a-time” approach is the recommended path to ensure success and manage risk – and actually increase project velocity. Trying to do too much at once or attempt a “big-bang” modernization or re-write is why most app modernization projects fail, sputter, or just fizzle out. This is not necessarily as slow-and-steady as it seems, as iteration builds velocity that will outpace any massive undertaking in short order. –  [vFunction](https://vfunction.com/) Chief Ecosystem Officer, Bob Quillin 

The rise of the Data Processing Agreement (DPA): How organizations process data within on-premises systems has historically been a very controlled process that requires heavy engineering and security resources. However, using today’s SaaS data infrastructure, it’s never been easier to share and access data across departments, regions, and companies. With this in mind, and as a result of the increase in data localization/sovereignty laws, the rules as to how one accesses, processes, and reports on data use will need to be defined through contractual agreements – also known as data processing agreements (DPA). In 2023, we’ll see DPAs become a standard element of SaaS contracts and data sharing negotiations. How organizations handle these contracts will fundamentally change how they architect data infrastructure and will define the business value of the data. As a result, it will be in data leaders’ best interest to fully embrace DPAs in 2023 and beyond. These lengthy documents will be complex, but the digitization of DPAs and the involvement of legal teams will make them far easier to understand and implement. – Matt Carroll, Co-founder & CEO, Immuta

For the past few years, big data has been framed as a technology that will disrupt diverse industries. However, big data has spiked in adoption thanks to advancements in metadata-driven data fabric, AutoML and the ever-growing variety of data. Data technology communities began discussing metadata-driven data fabric in 2022. Since active metadata-assisted automated functions in the data fabric reduces human effort while improving data utilization, this technology will gain significant traction in 2023. The data fabric listens, learns and acts on metadata or “data in context,” which helps users access contextual information.  One of the key strategic differentiators will be having access to contextual data. Machine learning (ML) will become more accessible to non-experts over the next year thanks to AutoML. This is a class of ML algorithms that helps automate the designing and training of a ML model. ML models are created by the algorithms built by humans. Many organizations now either have in-house talent or partners that have delivered successful big data driven solutions. These well-documented success stories coupled with more efficient analytical techniques have resulted in commercial outcomes becoming increasingly essential filters in big data projects. Consequently, in 2023, we expect to only rarely come across big data projects that use R&D budgets. – Raj Bhatti, SVP, Client Solutions at Cherre

Data Complexity Will Increase: The nature of data is changing. There are both more data types and more complex data types with the lines continuing to blur between structured and semi-structured data. At the same time, the software and platforms used to manage and analyze data are evolving. A new class of purpose-built databases specialize in different data types—graphs, vectors, spatial, documents, lists, video, and many others. Next-generation cloud data warehouses must be versatile—able to support multimodal data natively, to ensure performance and flexibility in the workloads they handle. The Ocient Hyperscale Data Warehouse, for example, supports arrays, tuples, matrixes, lines, polygons, geospatial data, IP addresses, and large variable-length character fields, or VARCHARs. The need to analyze new and more complex data types, including semi-structured data, will gain strength in the years ahead, driven by digital transformation and global business requirements. For example, a telecommunications network operator may look to analyze network metadata for visibility into the health of its switches and routers. Or an ocean shipping company may want to run geospatial analysis for logistics and route optimization. – Chris Gladwin, CEO and Co-founder of [Ocient](https://www.ocient.com/) 

Big data isn’t dead (yet): Providers will attempt to get ahead trends, and we will see many start to advertise that “Big data is dead.” Instead, many organizations are leaning into “smart data” for greater insights. But despite the advertisements, big data will continue to play an important role in business operations — for now. The key is to make sure you have easy to use, self-service tools in place that enable cleansing, verifying, and prepping of the data that can then be plugged into a data analytics model for valuable results and smart decisions. The companies that turn their big data into smart data will be the ones that will benefit from the new ways of thinking about data. – Christian Buckner, SVP, Data Analytics and IoT, Altair

In the coming year we will, unfortunately, start to see the industry backsliding into another era of vendor lock-in. Just as the cloud is becoming the center of business, companies are at risk of having limited access to their own data because they’re locked into closed vendor ecosystems, which limits the flexibility and creativity needed to maximize driving value from their data. Businesses whose data is locked in will not be as agile in reacting to market conditions and building new apps and services needed to meet customer demands. And of course, lock-in will also prove problematic for businesses because it will limit their ability to shop around for the best competitive pricing. It will be imperative for companies to invest in open data ecosystems to ensure they can quickly change strategies to keep pace with changing markets. – Gerrit Kazmaier, Vice President & General Manager for Database, Data Analytics & Looker, Google 

Moving to a metadata mindset: Metadata-based data management emerges from the shadows: Metadata is emerging as a vital component of data management as organizations look to accelerate the time to value of their data, optimize costs, and comply with the ever-evolving landscape of industry and governmental regulations. In 2023, the role of metadata in the data ecosystem will continue to grow, spurred by more organizations shifting to the cloud, and a growing interest in data discovery, governance, virtualization, and catalogs, as well as the need to speed up data delivery through the automation of data pipelines and warehouse automation. However, metadata is still often overlooked and understated in data analytics and data management. Businesses should take heed, as this alone could sabotage your data management strategy. When it comes to good quality data, metadata is the foundation. Simply put, metadata is data that provides information about other data so that it can be more easily understood and used by the organization. It answers the who, what, when, where, why, and how questions for data users. Metadata management also plays a large part in supporting data governance programs. With the recent influx of new regulatory compliance laws, businesses are increasingly investing in data governance programs to help securely manage their data assets. Metadata and metadata management can support these efforts by providing the foundation for identifying, defining, and classifying data. And with data quality standards established, metadata management can ensure that the necessary regulatory controls are applied to the corresponding data. As we look ahead, we encourage modern enterprise teams to embrace a metadata mindset, and we expect a new wave of metadata management tools and best practices to be a focal point in the market. – Jens Graupmann, SVP of product & innovation, [Exasol](https://www.exasol.com/)

The need for on the ground data excavators will become increasingly more important as vital information gaps grow wider and wider in “Data Dark” Parts of the World, especially where investment opportunities are plentiful. For example, the projected growth of African markets signals an increase in the production capacity of economies across the continent. Therefore, the demand for data will significantly increase to enable investors and businesses to capitalize on this increase in output. – Joseph Rutakangwa, co-founder and CEO of [Rwazi](https://rwazi.com/)

Global data creation is expected to continue to grow in the new year, [nearly doubling by 2025](https://urldefense.com/v3/__https:/www.statista.com/statistics/871513/worldwide-data-created/__;!!I6-MEfEZPA!Jy2U044BzrrLMyMv7nFvCFHlkI4pjDGuDBI15m6ham9EqO6z1jhhS2i55rpdr-4jt7NdAwEJv2XcdqkGtLBXiq9AnpETtMIc504$). For savvy businesses, this presents an incredible opportunity if they find new ways to leverage this wealth of data to make smarter and faster decisions. We can expect successful data-driven enterprises to focus on several key AI and data science initiatives in 2023, in order to realize the full value of their data and unlock ROI. These include: (i) Productizing data for actionable insights, (ii) Embedding automation in core business processes to reduce costs, and (iii) Enhancing customer experiences through engagement platforms. The key to success will be underpinning these characteristics with data that is accurate, consistent, and contextual. For example, higher-quality data provides better fuel for training machine learning applications and programs which translates into greater efficiency for MLOps and AIOps.  Also, focusing data engineering efforts to improve consistencies in how data is standardized, labeled, and delivered can unlock greater collaboration and productivity with domain experts. Data integrity will be integral for fueling the top data initiatives of 2023. – [Precisely](https://www.precisely.com/)’s Chief Product Officer, Anjan Kundavaram

APIs will drive democratization of data: APIs make it easy to adjust, transform, enrich and consume data – traditionally there was a need for hundreds of highly paid engineers to manage the data and data scientists were needed to understand algorithms. In 2023, we will see a shift towards APIs technologies managing data as a way to gain insights and also control data related costs which means people will no longer need to have highly developed engineering skills to harness the power of data. – [Rapid](https://rapidapi.com/)’s CEO and founder Iddo Gino

The data mindset will shift to real time. Many businesses use Apache Kafka to send data to traditional systems like data warehouses or databases for processing, essentially treating data streams like static data. In the next year, we will see more developers make use of data streams in their real-time form. Expect to see direct lines into more machine learning, analytics, and business applications as companies take advantage of real-time data. – Chad Verbowski, Senior Vice President of Engineering, [Confluent](https://www.confluent.io/)

In 2023 IT leaders and organizations are going to rely even more heavily on data. Making informed data-driven decisions is more crucial than ever, as companies navigate economic uncertainty and brace for a recession. Having data to inform purchase or renewal decisions around the tools and technologies employees use, can help businesses cut back on costs while actually improving efficiencies and overall agility. Companies today drastically overspend on cloud applications without even realizing it. For many organizations the number of SaaS subscriptions in use is three to six times higher than IT leaders think. Organizations will invest in solutions that automatically collect, normalize, and analyze data about SaaS tools, costs, usage, and savings opportunities, so that they can evaluate which apps to prioritize, which to get rid of, and how to right-size contracts to match app utilization. It’s more important than ever for IT leaders to use data to safeguard organizations against economic uncertainty, deliver value, and eliminate inefficiencies, risk and wasted spend. – Uri Haramati, Founder and CEO of [Torii](https://www.toriihq.com/)

The year big data becomes accessible: Most companies now understand the value of data as an asset, but many still struggle to unlock its true value. Trying to do so has partly driven the growth in managed Database-as-a-Service and/or Data-Management-as-a-Service that reduce complexity. 2023 will see the next step in this process, with an onset of data visualization platforms and tools being adopted by the C-suite, to better understand big data and use it to make better-informed decisions. – Heikki Nousiainen, CTO and co-founder at Aiven

Data Streaming: This year, the concept of data as a product will become more mainstream. Across many industries, data streaming is becoming more central to how businesses operate and disseminate information within their companies. However, there is still a need for broader education about key data principles and best practices, like those outlined through data mesh, for people to understand these complex topics. For people creating this data, understanding these new concepts and principles requires data to be treated like a product so that other people can consume it easily with fewer barriers of access. In the future, we expect to see a shift from companies using data pipelines to manage their data streaming needs to allowing this data to serve as a central nervous system so more people can derive smarter insights from it. – Danica Fine, senior developer advocate at Confluent  

数据流：今年，数据作为产品的概念将更加主流。在许多行业中，数据流对于企业如何在其公司内运营和传播信息变得越来越重要。然而，仍然需要对关键数据原则和最佳实践进行更广泛的教育，例如通过数据网格概述的那些，以便人们理解这些复杂的主题。对于创建这些数据的人来说，理解这些新概念和原则需要将数据视为产品，以便其他人可以轻松地使用它，而访问障碍更少。在未来，我们希望看到公司从使用数据管道来管理其数据流需求，转变为允许这些数据作为中枢神经系统，以便更多的人可以从中获得更明智的见解。- Danica Fine，Confluent高级开发人员倡导者

Open Source: Digital Transformation of Traditional Industries: I believe that open source and open systems will become even more critical over the next year. In particular, traditional industries like manufacturing in the United States will look to open systems to rebuild infrastructure to become more modern, cost-effective, and globally competitive. Open systems will allow traditional industries not to be locked in by legacy vendors and allow them to be on the pulse of cutting-edge tools and technologies like AI, ML, AR, and more. It will remove the data silos allowing data to be shared easily internally or with outside partners for better analysis. I predict that there will be two ways that this transformation will happen. First, through embracing the cloud. Cloud-based open systems engineers will be able to share data easier and take full advantage of modern data processing, analytics tools, and the elasticity of cloud to reduce operating costs. Additionally, democratizing infrastructure by embracing open-source projects will open traditional industries like manufacturing and automation to a larger developer community ecosystem. – Jeff Tao, Founder and CEO of [TDengine](http://www.tdengine.com/)  

开放源代码：传统产业数字化转型：我相信开源和开放系统在明年将变得更加重要。特别是，美国制造业等传统行业将寻求开放系统来重建基础设施，以变得更加现代化、更具成本效益和全球竞争力。开放系统将允许传统行业不被传统供应商锁定，并允许他们掌握AI、ML、AR等尖端工具和技术的脉搏。它将消除数据孤岛，使数据在内部或与外部合作伙伴轻松共享，以便更好地进行分析。我预测，这种转变将有两种方式发生。首先，拥抱云。基于云的开放系统工程师将能够更容易地共享数据，并充分利用现代数据处理、分析工具和云的弹性，以降低运营成本。 此外，通过采用开源项目实现基础设施的民主化，将使制造业和自动化等传统行业向更大的开发者社区生态系统开放。 - Jeff Tao，TDengine创始人兼首席执行官

Freedom and flexibility will become the mantra of virtually every data management professional in the coming year. In particular, data management professionals will seek data mobility solutions that are cloud-enabled and support data migration, data replication and data synchronization across mixed environments including disk, tape and cloud to maximize ROI by eliminating data silos. We will likewise see an uptick in solutions that support vendor-agnostic file replication and synchronization, are easily deployed and managed on non-proprietary servers and can transfer millions of files simultaneously – protecting data in transit to/from the cloud with SSL encryption. – Brian Dunagan, Vice President of Engineering, [Retrospect](http://www.retrospect.com/)  

自由和灵活性将成为未来一年几乎每一位数据管理专业人士的口头禅。特别是，数据管理专业人员将寻求支持云计算的数据移动解决方案，并支持跨混合环境（包括磁盘、磁带和云）的数据迁移、数据复制和数据同步，以消除数据孤岛，最大限度地提高投资回报率。我们同样会看到支持与供应商无关的文件复制和同步、在非专有服务器上轻松部署和管理、并且可以同时传输数百万个文件的解决方案的增长-通过SSL加密保护在云传输中/从云传输中的数据。- Brian Dunagan，Retrospect工程副总裁

Governments will need to go beyond the data and focus on how it can be used to support storytelling so they can present data in more profound and impactful ways. Data alone doesn’t motivate people to take action, but a story can inspire action. Storytelling encourages user-centric thinking and helps governments work toward more innovative and connected solutions. – Cathy Grossi, vice president, product management at [Accela](https://www.accela.com/)政府需要超越数据，专注于如何利用数据来支持讲故事，以便以更深刻、更有影响力的方式呈现数据。数据本身并不能激励人们采取行动，但一个故事可以激励人们采取行动。讲故事鼓励以用户为中心的思维，并帮助政府努力寻求更具创新性和互联性的解决方案。- Cathy Grossi，Accela产品管理副总裁  

The IT complexity of data storage, processing and analytics is reaching its breaking point: The current methods of storing and analyzing data have typically involved data warehouses and data lakes (i.e., originally using technologies like Hadoop).  With the advent of cloud computing, data lakes and warehouses have been able to move from on-premises to the Cloud to take advantage of scale economics (think Snowflake, Databricks, Azure Synapse, Amazon Athena to name a few).  All of the major cloud service providers now offer a set of robust data capabilities – storage, technical meta-data management, pipelines, warehousing, data science workbenches, etc. The challenge is that in most large enterprises, data is now being copied and proliferating into multiple disparate on-prem data marts and data lakes across multiple cloud providers. The more data is being copied, the greater the risk of data fidelity, integrity and quality issues, along with risk of data leakage and cybertheft. The latest technology innovations to try and manage data across all of these new environments include data fabrics, or data meshes. However, data fabrics are only exacerbating the complexity of the data estate. New technologies will emerge which will get to the core of data reusability and dramatically change the landscape and conversation.  This will be more of a return to better, smarter uses of reusable ‘Small Data’ components versus continuing to proliferate more and more ‘Big Data.’ – Eliud Polanco, the president of [Fluree](https://flur.ee/)  

数据存储、处理和分析的IT复杂性正达到极限：存储和分析数据的当前方法通常涉及数据仓库和数据湖（即，最初使用Hadoop等技术）。随着云计算的出现，数据湖和仓库已经能够从本地转移到云，以利用规模经济的优势（想想Snowflake，Databricks，Azure Synapse，Amazon Athena等等）。所有主要的云服务提供商现在都提供了一套强大的数据功能-存储、技术元数据管理、管道、仓储、数据科学工作台等。挑战在于，在大多数大型企业中，数据现在正在被复制并扩散到多个云提供商之间的多个不同的本地数据集市和数据湖中。复制的数据越多，数据保真度、完整性和质量问题的风险就越大，沿着数据泄露和网络盗窃的风险也就越大。 在所有这些新环境中尝试和管理数据的最新技术创新包括数据结构或数据网格。然而，数据结构只是加剧了数据资产的复杂性。新技术将出现，这些技术将触及数据可重用性的核心，并极大地改变环境和对话。这将更多地回归到更好、更智能地使用可重用的“小数据”组件，而不是继续增加越来越多的“大数据”。- Eliud Polanco，Fluree公司的总裁

Real-time data processing: Data Platforms: For Enterprise business applications, user responsiveness is a major factor that determines customer behavior, retention, and loyalty. All modern digital interactions are going to be seamless, B2B and B2C users expect real-time responses to their requests and transactions. These digital interactions are typically small transactions, but it needs modern data platforms for storing and processing billions of objects at scale. Data Platforms and their infrastructure should evolve fast enough to deal with the present & future needs of enterprises by adopting real-time data processing at the economics of scale. – Tony Afshary, Global VP of Products and Marketing, [Pliops](https://pliops.com/)  

实时数据处理：数据平台：对于企业业务应用程序，用户响应能力是决定客户行为、保留率和忠诚度的主要因素。所有现代数字交互都将是无缝的，B2B和B2C用户期望对其请求和交易的实时响应。这些数字交互通常是小型交易，但它需要现代数据平台来大规模存储和处理数十亿对象。数据平台及其基础设施应快速发展，以通过采用规模经济的实时数据处理来应对企业当前和未来的需求。- Tony Afshary，Pliops产品和营销全球副总裁

Data quality determines success: Over the past few years, many companies have made significant strides to accelerate their CX initiatives, but most are only now realizing the success of these programs is reliant on the quality of their data. This data can be sourced through solicited customer feedback, like surveys, or unsolicited feedback, like the conversations that happen in contact and customer service centers. In 2023, transcription accuracy of omnichannel customer-brand interactions will transition from a “nice-to-have” to a critical capability. The most successful organizations in the coming year will be the ones who understand the direct correlation between transcription accuracy and the quality of customer insights, and then use that better intelligence to drive even greater CX value. – Eric Williamson, CMO of [CallMiner](http://eric%20williamson%2C%20cmo%20of%20callminer%2C/)

Data Projects Face Prioritization: Market conditions will impact data projects, but not stop them. The trajectory toward leveraging data for business insight and advantage won’t be reversed despite reduced funding or revenue. In fact, it can’t. The need to eke out every little bit of profit, revenue and cost savings from the business requires data. But you’ll have to prioritize. If you have an ongoing data quality project, a data security project, and a BI or Analytics project, you’ll need to decide which is a “must have”, which is a “should have” and which is really a “nice to have.” The balance will start to tip toward security as the “must have” as it’s foundational to enable the other projects. – James Beecham, founder and CEO, [ALTR](http://www.altr.com/)

The synergy between structured and unstructured data: Despite the exponential growth of unstructured data, structured data will still carry substantial value in the future. And it’s almost inevitable for organizations to deal with both structured and unstructured data simultaneously to realize maximum business growth. Incumbent solutions originally engineered to deal with structured data for traditional data analytics can extend their processing capabilities to unstructured data through plug-ins, like “native vector search” in ElasticSearch 8.0 and “vector similarity search” in Redis 6.0. For AI applications known for intensive unstructured data, that’s where a purpose-built solution like vector databases shines, complemented with the hybrid search functionality that supports filtering based on tags, attributes, etc. – Frank Liu, Director of Operations at [Zilliz](https://zilliz.com/)

CIOs, chief data officers, and data managers will need to confront the cost of modernization: Modernization and digital transformation involve many long-term initiatives like migrating major systems to the cloud or constantly integrating existing data and systems in order to meet business process needs. These can be high-cost initiatives, but are more and more necessary in today’s digital world. To minimize the risks of failures with these initiatives, executives should look for ways to balance their long-term vision with the short-term ROI of modernization, like working with a data integration platform or automating the integration process. – Rajesh Raheja, Chief Engineering Officer, Boomi

Data will be the center of collaboration for organizations: We live in a data-rich environment with most companies sitting on an excess of data. But as much data as businesses have, there’s usually a lack of access to it because everything is siloed and owned by various stakeholders and departments spread across the organization. In 2023, we’ll see these data silos start to break down as companies move towards digital workplace tools, which offer a single place to get work done. In the digital workplace, teams can easily access and bring multiple data sources together to get a full-picture overview into their business–and make more informed decisions because of it. While decisions have long been ruled by the highest-ranking official or loudest person in the room, we’ll see data opening dialogue between team members and lending itself to fresh ideas. When data becomes the center of team communications, collaboration will increase and teams will drive smarter, more-informed decisions for the business. – Dean Guida, Founder of Slingshot & CEO of [Infragistics](https://www.infragistics.com/)

Enterprises are facing an issue when it comes to data. Insights generated by the data are not translated quickly enough and it takes so long to process and analyze it that when the insights are finally in hand, it’s often too late to act upon them. DataOps the application of agile engineering and DevOps best practices to data management, which promises to improve the success rate of data and analytics initiatives.  This is a process-oriented, automated, and collaborative approach to designing, implementing, and managing data workflows and a distributed data architecture. In 2023 we are seeing more companies recognize the value of data, implementing DataOps strategies and becoming data-driven businesses. Those that have begun that process will start to see a reduction in the number of times data is causing exceptions in applications (and vice versa) and an improvement in the ability to deliver data projects on time. With these improvements organizations will be able to build quality and trust back into the modern data environment while also improving data quality, trust, and positive business outcomes. – Ram Chakravarti, Chief Technology Officer at [BMC Software](https://www.bmc.com/)

In 2023, the most successful data people won’t be judged just on their knowledge of SQL, Tableau, or dbt. Instead, they’ll be measured by their impact on the business at large. This is a discipline data practitioners have largely struggled with in the past, but in a challenging economy, demonstrating ROI is everything. I hear many of my peers talk about the importance of business people being data literate, but I believe this is the year that we see more data people become business literate. Data scientists, analysts, engineers, and stewards are as essential to business outcomes as anyone in marketing, finance, or sales. After all, they deliver the raw material and dashboards that spark insight. When data people understand how the business operates, makes money, reduces risk, and drives innovation, they take greater pride in their work and focus on the metrics that the business cares most about. – Juan Sequeda, Principal Scientist at data.world

**Chatbots** **and Conversational AI**

Is Conversational AI becoming to human-like? Technologies like natural language processing/generation (e.g. GPT-3, BERT, etc) are becoming more and more powerful. As they do so, conversational AI is evolving to support more human-like relationships. This will lead companies to thinking through the ethical implications of building [conversational AI](https://www.accenture.com/_acnmedia/PDF-181/Accenture-POV-Ethics-Final.pdf#zoom=40) tools along three questions: 1. Does the conversational AI have a human-looking avatar that might embed stereotypes? 2. Does it set out to understand the human user? 3. Does it behave like a human in a way that changes the relationship with the end user? – Accenture

Virtual agents will become the experience integration hub for employees. As conversational AI, ML, and NLP capabilities expand, virtual agents will be able to resolve more complex issues and meet employees where they are to become the experience integration hub. Looking ahead, virtual agents will continue to evolve from automating the resolution of tier 1 service desk agents (password resets, questions on PTO, etc.), to resolving much more complex issues that historically required higher skilled IT staff. This will not only be critical to the journey of upleveling employee self-help, but also to reduce costs during uncertain economic conditions. Automation will be used to upskill current teams so leaders don’t have to mine for technical expertise. – Pat Calhoun, CEO and founder of [Espressive](https://www.espressive.com/)

Chatbots will chat less and answer questions more. Humans don’t want to spend more time interacting with machines as if they were talking to people; they really just want their questions answered quickly and efficiently from the start without lengthy wait times or having to choose from a myriad of options. Although many chatbots accurately execute the specific tasks they were designed to do, they fall far short of end-user expectations because they rarely answer their actual questions. In 2023, organizations will finally be able to complement chatbots with Natural Language Search capabilities. Because Natural Language Search understands human language and can process unstructured text-based data (documents, etc.) individuals can phrase questions using their own words–as if they were speaking to a person– and receive all the relevant answers back instantly. – Ryan Welsh, Founder and CEO of [Kyndi](https://www.kyndi.com/)

AI-powered surveys will change the customer feedback game: We’ll see attention shift beyond simply delivering strong customer experiences to how well each of those experiences are perceived by the consumer. Thanks to AI and a wealth of rich chat, SMS and WhatsApp messages showing the cadence of customer and agent conversations, as opposed to stop/start email interactions, organizations will get smarter and more sophisticated feedback. AI-powered surveys that dynamically morph to get maximum feedback from customers based on prior responses, will reshape the customer feedback game and textual analysis will be able to pull together a much more integrated sense of how customers feel. – Colin Crowley, CX Advisor at [Freshworks](https://www.freshworks.com/)

Over the last several decades, the value of automation has largely been derived from using robotics to replicate human actions and eliminate laborious, repetitive tasks. This coming year, I predict we’ll witness a significant expansion beyond robotics to intelligent automation, which uses artificial intelligence and analysis to carry out data-driven tasks with very little human interaction. This enablement shifts reliance off humans and onto technology, so workers can focus their attention on other areas of the business. As more businesses adopt this newer structure, they’ll find greater efficiencies in everyday tasks across their organization. Imagine streamlining hundreds of processes and decisions—everything from prioritizing employee work tasks, to determining the products stocked on shelves, to automating customer contact—with the push of a button. The possibilities and opportunities are endless for optimizing workflows and reducing costs. – Srinivasan Venkatesan, Executive Vice President, U.S. Omni Tech, Walmart Global Tech

AI shopping assistants: Something I personally don’t enjoy is buying gifts for the holiday season (don’t judge!) –– the good news is, it won’t be long before AI comes to the rescue for people like me. Smart online shopping with AI assistants is right around the corner and will have the ability to suggest items that your kids, partner, or parent will love, all while making unique recommendations based on the person you’re shopping for. It’s all about automation simplifying our lives. – David Ly – CEO and founder of [Iveda](https://www.iveda.com/)

AI Assistants Meet the Data Professional: AI assistants finally seem ready to be useful for data professionals. GitHub Copilot routinely writes code in a way that seemed impossible a decade ago, while OpenAI Codex is able to plainly understand and explain code. Every data professional knows the pain of issuing simple queries and aggregates against a database, or counting records looking for a discrepancy, or generating charts for a presentation. By handing these simple-in-theory but nuanced and idiosyncratic tasks over to an AI assistant, data professionals can free their time and focus on problems that truly deserve intelligence. – from [Prefect](https://www.prefect.io/) CEO and Founder, Jeremiah Lowin

The chatbot evolution is upon us: We’ll continue to see advancements with AI technology like Open AI to drive independent human interaction and AI training itself to better adapt to human responses”, says Olga. “In the customer service space specifically, businesses will forego the method of human interaction to allow AI technology to take the place of call centers and human operators. –  VP of AI and Machine Translation at Smartling

By this time next year, a new kind of conversational AI will be breaking away from the awkward pauses and turn-taking that can make voice interfaces feel robotic. Voice AI will also be more proactive, noting the context of a situation and using it to make helpful suggestions. The test ground for this technology will be the restaurant space, and as it  transitions from the lab to the drive thru we’ll see that it’s ready for broad commercialization. Particularly in industries battling labor challenges and inflation – like restaurants. – Zubin Irani, CRO,  [SoundHound](https://www.soundhound.com/)

With the Natural Language Processing (NLP) Tech Boom, More Contact Centers Will Strategically Implement Conversational AI Bots: As companies shift contact centers to the cloud, AI comes baked into many cloud solutions such as Amazon Connect. This brings in an NLP component, which makes chatbots and interactive voice response (IVR) systems more intuitive and conversational. There’s been an explosion in NLP startups in the last year, not to mention Google’s release of LaMDA, a large language model for chatbot applications. At the same time, big tech companies like Microsoft, Google, Amazon and Salesforce are now investing in contact center solutions to sell to their enterprise customers. Deploying IVRs and chatbots powered by conversational AI allows companies to improve customer support and in turn, drive more value for the business. NLP enables bots to understand customer intent and uses that context to provide a better customer experience. Bringing AI into the contact center also increases the speed and volume at which customers are helped, reducing wait times and requiring less live phone calls with agents. More satisfied customers means higher retention and less revenue lost from customer churn. So now, the contact center is strategic. – James Isaacs, President of [Cyara](https://cyara.com/)

Today’s customers look for highly flexible communication, and they don’t want to be restricted by pre-defined experiences. They are looking for conversations with businesses that can switch between modes and channels to deliver more immersive and engaging experiences. The key to this is multiexperience, which is all about creating seamless and simple experiences across apps, digital touchpoints, and interaction modalities. In 2023, businesses would need to adapt a strategy that would be equipped with the ability to drive automation across different modalities, be it voice or chat or across web or social, as well as across channels, be it WhatsApp or Instagram. And Conversational AI-powered Dynamic agents would be key to delivering the much-sought multiexperience. Additionally, conversational commerce will see increased demand and adoption, becoming a non-negotiable element in every brand’s marketing, sales, and customer support strategies. When it comes to channels, voice emerged as a prominent channel of communication between customers and businesses in 2022. Next year, the focus will be on making voice AI more human. As users demand more human-like, hyper-personalized experiences while interacting with voice AI agents, 2023 will see the industry working towards achieving this feat. Voice AI agents will only become more mainstream if synthetic monotones are completely replaced by conversational human tones. There will also be a quicker transition from analogue voice in telephony to digital voice, which will eventually lead to voice interactions supplemented by video. – Raghu Ravinutala, CEO & Co-founder, [Yellow.ai](http://yellow.ai/)  

今天的客户寻求高度灵活的沟通，他们不希望受到预定义体验的限制。他们正在寻找与企业的对话，这些企业可以在模式和渠道之间切换，以提供更身临其境和引人入胜的体验。实现这一目标的关键是多体验，即跨应用程序、数字接触点和交互方式创建无缝而简单的体验。到2023年，企业将需要调整一种战略，该战略将具备在不同模式下推动自动化的能力，无论是语音或聊天，还是网络或社交，以及跨渠道，无论是WhatsApp还是Instagram。对话式人工智能驱动的动态代理将是提供人们寻求的多重体验的关键。此外，对话式商务的需求和采用将增加，成为每个品牌的营销、销售和客户支持策略中不可谈判的元素。 在渠道方面，语音在2022年成为客户与企业之间的重要沟通渠道。明年，重点将是让语音AI更人性化。随着用户在与语音AI代理交互时需要更多类似人类的、超个性化的体验，2023年该行业将努力实现这一壮举。只有当合成的单调声完全被对话的人类音调所取代时，语音AI代理才会变得更加主流。电话中的模拟语音也将更快地过渡到数字语音，这将最终导致视频补充的语音交互。- Raghu Ravinutala，Yellow首席执行官兼联合创始人。艾

Next-gen conversational AI solutions that can understand the context and hold dialogues like a human are starting to kill the scripted chatbots that only frustrate users: End users don’t want to get on the phone with someone if they can avoid it. They want tech on their side to help them solve problems and answer questions in the moment while still experiencing an interaction that feels like they are talking to a human. Companies cannot offer this level of personalization at scale unless they use technology—and the right tech at that. The conversation has to feel natural and follow the customer’s needs, not the businesses’. That means scripted chatbots with rigid rules won’t cut it. Chat must be equipped with Natural Language Processing technology that can understand incoming messages, respond appropriately and take proper action to truly meet customer expectations and generate revenue. – Jim Kaskade, CEO of [Conversica](https://www.conversica.com/)  

下一代对话式AI解决方案可以理解上下文并像人类一样进行对话，它开始杀死那些只会让用户感到沮丧的脚本聊天机器人：最终用户不想与某人通电话，如果他们可以避免的话。他们希望技术能够帮助他们解决问题并在当下回答问题，同时仍然体验到一种感觉像是在和人说话的互动。公司不可能大规模提供这种程度的个性化，除非他们使用技术--而且是正确的技术。谈话必须让人感觉自然，并遵循客户的需求，而不是企业的需求。这意味着有严格规则的脚本聊天机器人不会削减它。聊天必须配备自然语言处理技术，能够理解传入的消息，做出适当的响应并采取适当的行动，以真正满足客户的期望并产生收入。- Jim Kaskade，Conversica首席执行官

**Cloud 云计算**

Hybrid Cloud. I look at hybrid cloud deployments as deployments that have significant production usage in both cloud and data centers. These typically arise where each location (cloud & data center) possess tools or requirements that are uniquely satisfied by something contained therein. Think about data location requirements or unique hardware for data centers, or using tools like BigQuery or Cloud Dataflow in Google Cloud. While we’ve made incremental steps towards true hybrid cloud over the years, hybrid cloud deployment patterns are still in their infancy. This is primarily because the tooling is all relatively new to consumers. However, I expect this to change next year. I think this primarily because I think the tooling, primarily led by the increasing maturity of Anthos, to be at a tipping point where companies will start really investing in hybrid deployments. – Peter-Mark Verwoerd, Associate CTO, [SADA](https://sada.com/)  

混合云。我将混合云部署视为在云和数据中心中都具有显著生产使用的部署。这些通常出现在每个位置（云和数据中心）都拥有由其中包含的东西唯一满足的工具或需求的情况下。考虑数据中心的数据位置要求或独特的硬件，或使用Google Cloud中的BigQuery或Cloud Dataflow等工具。虽然多年来我们已经朝着真正的混合云迈出了一步，但混合云部署模式仍处于起步阶段。这主要是因为这些工具对消费者来说都是相对较新的。不过，我预计明年这种情况会有所改变。我认为这主要是因为我认为主要由Anthos日益成熟的工具将处于一个临界点，公司将开始真正投资于混合部署。- Peter-Mark Verwoerd，SADA首席技术官

Hybrid computing is dead. Hybrid computing will cease to exist as everyone transitions to the cloud. Sales teams at Azure, AWS, and Google will continue to focus on moving legacy applications and organizations to the cloud because it’s where they make the most money, contributing to the death of hybrid computing. – Uma Chingunde, VP of Engineering at [Render](https://render.com/)  

混合计算已死。混合计算将不复存在，因为每个人都过渡到云。Azure、AWS和Google的销售团队将继续专注于将传统应用程序和组织迁移到云端，因为这是他们赚钱最多的地方，导致混合计算的死亡。- Uma Chingunde，Render工程副总裁

Prioritize a cloud-first strategy, not cloud-only: We are still working on reigning in cloud spend and where to appropriately place workloads. A few years ago, some believed on-premise hosting was dying, but this has not been the case. On-prem has a use and a purpose, and it works within a more traditional finance model. However, you need to do what works best for your industry, your skillset and your capacity. Migrating to the cloud or moving to on-prem to save money requires investment as both are niche expertise. Some organizations have completely shifted to the cloud, but we are currently in a hybrid world. Moving into 2023, companies must follow a cloud-first strategy, not a cloud-only strategy. – Jesse Stockall, Chief Architect at [Snow Software](https://www.snowsoftware.com/)  

优先考虑云优先战略，而不是仅考虑云：我们仍在努力控制云支出，以及在哪里适当地放置工作负载。几年前，一些人认为内部托管正在消亡，但事实并非如此。内部部署有用途和目的，它在更传统的金融模式中工作。然而，你需要做最适合你的行业，你的技能和能力的事情。迁移到云或迁移到本地以保存资金需要投资，因为两者都是利基专业知识。一些组织已经完全转向云计算，但我们目前处于一个混合的世界。进入2023年，企业必须遵循云优先的战略，而不是仅云战略。- Jesse Stockall，Snow Software首席架构师

Inflationary pressure will force major public cloud providers to reevaluate pricing and fee structures: Many organizations rely on public cloud service providers to help them “do more with less” and meet organizational requirements to store and analyze growing volumes of data with IT budgets that aren’t necessarily growing at the same rate. However, delivering on this expectation will become increasingly difficult for cloud providers in 2023, as inflationary pressures continue to rise. As a result, there’s a good likelihood that organizations will be met with service list price and fee increases as cloud hyperscalers seek to maintain margins. The simple fact is that $/GB rates for cloud storage have stopped trending down, and there have been no price reductions among leading providers since 2017. Between 2018-2022, instead of list-price reductions, many providers have introduced additional, lower-cost storage tiers (e.g., “cold” or “archive” tiers) as a way to help customers achieve ongoing cost reductions. But these new tiers require adoption, transfer of data, and new data lifecycle and management policies to realize these cost reductions. 2023 may mark the beginning of a new era of expectations when it comes to cloud infrastructure services pricing – and we expect organizations to heavily scrutinize the risk and impact of potential price changes from their cloud storage provider. – Andrew Smith, Senior Manager of Strategy and Market Intelligence, [Wasabi Technologies](https://wasabi.com/)

To the Cloud and Back Again: Enterprises will look to repatriate data from the public cloud to reduce their operating costs. Enterprises know they can reduce their costs if they can get their data back on-prem, particularly for data that need to be retained for long periods of time for compliance reasons. Digital data sources, including imagery and video, continue to grow exponentially, forcing organizations to confront the impracticality of relying on the public cloud for all of their data management and storage. Cost constraints, access control, data sovereignty, and longer-term retention of massive amounts of data will influence large enterprises to consider building their own low-cost storage cloud internally for access and use across the entire organization. – Tim Sherbak, Product Manager, [Quantum](http://www.quantum.com/)

As digital data repositories continue to grow, organizations are under increased pressure to optimize their IT infrastructures to take full advantage of the power of their data. Additionally, the concept of a cloud-first strategy for organizations is becoming more mainstream. These trends are driving the need for organizations to manage data at scale in single-cloud or multi-cloud architectures, raising new complex challenges regarding the management, usage and preservation of data stored in the cloud. The rise of modern multi-cloud and multi-location ecosystems provides agility and flexibility in data utilization across clouds and sites, where data, applications and workflows are accessible to drive more value from the data.  New tools, such as distributed multi-site, multi-cloud data management software, will help to unify and simplify data access, usage and placement across on-premises storage and multiple clouds. This will empower organizations to leverage cloud services no matter where data is created or stored for optimal productivity and collaboration. – Deanna Hoover, Director of Product Marketing for [Spectra Logic](http://www.spectralogic.com/)

Proper Data Protection in the Cloud will put Data Democratization Into Sharper Focus:  As positions across companies become more reliant on utilizing data in their daily roles, and with data primarily being protected in the cloud, there are more opportunities emerging for businesses to leverage data in ways they have not yet done before. More specifically, the cloud opened up the ability to leverage infinite compute, to democratize access to data in ways that could not be previously supported. Before the cloud, backup data protection meant locking up highly sensitive data, without being able to utilize it again, less threatening its security. Data stored on the cloud however, can stay protected and repeatedly accessed across an organization while remaining secure. For example, many businesses are now taking advantage of data lakes to warehouse large swaths of data that can go on to ultimately train artificial intelligence (AI) and machine learning (ML) models. This makes it necessary to protect both the original data source as well as the new data that is continuously generated from these models on a granular level.  The key here will be to execute incredibly well in regard to data protection on the cloud, in order for this to become a regular and effective practice. This dual use of data will revolutionize how businesses are able to interact with data to achieve their desired outcomes, while continuing to secure such data at all times. – Chadd Kenney, VP of Product, [Clumio](https://clumio.com/)

Continued AI breakthroughs due to increasing cloud options: The testing and experimenting with AI systems and machine learning tools to perform all aspects from everything between “art-to-documentation” to “code assistance”. These integrated innovations are truly driving more sophisticated intelligence into cloud systems which helps accelerate development, support, customer interaction and adaptive tooling.  Artificial intelligence and machine learning (AI/ML) is an exploding innovation which is pushing breakthrough services for the cloud. – Chris Chapman, CTO at [MacStadium](https://www.macstadium.com/)

**Database/Data Warehouse/Data Lake**

The Return of Data Modeling. In 2023, industry veterans who spent nearly a decade calling for thoughtfulness in building fundamental data infrastructure instead of rushing to build buzzworthy products will get their “I told you so” moment. Data modeling is making a comeback, alongside the realization that without the infrastructure to deliver high-quality data, businesses will not get very far towards the promise of predictive analytics, machine learning/AI, or even making truly data-driven decisions. – Satish Jayanthi, CTO and co-founder of [Coalesce](https://coalesce.io/)

Databases will Streamline the Tech Stack, Enabling DevOps to do More with Less. With today’s organizations dealing with massive amounts of data in an uncertain macro environment, they will continue to move away from relational databases to multi-model databases, which can handle different data types and models, including documents, graphs, and relational and key-value databases – all from a single, integrated backend. Multi-model databases provide unified data management, access, and governance. This speeds up time to market and lowers deployment and operational costs, saving resources at a time when budgets are tight. We’ll also see next-generation databases emerge that can seamlessly support both transactions and analytics for real-time business insights. No longer will businesses need a separate vendor solution for operational analytics. – Rahul Pradhan, VP of Product at [Couchbase](https://www.couchbase.com/)

In 2023 with rising economic concerns, we will see companies taking a deeper look at cloud data warehouse costs and becoming much more serious about cost control. Information on total cost of ownership is critical to effectively managing cost for data teams because driving down costs one at a time will undermine the efficacy of the whole system. The burden of proof shifts to data teams to demonstrate efficiency with total cost of ownership and that data insights are driving excess value to the business. – Alexander Lovell, Head of Product at [Fivetran](https://fivetran.com/)

Cloud databases will reach new levels of sophistication to support modern applications in an era where fast, personalized and immersive experiences are the goal: From a digital transformation perspective, it’s about modernizing the tech stack to ensure that apps are running without delay – which in turn gives users a premium experience when interacting with an app or platform. Deploying a powerful cloud database is one way to do this. There’s been a massive trend in going serverless and using cloud databases will become the de facto way to manage the data layer. In the next year, we will also see the decentralization of data as it moves closer to the edge to offer faster, more dependable availability. Additionally, we’ll start to see the emergence of AI-assisted databases to enable teams to do more with less. The proliferation of data will only continue, making AI-assisted databases a critical strategy to making the data lifecycle more operationally efficient for the business. – Ravi Mayuram, CTO, [Couchbase](https://www.couchbase.com/).

Enterprises move from traditional data warehouses to real time data storage: In 2023, we will continue to see movement away from traditional data warehousing to storage options that support analyzing and reacting to data in real time. Organizations will lean into processing data as it becomes available and storing it in a user-friendly format for reporting purposes (whether that’s as a denormalized file in a data lake or in a key-value NoSQL database like DynamoDB). Whether a manufacturer monitoring streaming IoT data from machinery, or a retailer monitoring ecommerce traffic, being able to identify trends in real time will help avoid costly mistakes and capitalize on opportunities when they present themselves. – Jay Upchurch, Executive Vice President and Chief Information Officer, SAS

The rise of the data lakehouse will lead to simplicity but will require a rethinking of data security and governance: Enterprises will increasingly migrate to the data lakehouse, which is a unified data platform for previously siloed workloads such as data engineering, warehousing, streaming, data science, and machine learning. Unifying these silos unlocks tremendous value for businesses, but also requires the organization to evolve to realize the full potential of the platform. Understanding that data remains one of the most valued assets within a business; forward-thinking enterprises will also be looking for simplicity by consolidating on a single vendor lakehouse architecture. Enterprises will evolve their teams and processes to adopt a secure, centralized management and governance model with the associated tooling for the data assets that span multiple workloads. – Fermín J. Serna, Chief Security Officer, Databricks

Open Lakehouse Will More Effectively Augment the Proprietary Cloud Enterprise Data Warehouse: As the architectural paradigm shift toward the lakehouse continues forward, the disaggregated stack will become more fully-featured data management systems; from disjoint components evolving into cohesive stacks that include metadata, security, and transactions. – Dave Simmon, Co-founder and CTO, [Ahana](http://www.ahana.io/)

In a multi-cloud world, object storage is primary storage : Right now, databases are converging on object storage as their primary storage solution. This is driven by performance, scalability and open table formats. One key advantage in the rise of open table formats (Iceberg, Hudi, Delta) is that they allow for multiple databases and analytics engines to coexist. This, in turn, creates the requirement to run anywhere – something that modern object storage is well suited for. The early evidence is powerful, both Snowflake and Microsoft will GA external tables functionality in late 2023. Now companies will be able to leverage object storage for any database without ever needing to move those objects directly into the database, they can query in place. – Anand Babu Periasamy, Co-founder and CEO at [MinIO](https://min.io/)

For years, data lakes held the promise of taming data chaos. Many organizations dumped their ever-growing body of data into a data lake with the hope that having all their data in one place will help bring order to it. But data lakes are overhyped and often lack proper governance. And without clean, curated data, they simply do not work. That’s why many organizations who implemented data lakes are realizing that what they actually have is a data swamp. Having clean, curated data is valuable. That’s a fact. But dirty data swamps are not and organizations must prioritize the importance of accurate and integrated data, develop a strategy of eliminating data silos, and make cleaning data everyone’s responsibility. – [Tamr](https://www.tamr.com/) Co-Founder and CEO Andy Palmer 

Standards-based Semantic Layers Will Power Data Selection through Business Terms: Data fabrics, data lakes, and data lake houses contain a surplus of unstructured and semi-structured data from external sources. In 2023 there will be a significant uptick in organizations applying W3C standards-based semantic layers atop these architectures, where data assets are described by metadata in familiar business terms and enable business users to select data through a lens of business understanding. This method will provide a seamless business understanding of data that fosters a culture of data literacy and self-service, while simplifying data integration and improving analytics. – Jans Aasman, Ph.D., an expert in Cognitive Science and CEO of [Franz Inc](https://franz.com/).

End in sight for legacy databases: 2023 will see an acceleration of the end for legacy databases. With the world moving towards real-time unified databases, speed has been an important differentiator, and legacy systems can’t keep up anymore with the real-time nature we are seeing in this digital services economy. We have seen this trend in industries like finance up until this point, but it’s now becoming apparent to business leaders across sectors that the digital revolution begins with the tech stack that holds your company together: the database. We are ushering in an era of unified, simple, modern data in real time. Without this, your company will likely not see 2024. – Shireesh Thota, SVP of Engineering, SingleStore

Organizations’ competitive advantage lies in being able to easily build intelligent, data-driven applications. This requires today’s developer to unlock and leverage data from both operational and analytical systems and infuse machine learning models into their applications. We believe in the coming years, the barriers between transactional and analytics workloads will disappear. Traditionally, data architectures have separated these workloads because each needed a fit-for-purpose database. Transactional databases are optimized for fast reads and writes, while analytical databases are optimized for aggregating large data sets. With advances in cloud-based data architectures that leverage highly scalable, disaggregated compute and storage with high-performance networking, we predict there will be new database architectures that allow both transactional and analytical workloads within one system without requiring applications to compromise on workload needs. – Andi Gutmans, Vice President & General Manager, Google Databases, Google

From centralized Hive catalog to open table formats in data lakes: With data lakes becoming the primary destination for a growing volume and variety of data, having a table format for data stored in a data lake is a no-brainer. More organizations now have realized that Hive catalogs have become the central bottleneck. In the cloud-native era, decentralized open data table formats are popular, especially in large-scale data platforms. In 2023, we can expect to see more enterprise data being stored in open table formats as Apache Iceberg, Hudi and Delta Lake are rapidly adopted. – Haoyuan Li, Founder and CEO, [Alluxio](https://www.alluxio.io/)

In 2023 with rising economic concerns, we will see companies taking a deeper look at cloud data warehouse costs and becoming much more serious about cost control. Information on total cost of ownership is critical to effectively managing cost for data teams because driving down costs one at a time will undermine the efficacy of the whole system. The burden of proof shifts to data teams to demonstrate efficiency with total cost of ownership and that data insights are driving excess value to the business. – Alexander Lovell, Head of Product at [Fivetran](https://fivetran.com/) 

Rise of the SQL: The most important language to learn isn’t Python; it’s SQL. Databases of all sizes are on a tear. Many workloads are moving to the cloud (and powerful cloud data warehouses in particular), finally reaching a tipping point as a combination of features and price make it difficult for any company to hold out. And when data is available locally, new in-memory databases like DuckDB make it possible to use advanced, SQL-based query engines from a laptop, from a serverless function, even from the browser itself. These ubiquitous SQL-based tools are crowding out yesterday’s heavily scripted approaches to data manipulation because they empower users to work with data where it sits, rather than have to extract it, manipulate it, and re-insert it. – [Prefect](https://www.prefect.io/) CEO and Founder, Jeremiah Lowin

Ushering an era of unified databases: 2023 is going to be the year of unified databases. Unified databases are designed to support large amounts of transactional and analytical workloads at the same time. This allows a simplified and flexible data architecture for companies to process massive workloads. In 2023, we will witness a convergence of specialized databases that will be built on four primary characteristics: distributed, shared-nothing architecture, cloud-native, multi-model and relational foundation. Organizations will need one platform to transact and reason with data in milliseconds in a hybrid, multi-cloud environment. 2022 saw many popular vendors move in this direction, and it will pick up a significant pace in the coming year. – Shireesh Thota, SVP of Engineering, SingleStore

The rise of hybrid “bring-your-own-database” (BYODB) cloud deployments: The benefits of moving certain data-driven projects to the cloud are undisputed — quicker deployment, reduced infrastructure and maintenance costs, built-in support and SLAs, and instant scalability when you need it. However, there will always be use case obligations that require keeping data on-premises, including performance, security, regulatory compliance, local development, and air-gapped hardware (to name a few). A more flexible solution is for modern data vendors to support hybrid “bring-your-own-database” (BYODB) cloud deployments in addition to the more common on-premises and fully-managed cloud service options. This new approach will catch on in the years ahead, allowing data to be kept in situ and unaltered but remotely connected to SaaS services that layer on top from nearby data centers. This provides all the benefits of the cloud, while still allowing for full authority and control over the company’s most precious resource… its data. _–_ Ben Haynes, co-founder/CEO of [Directus](http://www.directus.io/)  

混合“自带数据库”（BYODB）云部署的兴起：将某些数据驱动的项目迁移到云的好处是毋庸置疑的-更快的部署、更低的基础架构和维护成本、内置的支持和SLA以及在需要时的即时可扩展性。然而，总是会有用例义务要求在本地保存数据，包括性能、安全性、法规遵从性、本地开发和气隙硬件（仅举几例）。对于现代数据供应商来说，一个更灵活的解决方案是支持混合“自带数据库”（BYODB）云部署，以及更常见的本地和完全托管的云服务选项。这种新方法将在未来几年内流行起来，允许数据保持在原位，不被更改，但远程连接到附近数据中心的SaaS服务。 这提供了云计算的所有好处，同时仍然允许对公司最宝贵的资源--数据--进行完全的授权和控制。 - Ben Haynes，Directus联合创始人兼首席执行官

PostgreSQL will continue to take over the world: PostgreSQL continues to grow as a project and as a community. It will eventually take over the position that MySQL holds on the DB-Engines ranking and become the most popular open source database, but this will be a while. There are lots of new projects being launched that base themselves on PostgreSQL, and then offer their spin on top. The reason for this is that it is easy to make PostgreSQL do what you want it to, and the license it is released under makes it possible to build businesses on this as well. For users, it is simple to implement and the community is a strong one. – Donnie Berkholz, SVP of Product Management at [Percona](https://www.percona.com/)PostgreSQL将继续占领世界：PostgreSQL作为一个项目和社区继续成长。它最终将取代MySQL在DB-Engines排名中的位置，成为最受欢迎的开源数据库，但这还需要一段时间。有很多基于PostgreSQL的新项目正在启动，然后在上面提供他们的旋转。这样做的原因是，很容易让PostgreSQL做你想做的事情，并且它发布的许可证也使得在此基础上建立业务成为可能。对于用户来说，它很容易实现，社区是一个强大的社区。- Donnie Berkholz，Percona产品管理高级副总裁  

NoSQL had a good run over the past 10 years. By catering to developers, they changed how database companies address their audiences. True to their namesake, NoSQL started with replacing SQL to appeal to developers. Transactions and many typical database features became collateral damage. They got ditched along the way too. Now, much matured, NoSQL vendors are looking to conquer the enterprise. However, they now realize that enterprise customers consider SQL table stakes. In a complete face-about, NoSQL databases are now adding SQL and other database features. 2023 will be a watershed moment for NoSQL vendors. They must prove they can move beyond their original niches. Otherwise they will not be able to challenge the dominance of established database players. – Mike Waas, CEO, Datometry  

NoSQL在过去的10年里有着良好的发展。通过迎合开发人员，他们改变了数据库公司解决其受众的方式。正如他们的名字一样，NoSQL开始取代SQL来吸引开发人员。事务和许多典型的数据库功能成为附带损害。他们也被抛弃了。现在，成熟的NoSQL供应商正在寻求征服企业。然而，他们现在意识到企业客户会考虑SQL表的风险。在一个完整的面对，NoSQL数据库现在正在添加SQL和其他数据库功能。2023年将是NoSQL供应商的分水岭。他们必须证明他们可以超越原来的利基市场。否则，他们将无法挑战现有数据库玩家的统治地位。- Mike Waas，Datometry首席执行官

Hyperscale Will Become Mainstream: Data warehouse vendors are will develop new ways to build and expand systems and services. Some leading-edge IT organizations are now working with data sets that comprise billions and trillions of records. In 2023, we could even see data sets of a quadrillion rows in data-intensive industries such as adtech, telecommunications, and geospatial.  Hyperscale data sets will become more common as organizations leverage increasing data volumes in near real-time from operations, customers, and on-the-move devices and objects. – Chris Gladwin, CEO, and Co-founder of [Ocient](https://www.ocient.com/)  

超大规模将成为主流：数据仓库供应商将开发新的方法来构建和扩展系统和服务。一些领先的IT组织现在正在处理包含数十亿和数万亿条记录的数据集。到2023年，我们甚至可以在广告技术、电信和地理空间等数据密集型行业中看到千万亿行的数据集。超大规模数据集将变得越来越普遍，因为组织将利用来自运营、客户以及移动设备和对象的近实时数据量。- Chris Gladwin，Ocient首席执行官兼联合创始人

Vector databases take hold to unleash the value of untapped unstructured data: As businesses embrace the AI era and attempt to make full use of its benefits in production, there occurs a significant spike in the volume of unstructured data taking all sorts of forms that need to be made sense of.  To cope with these challenges in extracting tangible value from unstructured data, vector databases–a new type of database management technology purpose-built for unstructured data processing–is on the rise and will take hold in years to come. – Frank Liu, Director of Operations at [Zilliz](https://zilliz.com/)  

矢量数据库可以释放未开发的非结构化数据的价值：随着企业拥抱人工智能时代并试图在生产中充分利用其优势，非结构化数据的数量出现了显着的激增，这些数据采取了各种形式，需要理解。为了科普从非结构化数据中提取有形价值的挑战，矢量数据库（一种专门用于非结构化数据处理的新型数据库管理技术）正在兴起，并将在未来几年内站稳脚跟。- Frank Liu，Zilliz运营总监

Snowflake will become a niche technology as legacy providers costs rise: In 2023 Snowflake will become more of a niche technology. With Snowflake’s costs increasing on average 71% year over year, based on their earnings report, customers are getting to a point where they can no longer afford to continue that kind of exponential increase in costs. Because of this, customers are going to be much more cautious about what they put in there, and will put up walls of approvals and rules regarding who’s allowed to use and access what. With companies becoming more careful in this regard, they will be looking for open alternatives. The demand to make data accessible and to become data driven is still there, and data’s still growing very fast. But, customers need systems that are able to do that at scale, and customers need them to be cost efficient. The industry is moving towards those types of systems. – Tomer Shiran, CPO, and co-founder of [Dremio](https://www.dremio.com/)  

Snowflake将成为一种利基技术，因为传统提供商成本的上升：到2023年，Snowflake将成为一种小众技术。雪花的成本平均每年增长71%，根据他们的收益报告，客户已经到了一个点，他们再也负担不起继续这种指数增长的成本。正因为如此，客户将更加谨慎地对待他们在那里放的东西，并将建立起批准墙和规则，关于谁可以使用和访问什么。随着公司在这方面变得更加谨慎，他们将寻找开放的替代方案。让数据可访问并成为数据驱动的需求仍然存在，数据仍在快速增长。但是，客户需要能够大规模实现这一目标的系统，客户需要它们具有成本效益。该行业正在向这些类型的系统发展。- Tomer Shiran，首席执行官，Dremio联合创始人

 Why NoSQL is irrelevant, NewSQL is insufficient and Distributed SQL reigns supreme: 2023 is the year that companies facing new challenges in the cloud will realize they cannot solve their problems, meet customers’ expectations, or achieve goals entirely with NoSQL, SQL, or extensions of NewSQL databases. It’s time for them to adopt an architecture that provides the freedom and flexibility required to address their current and future needs. – Co-founder and CTO of Yugabyte Karthik Ranganathan  

为什么NoSQL是无关紧要的，NewSQL是不够的，分布式SQL占主导地位：2023年，面临云计算新挑战的企业将意识到，他们无法完全通过NoSQL、SQL或NewSQL数据库扩展来解决问题、满足客户期望或实现目标。现在是时候让他们采用一种能够提供满足他们当前和未来需求所需的自由和灵活性的体系结构了。- Yugabyte Karthik Ranganathan联合创始人兼CTO

Data Lakes and Warehouses will converge as data infrastructure vendors of all sizes try to differentiate themselves through innovation. We are currently in a rare moment in the evolution of the data infrastructure industry as users are increasingly seeing competitive parity features emerge from major players like Snowflake, Databricks, etc. In turn, this will create an even stronger buyer’s market as vendors continue to innovate and differentiate themselves, resulting in greater industry integration, interoperability and a standardization of best practices. In 2023 and beyond, data warehouses, data lakes and other similar infrastructure technologies will see notable consolidation as buyers sift through vendors and features to find the most value for their data stack while removing redundancies and the need to build and manage their own bespoke platforms. – Sean Knapp, CEO and founder of [Ascend.io](https://www.ascend.io/)  

随着各种规模的数据基础设施供应商试图通过创新使自己与众不同，数据湖和仓库将融合。我们目前正处于数据基础设施行业发展的一个罕见时刻，因为用户越来越多地看到Snowflake、Databricks等主要参与者推出了具有竞争力的平价功能。反过来，这将创造一个更强大的买方市场，因为供应商不断创新和差异化，从而实现更大的行业整合、互操作性和最佳实践的标准化。在2023年及以后，数据仓库、数据湖和其他类似的基础设施技术将经历显著的整合，因为买家会筛选供应商和功能，为他们的数据堆栈找到最大的价值，同时消除冗余以及构建和管理自己定制平台的需求。Ascend.io – Sean Knapp, CEO and founder of

Companies should adopt a unified database: Companies need a unified database to support large amounts of transactional and analytical workloads at the same time. This allows a simplified and flexible data architecture for companies to process massive workloads. In 2023, successful organizations will use one platform to transact and reason with data in milliseconds in a hybrid, multi-cloud environment. Specialized databases need to converge to be built on four primary characteristics: distributed, shared-nothing architecture, cloud-native, multi-model and relational foundation. – Shireesh Thota, SVP of Engineering, [SingleStore](https://www.singlestore.com/)  

企业应采用统一的数据库：公司需要一个统一的数据库来同时支持大量的事务和分析工作负载。这为公司提供了简化和灵活的数据架构，以处理大量工作负载。到2023年，成功的组织将使用一个平台在混合多云环境中以毫秒的时间处理数据和推理。专用数据库需要融合以构建在四个主要特征之上：分布式、无共享架构、云原生、多模型和关系基础。- Shireesh Thota，SingleStore工程高级副总裁

**Data Engineering**

Python will become a key enabler of the democratization of data: Business people are no longer patiently waiting for data scientists and ML engineers to unlock the value of data, they want to extract insights from data themselves. In 2023, Python will be the primary medium for democratizing access to, and insights from, data for everyone across an organization. Python will become more enterprise-ready as the runtime infrastructure around Python grows simpler and more straight-forward, and includes more security and governance. At the same time, productionizing Python results will become further streamlined and that code will be wrapped in a meaningful user experience so it can be easily consumed and understood by non-IT users such as a company’s marketing team. We’ll see Python have the same or more likely, an even greater transformational impact on democratizing data than the emergence of self-service business intelligence tools 15 to 20 years ago. – Torsten Grabs, Director of Product Management, Snowflake 

The Data Engineer role will continue down the path of specialization. Over the past couple of decades, we’ve seen the role of the software engineer split into a variety of other roles such as infrastructure, backend, frontend, mobile, and even product engineer. The role of the data engineer will follow a similar path, and we will see continued growth not only in today’s “data engineer” (i.e. the full stack engineer), but expansion in the “analytics engineer” (i.e. the frontend engineer), as well as the “data platform engineer” (i.e. the infrastructure engineer). This specialization will enable organizations to tap into a greater body of talent and skills, as well as aligning jobs with what is of greatest interest to their developers. – Sean Knapp, CEO and founder of [Ascend.io](https://www.ascend.io/)

The Beginning of the End for Data Engineering As We Know It: Maintaining legacy data pipelines is a costly affair for enterprises. Data Engineers are constantly moving data across different platforms. This is a wasteful, inefficient allocation of talent and resources. Recent developments in cloud architecture and Artificial Intelligence will fundamentally change how data is prepared, resulting in more efficient data engineering. These developments will bring about new products, architectures, and methodologies in the coming year that will improve the profiling, acquisition, and movement of data, all powered by AI. – James Li, CEO of [CelerData](http://www.celerdata.com/)

Believe it or not, technical skills are not the most important qualification when looking for an engineer. If someone is sufficiently curious, they can pick up any technical skill. Engineers looking to make themselves “recession-proof” will need to understand that companies are looking for someone with the potential and willingness to learn while also being able to communicate effectively. Hiring based on curiosity and potential opens the door to a more diverse, and therefore successful, workforce. – According Manjot Singh — Field CTO for [MariaDB](https://mariadb.com/) 

Data Contracts Become More Real & The Business Finally Gets Involved: Too many engineering teams are struggling to maintain data quality, access, and track usage patterns. While many businesses have in-function analytics professionals collaborating with core enterprise analytics teams, data and/or analytics engineering professionals are still navigating data domains and certifying data coming out of data build tools. In 2023, the continued proliferation of data is going to finally force the business to take more ownership of data, not just in use and interpretation, but also in the patterns of how it is managed and provisioned. Distributed stewardship will become a reality and the best way to enable this will be with tools that are not built for engineers, but with data contracts that clearly map ownership, use, dependencies, etc. This will become more visible as features in data catalogs and/or a few startups emerging since confluence will not cut it at scale. – Nik Acheson, Field Chief Data Officer for [Okera](http://www.okera.com/) 

Data reliability engineering: All too often, bad data is first discovered by stakeholders downstream in dashboards and reports instead of in the pipeline— or even before. Since data is rarely ever in its ideal, perfectly reliable state, data teams are hiring data reliability engineers to put the tooling (like data observability platforms and data testing) and processes (like CI/CD) in place to ensure that when issues happen, they’re quickly resolved and impact is conveyed to those who need to know before your CFO finds out. – Lior Gavish, co-founder and CTO of [Monte Carlo](https://www.montecarlodata.com/)

The role of AI/ML engineers will become mainstream: Since model deployment, scaling AI across the enterprise, reducing time to insight and reducing time to value will become the key success criteria, these roles will become critical in meeting these criteria. Today a lot of AI projects fail because they are not built to scale or integrate with business workflows. – Nicolas Sekkaki, [Kyndryl](https://www.kyndryl.com/us/en)’s GM of Applications, Data & AI

**Data Governance**

The share of organizations with a formal data governance team will increase 30%. Organizations must take the critical step of establishing a dedicated data governance team to develop standards and policies, implement enterprise data governance tools, and coordinate business-line efforts. In the next 12 months, 36% of organizations plan to bring on a head of data governance, and 32% of organizations will bring on a chief data officer. – Forrester 

Getting access to data does not necessarily mean being in a position to derive useful insight. In this data deluge, the successful organizations will be those who will be able to crack the data governance dilemma by leveraging both self-executing policies, such as access control and obfuscation, and auditing capabilities, with a view to reduce time to data. They will discard meaningless pre-approval workflows and federate data governance by making data owners the key players: data owners will be both domain experts and data stewards. – Sophie Stalla-Bourdillon, Senior Privacy Counsel and Legal Engineer, Immuta

New data sovereignty laws will spur businesses to make data more visible and interoperable: We expect to see businesses take a more proactive role in creating their own data governance policies amid the current wave of regulatory action. The current global patchwork of data sovereignty and privacy laws has made it more complicated than ever for businesses to create consistent policies on data sharing, integration and compliance. This will continue to have a significant impact on organizations’ ability to maximize the use of data across their IT infrastructure, unless they put together clear plans for data integration and governance. In 2023, the passing of more data sovereignty and sharing laws will spur businesses to invest in getting visibility into their data and creating clear plans for sharing and integration across their IT landscape. – Danny Sandwell, Senior Solutions Strategist, Quest

Automation will offer data teams a way to balance defensive/offensive data operations: With recent high-profile cases of organizations being fined for data breaches, there was a risk that data teams may have become “spooked” into funneling efforts and funds into data regulation compliance and away from data innovation. While that may have happened in previous years, the balancing act between data compliance and data innovation could be about to become a lot easier in 2023 as data governance automation begins to take root. Data access and security controls have been automated for a while, but we expect data governance automation to blend existing automated operations with data governance policy-making to free-up time for data teams to focus on business innovation without leaving the organization defenseless. – John Wills, Field CTO at Alation

Ungoverned data will have to fall in line. Because of the rapid proliferation of data, many companies still don’t have a good grasp on who has access to what data and where their data lives. Data governance will remain a top priority for IT leaders, not only for compliance reasons, but also to ensure the data in your company is usable. It’s harder to turn data into value if you struggle to locate, access, and securely share it with the right people. – Chad Verbowski, SVP of engineering at Confluent

Businesses to focus efforts on AI regulation and governance: As the United States – and the rest of the world – respond to the increasing demand for trust in AI, technology leaders will follow in pursuit. While AI and automation can provide businesses with many benefits, it also comes with a lot of risks. It is critical to embrace AI to stay competitive, but it is also imperative to set standards within your business. To stand out in the new digital landscape in the coming year, we will see businesses not only continue to invest in AI, but also invest their resources in getting ready for new regulations. – Anand Rao, Global AI Lead; US Innovation Lead, Emerging Technology Group, PwC

Data democratization and data governance balancing act takes center stage: The trend of data democratization will continue to grow as organizations increasingly seek greater accessibility. However data democratization comes with risks and today’s organizations are faced with a challenge — how do you drive governance around data democratization? With the continued rise of data democratization, we’ll see a shift from a storage-centric world to an analytics-centric world, one where data is treated as a first class product to be consumed by the rest of the organization. The democratization of Data Products enables organizations to have greater access to their data across the board, but with that, there also needs to be fine grained access controls. To support that, similar to how the data science occupation was created about 10 years ago to support big data analytics projects, in 2023 we’ll see the Data Product Manager role emerge to provide the necessary governance to facilitate who has access to what. – Justin Borgman, [Starburst](https://www.starburst.io/) CEO

**Data Integration, Data Quality**

Need real-time data monitoring to ensure AI is fed by good quality data: For companies looking to up-level their data and AI strategies in 2023, data quality should be a top priority. Poor quality or biased data results in erroneous or biased AI models. In order to trust and ensure the quality of the data being fed into AI and ML models, enterprise leaders need to implement real-time monitoring of data pipelines via data observability tools to catch issues and pipeline breakdowns before they cause serious issues. – Jay Militscher, Head of Data Office at [Collibra](https://www.collibra.com/us/en)

This is the year that the data quality issue in healthcare will really come to the forefront. This is because the federal government is looking at provider data quality more seriously (through the CMS National Health Directory proposal) and it is becoming more apparent that machine learning-based interventions in healthcare do not actually work. There is a big push to free data in healthcare (APIs to share data from health plans, price transparency, etc.) that will be realized next year, and the assumption is that all of this will be great. However, if you’re sharing “dirty data,” the system won’t get the benefits that everyone is predicting. – Amit Garg, CEO and co-founder of [HiLabs](https://www.hilabs.com/)

Junky or dirty data is data that is incorrect, incomplete, inconsistent, outdated, duplicative – or all of the above, and may be killing your business. It’s a common problem often heightened during cyclical periods when you need your customer data to work for you most — i.e., for holiday shopping and travel. Avoid confusion and frustration, and ease your customers’ shopping and travel experience by mastering your customer data. Customer mastering creates a unified, accurate and enriched view of customer data across systems and sources, and a unique identifier enabling consistent tracking of the customer. Mastering your customer data at scale gives sales, marketing and customer experience teams a powerful way to accelerate data-driven selling. It also enables customer insights for competitive advantage. – Anthony Deighton, Chief Product Officer at [Tamr](http://www.tamr.com/)

Data contracts: Designed to prevent data quality issues that occur upstream when data-generating services unexpectedly change, data contracts are very much en vogue. Why? Thanks to changes made by software engineers who unknowingly create ramifications via updates that affect the downstream data pipeline and due to the rise of data modeling gives data engineers the option to deliver the data into the warehouse, pre-modeled. 2023 will see broader data contract adoption as practitioners attempt to apply these frameworks. – Lior Gavish, Co-founder and CTO of [Monte Carlo](https://www.montecarlodata.com/)

Developer platforms will overtake loosely connected tools as teams tire of integrations. While only a handful players continue to dominate the data infrastructure stack (Snowflake, Databricks, and the big 3 clouds), businesses have been using a hodgepodge of tools upstack for tasks like data ingestion, transformation, orchestration, management, and observability. In 2023, businesses will reach their breaking point as they tire of assembling and managing these upstack tools and don’t see enough returns on those investments. As they become increasingly frustrated by the inherent inefficiency of the fragmentary model, businesses will start to consolidate their vendor tools in order to prioritize developer team productivity and ease of maintenance. – Sean Knapp, CEO and founder of [Ascend.io](https://www.ascend.io/)

As data integration technology becomes more accessible, the focus will shift to operationalizing those technologies. The ability to scale simple-to-build pipelines and comply with enterprise governance requirements will be seen as more important than simply being able to connect to lots of environments. There will be a greater focus on efficiency and cost-benefit for users of cloud solutions. Companies have spent years moving data into cloud-hosted data warehouses and data lakes and, especially with uncertainty in the economy, leadership will be expected to justify the existing spend and control it moving forward. Technology companies that can provide complete end-to-end solutions for businesses undergoing digital transformation will have a significant advantage over those that don’t. As businesses look to see returns on their digital transformation investments, time-to-value and battle-tested solutions will be highly sought-after. – Dima Spivak, COO Products at [StreamSets](http://streamsets.com/)

AI and ML will enhance data quality: Artificial intelligence and machine learning have been adopted at unprecedented rates. In today’s multi-cloud environments, enterprises are sometimes left to their own devices to manage their data. AI and machine learning can help enterprises manage their data sources while also quickly scaling a multi-cloud environment. Enterprises are finally understanding that one size does not fit all and are looking to improved tools to get more value from their data. We’re seeing a renewed cloud conversation that encompasses cloud, data center, edge, and how data plays across those environments. In 2023, enterprises will treat data as a first-class consideration and not an afterthought. – Matt Wallace, CTO at [Faction](https://www.factioninc.com/)

**Data Mesh, Data Fabric**

Data Mesh Takes a Backseat But Data Products Will Push on Ahead in 2023: With the economy in a slowdown, we can expect data mesh— frameworks that bring scale to enterprise wide data adoption — to take a backseat. 2023 will be the year of data products before the industry moves towards data mesh in 2024 and beyond. – Founder and CEO of [Nexla](https://www.nexla.com/), Saket Saurabh

Accelerated adoption of data fabric and data mesh. Over the past two decades, data management has gone through cycles of centralization vs. decentralization, including databases, data warehouses, cloud data stores, data lakes, etc. While the debate over which approach is best has its own proponents and opponents, the last few years have proven that data is more distributed than centralized for most of the organizations. While there are numerous options for deploying enterprise data architecture, 2022 saw accelerated adoption of two data architectural approaches – data fabric and data mesh, to better manage and access the distributed data. While there is an inherent difference between the two, data fabric is a composable stack of data management technologies and data mesh is a process orientation for a distributed groups of teams to manage enterprise data as they see fit. Both are critical to enterprises that want to manage their data better. Easy access to data and ensuring it’s governed and secure, is important to every data stakeholders — from data scientists all the way to executives. After-all, it is critical for dashboarding and reporting, advanced analytics, machine learning, and AI projects. Both data fabric and data mesh can play critical roles in enterprise wide data access, integration, management and delivery, when constructed properly with the right data infrastructure in place. So in 2023, expect a rapid increase in adoption of both architectural approaches within mid-to-large size enterprises. – Angel Viña, CEO and founder of [Denodo](https://www.denodo.com/en)

X fabric connects data governance: Investment in data and analytics has dramatically accelerated thanks to the pandemic, and will continue to do so for the foreseeable with [93% of companies indicating they plan to continue to increase budgets in these areas.](https://www.ey.com/en_us/consulting/how-companies-are-investing-in-data-and-analytics) But rapidly shifting rules and regulations around privacy, as well as the distribution, diversity and dynamics of data is holding back organizations’ ability to really squeeze the best competitive edge out of it. This becomes especially challenging in a distributed and fragmented world, as data governance becomes even more complex. Improving access, real-time movement and advanced transformation of data between sources and systems across the enterprise is crucial to organizations realizing the full power of data and will be a key trend for 2023. This is why an [increasing number of businesses are turning to data control plane](https://www.idc.com/research/viewtoc.jsp?containerId=US48082521) architecture, an “X-fabric” not just for your data, but also for your applications, BI dashboards and algorithms, enabled by catalogs and cloud data integration solutions. Vital for anyone tasked with increasing agility, flexibility, compliance and sustainability; while propelling innovation. In short, they are a critical component in the modern data environment and for any organization that wants to act with certainty. – Dan Sommer, former Gartner analyst and Qlik’s Global Market Intelligence Lead 

One of the main challenges data executives will face in 2023 is deciding how they will leverage data to gain a competitive advantage. The ‘cloud wars’ have given way to the ‘data wars.’ To stay ahead of competitors, companies will need to improve the success rate of their AI and ML projects as disciplines like MLOps and related toolsets are helping AI/ML to have more of an impact beyond the data lab. To improve operations, organizations must go beyond technology and address the structural, cultural, and people-based aspects of data management—embracing disciplines like ‘data mesh’ and DataOps. – Myles Gilsenan, Vice President of Data, Analytics and AI at [Apps Associates](https://www.appsassociates.com/)

Organizations Must Focus on Getting the Data Fabric in Place or Risk AI Project Failure: As more enterprises look to implement AI projects in 2023 to increase productivity, gain better insights and have the ability to make more accurate predictions regarding strategic business decisions, the challenge will be for traditional enterprises to establish a robust data framework that will allow their organizations to leverage data effectively for AI purposes. To succeed, organizations must have the correct data infrastructure architecture (IA) in place. The issue is that most companies do not have a sound data infrastructure and will struggle to maximize the value of their data unless their data fabric is in place. Additionally, the data is often unorganized, uncleaned, and unanalyzed and could be sitting in several systems, from ERP to CRM. In 2023, organizations must utilize data in the same way that oil firms use crude oil and farmers use their land and crops to generate profit:  identify the sources, plant the “seeds,” extract the impurities, refine, store, and pipe them, build the infrastructure for distribution, nurture, cure, safeguard, and yield it. AI solution providers can work with enterprises on these obstacles and implement frameworks that will strengthen the infrastructure architecture (IA) so that it can more successfully implement AI. The first order of business should be how to collect data which includes widening the data by adding external features –  both structured and unstructured data along with more focus on the quality and availability of the data required for developing an AI solution versus just volume. When finding answers to “what will happen,” enterprises need various data sources. Once all the data is collected, it can then be unified, processed, and ultimately presented as the AI output to iterate predictions and other information enterprises need and then all three ROIs like strategy, capability and financial ROI rather than only financial ROI to be focused. – Anand Mahukar, CEO, Findability

Data mesh initiatives gain momentum, but misinformation threatens to slow adoption: Companies that rely on data management tools to make decisions are 58% more likely to beat their revenue goals than non-data-driven companies, according to a study from Collibra and Forrester Consulting. And data-driven organizations are 162% more likely to significantly surpass revenue goals than those that are not data-driven. The enterprise has reached a turning point in the evolution of data management. We are increasingly seeing companies pivot away from traditional, monolithic approaches, and instead embrace new strategies and solutions in an effort to become more data-driven. One growing trend is the adoption of a data mesh architecture, which many organizations view as an answer to their challenges around data ownership, quality, governance, and access. A data mesh offers a distributed model where domain experts have an ownership role over their data products. In 2023, we anticipate even greater pressure on organizations to move faster and build resilient, agile data architectures that will push data teams towards data mesh implementations. However, despite the growing enthusiasm around data mesh, we do expect roadblocks due to misinformation. In order to move forward, misinformation needs to be eradicated so that data mesh can be successfully adopted at scale. For example, despite being marketed as such, you cannot buy a data mesh — it is not a technology. There is also still much discussion and confusion about how to prevent data meshes from exacerbating data silos, and whether or not data mesh and data fabric are actually the same thing. To overcome these challenges and move beyond any debates or uncertainties, companies must take responsibility for educating themselves to strengthen their understanding of what a data mesh is and how it can optimize their data management strategy. – Jens Graupmann, SVP of product & innovation, [Exasol](https://www.exasol.com/)

Data fabrics will become more popular for businesses at the forefront of data management: As organizations work to break down data silos, many highly data-literate companies are turning to data fabrics as a way to utilize the data they have as optimally as possible. As these systems gain traction, we’re likely to see more data marketplaces within organizations, where users of all skill levels from departments across the organization can find and use data in a self-service, consumable manner. – John Wills, Field CTO at Alation

Centralized data infrastructures will shift to data meshes: Data mesh’s popularity will keep growing as data teams search to reduce bottlenecks and improve data usage. To make data more accessible and available, organizations will adopt key concepts popularized by Zhamak Dehghani, such as domain ownership or data as a product. – Andy Petrella, founder and CPO of [Kensu](https://www.kensu.io/)

2023 will be the year of data products before we move fully towards data mesh. With the economy in a slowdown, we can expect complete adoption of data mesh to take a backseat. We will also see augmented data management rise in importance as AI becomes more integrated with data quality, metadata management, and master data management. Specialists will be able to focus on more high-value tasks as manual data management tasks are lessened by ML and AI developments. New approaches will make it possible to converge multiple tools such as integration, monitoring, and transformation into one. With data products, augmented data management, and convergence changing the way we handle data, 2023 will bring new solutions for handling data problems. – Saket Saurabh, CEO of [Nexla](https://www.nexla.com/)  

2023年将是数据产品的一年，然后我们才能完全转向数据网格。随着经济的放缓，我们可以预期数据网格的完全采用将退居次要地位。随着人工智能与数据质量、元数据管理和主数据管理更加集成，我们还将看到增强数据管理的重要性上升。专家将能够专注于更高价值的任务，因为机器学习和人工智能的发展减少了手动数据管理任务。新的方法将使整合、监控和转换等多种工具成为可能。随着数据产品、增强的数据管理和融合改变了我们处理数据的方式，2023年将为处理数据问题带来新的解决方案。- Saket Saurabh，Nexla首席执行官

Businesses will take incremental steps towards Data Mesh and Fabric adoption. While the tech industry as a whole may still be debating what defines each of these (as well as what differentiates them), there is undeniable interest among organizations to gain the benefits of these specific architectures, namely speed and agility at scale. In 2023 and the years ahead, while most data teams will not have the resources to dive headfirst into working with a new mesh or fabric architecture, we will see them incrementally work their way towards the adoption of these solutions, often first by defining new best practices and strategies that support these future cutting-edge architectures. – Sean Knapp, CEO and founder of [Ascend.io](https://www.ascend.io/)  

企业将逐步采用Data Mesh和Fabric。虽然整个科技行业可能仍在争论是什么定义了每一个架构（以及它们的区别），但不可否认的是，组织都有兴趣获得这些特定架构的好处，即大规模的速度和敏捷性。在2023年和未来几年，虽然大多数数据团队将没有资源来一头扎进新的网状或结构架构中，但我们将看到他们逐步采用这些解决方案，通常首先定义新的最佳实践和战略来支持这些未来的尖端架构。Ascend.io – Sean Knapp, CEO and founder of

Smart data fabrics move to the edge: Edge computing, the analysis of data and the development of solutions at the location where the data is generated, can significantly reduce latency and improve both customer and end-user experiences. While the edge computing market is forecast to grow 38.9% each year and reach [$155.90 billion by 2030](https://www.techrepublic.com/article/global-edge-computing-market/), progress is beginning to stall as implementation and enablement of edge technologies is proving more costly than beneficial. The “edge” is never a defined thing, but instead is a jagged edge that is constantly in a state of flux – a moving target that businesses are always trying to hit the mark on. As moving data is one of the biggest IT expenses for companies, ensuring you have the right data architecture to support the edge is critical for success and for budgeting. I anticipate smart data fabrics will become inherent to edge implementations in 2023 as this reference architectural approach provides organizations with a consistent, accurate, unified view of their data assets and keep pace with the changing demand at the edge. – Scott Gnau, Head of Data Platforms, [InterSystems](https://www.intersystems.com/)  

智能数据结构走向边缘：边缘计算、数据分析和在数据生成地点开发解决方案，可以显著减少延迟并改善客户和最终用户体验。虽然边缘计算市场预计每年增长38.9%，到2030年将达到1559亿美元，但进展开始停滞，因为边缘技术的实施和实现被证明成本大于效益。“边缘”从来不是一个定义的东西，而是一个锯齿状的边缘，不断地处于变化的状态-一个移动的目标，企业总是试图击中目标。由于移动数据是公司最大的IT支出之一，因此确保您拥有正确的数据架构来支持边缘对于成功和预算至关重要。 我预计智能数据结构将在2023年成为边缘实施的固有特征，因为这种参考架构方法为组织提供了一致、准确、统一的数据资产视图，并跟上边缘不断变化的需求。 - Scott Gnau，InterSystems数据平台主管

**Data Science 数据科学**

Data science democratizes to address skills shortage: The demand for data scientists has grown but organizations are struggling with finding the best candidates, leading to difficulty in putting models into production and operationalizing AI. At the same time, citizen data scientists are emerging as organizations have recognized that data science is no longer a skill for only the technical few and that everyone should be enabled to work with data comfortably. In 2023, look for organizations to consolidate diverse AI and analytics tools around modern, open, multi-language tools that will increase data science productivity, empower end users to do basic analytics tasks, and allow data scientists to focus on core tasks. By democratizing analytics, more people can join the field. – Marinela Profi, Data Scientist and Product Lead for Analytics and ModelOps, SAS  

数据科学民主化以解决技能短缺问题：对数据科学家的需求不断增长，但组织正在努力寻找最佳候选人，导致难以将模型投入生产和人工智能操作。与此同时，公民数据科学家正在崛起，因为组织已经认识到，数据科学不再是只有少数技术人员的技能，每个人都应该能够轻松地使用数据。在2023年，寻求组织围绕现代、开放、多语言工具整合多样化的人工智能和分析工具，以提高数据科学生产力，使最终用户能够完成基本的分析任务，并允许数据科学家专注于核心任务。通过使分析民主化，更多的人可以加入这个领域。- Marinela Profi，SAS数据科学家兼分析和模型运行产品负责人

New vulnerability in the data science ranks. For the past several years, there has been a severe shortage of data scientists, and companies lucky enough to have them treated them like gold. But as trends continue regarding the difficulty of demonstrating ROI on AI efforts, and as the economy softens, enterprises are taking a harder line on results. It’s common today for only 1 in 10 models developed to ever see the light of day. Data science teams that aren’t able to get models into production at a faster pace will face pressure. Those jobs may not be secure forever. – Anupam Datta, co-founder, president and chief scientist at [TruEra](https://truera.com/)数据科学中的新漏洞。在过去的几年里，数据科学家一直严重短缺，而幸运的是，他们像对待黄金一样对待他们。但是，随着AI努力证明ROI的难度的趋势继续存在，以及经济疲软，企业对结果采取了更强硬的立场。如今，只有十分之一的型号开发出来的产品能够重见天日，这是很常见的。无法以更快的速度将模型投入生产的数据科学团队将面临压力。这些工作可能不会永远安全。- Anupam Datta，TruEra联合创始人、总裁兼首席科学家  

The world reaches the era of “peak data scientist.” The shortfall of data scientists and machine learning engineers has always been a bottleneck in companies realizing value from AI. Two things have happened as result: (1) more people have pursued data science degrees and accreditation, increasing the number of data scientists; and (2) vendors have come up with novel ways to minimize the involvement of data scientists in the AI production roll out. The coincident interference of these two waves yields “peak data scientist”, because with the advent of foundational models, companies can build their own applications on top of these models rather than requiring every company to train their own models from scratch. Less bespoke model training requires fewer data scientists and MLEs at the same time that more are graduating. In 2023, expect the market to react accordingly resulting in data science oversaturation. – Ryan Welsh, Founder and CEO of [Kyndi](https://www.kyndi.com/)  

世界达到“巅峰数据科学家”时代数据科学家和机器学习工程师的短缺一直是企业实现AI价值的瓶颈。结果发生了两件事：（1）更多人追求数据科学学位和认证，增加了数据科学家的数量;（2）供应商已经提出了新的方法来尽量减少数据科学家在AI产品推出中的参与。这两种浪潮的同时干扰产生了“巅峰数据科学家”，因为随着基础模型的出现，公司可以在这些模型之上构建自己的应用程序，而不是要求每家公司从头开始训练自己的模型。较少定制的模型培训需要更少的数据科学家和MLE，同时更多的人毕业。到2023年，预计市场将做出相应反应，导致数据科学过度饱和。- Ryan Welsh，Kyndi创始人兼首席执行官

The role of data scientists will evolve in 2023, reflecting the rising popularity and power of AutoML and AI capabilities that can handle many of the routine tasks usually handled by these experts. With everyday predictive needs increasingly addressed by automated platforms, business leaders will dedicate data scientists’ scarce time and costly resources more intentionally toward projects requiring hand-crafted, one-off models or specialized domain expertise. To preserve flexibility and reduce risk in the coming year’s turbulent conditions, more businesses will turn to specialized vendors and SaaS for routine predictive modeling projects instead of continuing to build expensive data science teams. – Zohar Bronfman, co-founder and CEO of [Pecan AI](https://www.pecan.ai/)数据科学家的角色将在2023年演变，反映出AutoML和AI功能的日益普及和强大，这些功能可以处理通常由这些专家处理的许多常规任务。随着自动化平台越来越多地满足日常预测需求，业务领导者将更有意识地将数据科学家的稀缺时间和昂贵资源用于需要手工制作的一次性模型或专业领域专业知识的项目。为了在未来一年的动荡环境中保持灵活性并降低风险，更多的企业将转向专业供应商和SaaS进行常规预测建模项目，而不是继续建立昂贵的数据科学团队。- - Zohar Bronfman，Pecan AI联合创始人兼首席执行官  

The generalist data scientist becomes specialized: Recent focus has been on training data scientists as generalists in coding, algorithm development, and open source on the most dispersed (and sometime with low business value) topics. However, we are seeing that when faced with a real-world business problem, data scientists are lacking industry-specific knowledge – an understanding of the dynamics, trends, challenges of a specific industry, and the ultimate goals that everyone is looking to achieve in that niche market – stalling projects at the onset. In 2023, data scientists who have industry specific knowledge will be the most successful in meeting business demand and expectations and we will see data scientists seek out specialized training. – Marinela Profi, Data Scientist and Product Lead for Analytics and ModelOps, SAS  

多面手数据科学家变得专业化：最近的重点是将数据科学家培训为编码、算法开发和开源方面的通才，这些领域涉及最分散（有时商业价值较低）的主题。然而，我们看到，当面对现实世界的商业问题时，数据科学家缺乏特定行业的知识--对特定行业的动态、趋势、挑战的理解，以及每个人都希望在该利基市场实现的最终目标--在一开始就停滞了项目。到2023年，拥有特定行业知识的数据科学家将在满足业务需求和期望方面最成功，我们将看到数据科学家寻求专业培训。- Marinela Profi，SAS数据科学家兼分析和模型运行产品负责人

Data scientists will develop a greater appetite for pre-built industry-specific and domain-specific ML models: In 2023, we’ll see an increased number of pre-built machine learning models becoming available to data scientists. They encapsulate area expertise within an initial ML model, which then speeds up time-to-value and time-to-market for data scientists and their organizations. For instance, these pre-built ML models help to remove or reduce the amount of time that data scientists have to spend on retraining and fine-tuning models. Take a look at the work that the Hugging Face AI community is already doing in driving a marketplace for ready-to-use ML models. What I expect to see next year and beyond is an increase in industry-specific and domain-specific pre-built ML models, allowing data scientists to work on more targeted problems using a well-defined set of underlying data and without having to spend time on becoming a subject matter expert in a field that’s non-core to their organization. – Torsten Grabs, Director of Product Management, Snowflake 

Pipelines Will Get More Sophisticated: A data pipeline is how data gets from its original source into the data warehouse. With so many new data types—and data pouring in continuously—these pipelines are becoming not only more essential, but potentially more complex. In 2023, users should expect data warehouse vendors to offer new and better ways to extract, transform, load, model, test, and deploy data. And vendors will do so with a focus on integration and ease of use. – Chris Gladwin, CEO and Co-founder of [Ocient](https://www.ocient.com/) 

In 2023, business leaders will evaluate potential data science projects much more rigorously than in the past. These projects often fail to generate real impact due to poor alignment with business needs or because they never make it into production. With the expense and time commitment involved in data science, leaders will scrutinize proposed efforts more carefully and investigate the right way to pursue them to ensure that business-improvement actions could be taken in the near term based on the output of the models — or scuttle them before resources are wasted. – Zohar Bronfman, co-founder and CEO of [Pecan AI](https://www.pecan.ai/) 

New vulnerability in the data science ranks: For the past several years, there has been a severe shortage of data scientists, and companies lucky enough to have them treated them like gold. But as trends continue regarding the difficulty of demonstrating ROI on AI efforts, and as the economy softens, enterprises are taking a harder line on results. It’s common today for only 1 in 10 models developed to ever see the light of day. Data science teams that aren’t able to get models into production at a faster pace will face pressure. Those jobs may not be secure forever. – Anupam Datta, co-founder, president and chief scientist at [TruEra](https://truera.com/)

Data science teams will need to drive ROI to dodge layoffs: Today, many data scientists and data science teams are too disconnected from core business outcomes, focused on interesting experiments instead of programs that deliver measurable revenue. Even with the relative scarcity of talent, the economic need to show results will evolve roles to be more revenue-based. As it relates to the marketing function, the successful data scientist will be able to collaborate with marketing counterparts to productionize a churn model to not just predict churn but actually prevent it. This requires a degree of business acumen – but it also requires the right tooling. MarTech stacks that enable seamless connectivity from data and data science environments will be critical. This prediction will ultimately lead to changes in the data scientist role – while there still will be core data scientists, they’ll be focused on solving well defined problems with understood value and incrementality. For those data scientists that don’t make the cut, marketing teams will need tools in place to allow them to be self-sufficient in the absence of this resource. The wide-reaching data science roles that we see today will move closer to business functions to focus on marketing insights or product analytics in 2023. – Simon Data CEO and co-founder Jason Davis

Business leaders will be demanding increased AI/ML Engineering Productivity and better ROI of AI: The war on data science talent has led to a number of companies acquiring AI/ML talent at a premium in the market during the ‘Great Resignation’. As the economy slows down, business leaders are looking for proof points for better AI/ML engineering productivity from their data scientists. This will also translate into a more rigorous approach to measuring and enhancing Return on Investment (ROI) of their AI initiatives. – Anand Rao, Global AI Lead; US Innovation Lead, Emerging Technology Group, PwC

In the past few years, businesses have come to realize just how much data is available within their organization. The challenge now becomes what to do with this sheer volume of data and how to extract insights from it in a reliable and near real-time fashion. In 2023, Data Science will move from a job role all by itself, to a skill set performed by many in wider job functions in an effort to capitalize on the valuable insights a company’s data can provide. Additionally, AI practitioners and data scientists will continue to see a growing need for more compute power at the desktop as datasets get even larger, and with the right technology platforms in place, the possibilities are almost endless for corporations of any size. – Mike Leach, senior manager for client AI and workstation solutions at Lenovo

Pipelines Will Get More Sophisticated: A data pipeline is how data gets from its original source into the data warehouse. With so many new data types—and data pouring in continuously—these pipelines are becoming not only more essential, but potentially more complex.  In 2023, users should expect data warehouse vendors to offer new and better ways to extract, transform, load, model, test, and deploy data. And vendors will do so with a focus on integration and ease of use. – Chris Gladwin, CEO, and Co-founder of [Ocient](https://www.ocient.com/)

Data science teams will need to drive ROI to dodge layoffs: Today, many data scientists and data science teams are too disconnected from core business outcomes, focused on interesting experiments instead of programs that deliver measurable revenue. Even with the relative scarcity of talent, the economic need to show results will evolve roles to be more revenue-based. As it relates to the marketing function, the successful data scientist will be able to collaborate with marketing counterparts to productionize a churn model to not just predict churn but actually prevent it. This requires a degree of business acumen – but it also requires the right tooling. MarTech stacks that enable seamless connectivity from data and data science environments will be critical. This prediction will ultimately lead to changes in the data scientist role – while there still will be core data scientists, they’ll be focused on solving well defined problems with understood value and incrementality. For those data scientists that don’t make the cut, marketing teams will need tools in place to allow them to be self-sufficient in the absence of this resource. The wide-reaching data science roles that we see today will move closer to business functions to focus on marketing insights or product analytics in 2023. – Simon Data CEO and co-founder Jason Davis

Within the field of data science in 2023, things that will stand out include autonomous systems in software platforms, and physical self management with self learning mechanics. It’s likely that autonomous platforms will be able to adapt to algorithms without the usual software upgrade. What’s more, autonomous systems will be used to solve problems facing model-based and conventional automation systems that are struggling to scale as per business needs.  – Bal Heroor, CEO of [Mactores](https://mactores.com/)

**Deep Learning**

This year, Generative AI became the source of tremendous hype. It marks the entrance of AI into the creative realm, for example, with Jasper creating original marketing content or Dall-E 2 instantaneously producing art based on user-provided text. But I believe the real excitement should be focused on Generative AI’s ability to democratize existing AI use cases for traditional companies—and this could have a major impact as early as 2023. Today, traditional companies are limited in their AI adoption because they have to build algorithms from scratch and often lack both the data and skills to do so. With Generative AI, companies will have access to pre-trained “all-purpose” algorithms that require few data and data scientists to fine-tune and are easy for employees to operate. As a result, we could see a major wave of AI adoption in different sectors. For instance, Generative AI could enable the large-scale use of AI in healthcare to produce more accurate medical diagnoses or in manufacturing through the introduction of better predictive maintenance at lower cost. – François Candelon, Global Director, [BCG Henderson Institute](https://www.bcg.com/bcg-henderson-institute)

End-to-End Deep Learning Needs Data-Driven Solutions: In 2023, more companies will use data-driven solutions to build end-to-end deep learning AI models. Approaching the models with data is the most productive and efficient way to advance the existing technology and ramp up the pace of innovation. Each massive step in AI thus far has been faster than the previous, and that’s due to other companies bringing awareness to data-driven strategies for building AI models and ramping up the speed of the entire industry along with it. – Scott Stephenson, CEO and co-founder of [Deepgram](https://deepgram.com/) 

Deep learning is here: The next step for artificial intelligence in 2023 is deep learning. While AI so far has mostly been a mix of supervised machine learning and data analytics, the rise of deep learning will usher in a new era where computers are able to learn without supervision. Advancements in deep learning will lead to innovations in robotics, generative AI, natural language processing and speech recognition, and scientific breakthroughs in health, sustainability, and more. Of course, as with any AI models, the key for organizations to ensure the results are accurate and comply with new regulations emerging is to make sure there is still a human element for routine monitoring and trusted accuracy of the ML models. – Rosemary Francis, Chief Scientist, Altair

Training and Deploying Foundation Models Supporting Billions of Parameters Becomes Less Costly and Complex: In 2022, we saw an increase in the accessibility of models with a number of parameters in the order of billions to hundreds of billions. These models – known as foundation models – exhibit strong generalization and the ability to solve tasks for which they were not trained. Currently, training foundation models require months of work and budgets that can stretch to millions of dollars for a single training run. In 2023, I anticipate a significant reduction in both the effort and cost required to train foundation models as well as deploy them in a number of industries, like pharmaceutical research and fintech. – Luca Antiga, CTO of [Lightning AI](https://lightning.ai/)

The singularity in our sights?: A research paper by Jiaxin Huang et al. was published this past October with the attention-grabbing title “[Large Language Models Can Self-Improve](https://arxiv.org/abs/2210.11610).” While not yet the singularity, the researchers coaxed a large language model into generating questions from text snippets, answering the self-posed question through “chain of thought prompting,” and then learning from those answers in order to improve the abilities of the network on a variety of tasks. These bootstrapping approaches have historically had a pretty tight bound to improvement – eventually models start teaching themselves the wrong thing and go off the rails – but the promise of improved performance without laborious annotation efforts is a siren song to AI practitioners. We predict that while approaches like this won’t drive us into a singularity moment, it will be the hot research topic of 2023 and by the end of the year will be a standard technique in all state-of-the-art, natural language processing results. – Paul Barba, Chief Scientist at [Lexalytics](https://www.lexalytics.com/), an InMoment Company

DALL-E and Generative AI in 2023: Generative models, like the one used to create DALL-E, analyze data and interpolate to create something brand new. But they’re not just good at creating weird art — generative models can be used to discover new materials for battery design, carbon capture, and loads of other innovations. Generative models will reach new heights in 2023 as solutions like DALL-E are adapted to the younger generation’s desire for video over audio and pictures. We can also expect to see generative models continue to infiltrate the healthcare space for vaccine modeling, drug discovery, and even personalized medicine supported by training data generated from electronic medical records. – Michael Krause, the AI Solutions Director at [Beyond Limits](https://www.beyond.ai/)

Environmental Impact of Generative Models: Generative models are producing extremely impressive results, but it’s not clear the impact they have on an actual business. What is clear is the carbon emission impact of training these massive models. The compute requirements are insane. So it begs the question, “Are the outcomes worth the environmental cost?” – Gideon Mendels, CEO and co-founder of MLOps platform [Comet](http://comet.ml/)

Investment in Large Language Models Will Skyrocket in 2023: Large Language Models (LLMs) like GPT-3 and BERT exhibit the ability to perform complex tasks by crafting input text in a way that triggers the model to solve a specific problem, such as a mathematical quiz. LLMs are considered “large” because of the inability to load them on an individual device and the attendant difficulties encountered when training them. Next year, I expect to see a significant increase in the number of startups and established businesses seeking funding or redirecting extant funds to budgets specifically allocated toward creating and training an individual LLM. – Luca Antiga, CTO of [Lightning AI](https://lightning.ai/)

The rise of multi-modal learning: The wave of image-generating networks like Stable Diffusion and DALL-E demonstrate the power of AI approaches that understand multiple forms of data – in this case, image in order to generate a picture, and text in order to take in descriptions from a human. While multimodal learning has always been a significant research area, it’s been hard to translate into the business world where each data source is difficult to interact with in its own way. Still, as businesses continue to grow more sophisticated in their use of data, multimodal learning jumps out as an extremely powerful opportunity in 2023. Systems that can marry the broad knowledge conveyed in text, image and video with sophisticated modeling of financial and other numeric series will be the next stage in many companies’ data science initiatives. – Paul Barba, Chief Scientist at [Lexalytics](https://www.lexalytics.com/), an InMoment Company

The Next Version of Tech is Generative: In 2023, one of the biggest focuses will be on [generative technologies](https://www.wired.com/story/ais-new-creative-streak-sparks-a-silicon-valley-gold-rush/). As the technology grows more sophisticated it will continue to be disruptive, not just for images and content development, but for other industries like speech recognition and banking. I predict that generative technology will soon act as an exoskeleton for humans—it will support the work we are doing and ultimately drive a more efficient and creative future. – Scott Stephenson, CEO and co-founder of [Deepgram](https://deepgram.com/) 

The rise of generative AI startups: Generative artificial intelligence exploded in 2022. In this next year, we will see text processing and visual art using generative AI continue to improve. Entrepreneurs will look to get in on the action (and the $$) and many startups will emerge that create simple experiences for non-technical people based on generative AI. This could range from advertising copy, SQL queries, documentation copy, blog title ideas, code comments, instructional material, and even deepfake video content. Increasingly the creative output from these models is indistinguishable from – and in many cases superior to – human output. – Christian Buckner, SVP, Data Analytics and IoT, Altair

Big models for AI are driving innovations in specialized infrastructure and solutions: Over the past few years, AI and deep learning have become mainstream and reached the same maturity level as data analytics. Big models, from OpenAI’s DALL-E 2 image generation model to Google’s LaMDA conversation agent, are expected to dominate the landscape in 2023. Billions of files will be used to train big models for longer periods of time, requiring more specialized infrastructure and solutions. Next-generation AI infrastructure will be developed to handle the scale. – Haoyuan Li, Founder and CEO, [Alluxio](https://www.alluxio.io/)

If 2022 was the year of Generative AI toys, 2023 will be the year of Generative AI products.” The focus will be on revenue generation and not just product viability. Optimizing Generative AI means focusing on things humans can’t do well. With Dall-e 2, much of its success is similar to a good search engine. Humans can already make incredible art and write life-changing text. However, what humans aren’t good at is analyzing billions of data points to unpack trends, patterns and predictions. That’s where the opportunity lies. There are massive applications for everything from drug discovery to solving traffic! – Joshua Meier, Lead AI Scientist, [Absci](https://www.absci.com/)  

如果说2022年是Generative AI玩具之年，那么2023年将是Generative AI产品之年。重点将是创收，而不仅仅是产品的可行性。优化生成AI意味着专注于人类无法做好的事情。Dall-e2的成功与一个好的搜索引擎相似。人类已经可以创作出令人难以置信的艺术作品，书写出改变生活的文字。然而，人类不擅长的是分析数十亿个数据点来解开趋势、模式和预测。这就是机会所在。从药物发现到解决交通问题都有大量的应用！- 约书亚Meier，Absci首席AI科学家

Prompt Engineering Takes Flight and Gains Refinement as Deployment of LLMs Increase: Once a foundation model is trained, it can be used to address problems that go well beyond predicting for example the next word in a sentence based on the words that precede it. Inference – in other words, submitting an input to a model and receiving an output – becomes both more complex and of greater interest as a model grows in size. Next year, I expect prompt engineering – fine-tuning inputs to a model in order to receive a specific type of output – to become a central strategy in the deployment of LLMs. We’ve already seen this take place with the multitude of resources for engineering images generated by models like Stable Diffusion. In 2023, I expect the efforts to refine prompt engineering to take center stage. – Luca Antiga, CTO of [Lightning AI](https://lightning.ai/)  

随着LLM部署的增加，快速工程迅速起飞并获得改进：一旦基础模型被训练，它可以用于解决远远超出预测例如基于句子前面的单词预测句子中的下一个单词的问题。推理-换句话说，将输入提交给模型并接收输出-随着模型规模的增长，变得更加复杂和有趣。明年，我预计快速工程-微调模型的输入以获得特定类型的输出-将成为部署LLM的核心策略。我们已经看到了这一点，这是通过稳定扩散等模型生成的工程图像的大量资源来实现的。在2023年，我预计改进即时工程的努力将占据中心舞台。- Luca Antiga，Lightning AI首席技术官

Generative AI will gain momentum across businesses: Recent advances in AI image generation are making generative AI understandable to people who previously couldn’t picture it or imagine its uses. With image generation, AI has entered the home. Business leaders are hearing about it from their kids and their friends. Once a technology is being talked about by families over the dinner table, it’s poised to change the business landscape. In this way, generative images are paving the way for language models. Generative AI is trained on unfathomable amounts of data. If businesses aren’t figuring out how to operationalize the data they own, they will need to start there. It’s the perfect entry point for partnering with companies that have developed and honed AI tools over the years to accelerate progress in profound ways. Now is the moment for generative AI. –  Lisa Spira, Head of Content Intelligence, [Persado](https://www.persado.com/)  

生成式AI将在企业中获得动力：人工智能图像生成的最新进展使生成式人工智能能够被以前无法描绘或想象其用途的人所理解。随着图像生成，AI已经走进了家庭。商界领袖从他们的孩子和朋友那里听说过这件事。一旦一项技术被家庭成员在餐桌上谈论，它就将改变商业格局。通过这种方式，生成图像为语言模型铺平了道路。生成性AI是在深不可测的数据量上训练的。如果企业不知道如何将他们拥有的数据操作化，他们将需要从那里开始。这是与多年来开发和磨练人工智能工具的公司合作的完美切入点，以深刻的方式加速进步。现在是生成AI的时刻。- 丽莎Spira，Persado内容情报主管

Increased opportunities for deep learning will boost demand for GPUs: The biggest source of improvement in AI has been the deployment of deep learning—and especially transformer models—in training systems, which are meant to mimic the action of a brain’s neurons and the tasks of humans. These breakthroughs require tremendous compute power to analyze vast structured and unstructured data sets. Unlike CPUs, graphics processing units (GPUs) can support the parallel processing that deep learning workloads require. That means in 2023, as more applications founded on deep learning technology emerge to do everything from translating menus to curing disease, demand for GPUs will continue to soar. – [Domino Data Lab](https://www.dominodatalab.com/)’s CEO Nick Elprin  

深度学习机会的增加将推动对GPU的需求：人工智能最大的改进来源是在训练系统中部署深度学习，特别是Transformer模型，这意味着模仿大脑神经元的动作和人类的任务。这些突破需要强大的计算能力来分析大量的结构化和非结构化数据集。与CPU不同，图形处理单元（GPU）可以支持深度学习工作负载所需的并行处理。这意味着到2023年，随着更多基于深度学习技术的应用程序出现，从翻译菜单到治疗疾病，对GPU的需求将继续飙升。- Domino Data Lab首席执行官Nick Elprin

HPC tackles deep learning: As deep learning becomes more prevalent in 2023, we will see a further shift in HPC workloads. While initially most machine learning workloads were run on Kubernetes or other container orchestration frameworks, it’s become clear that these systems are designed for microservices, not for the bursty, computer-intensive machine workloads now required for deep learning. Commercial HPC workload managers need comprehensive container support so organizations can spool their compute and start to take advantage of batch scheduling, cloud bursting, and fare share — all key aspects of efficient HPC. – Altair’s Chief Scientist Rosemary Francis  

HPC解决深度学习：随着深度学习在2023年变得更加普遍，我们将看到HPC工作负载的进一步转变。虽然最初大多数机器学习工作负载都在Kubernetes或其他容器编排框架上运行，但很明显，这些系统是为微服务设计的，而不是为深度学习所需的突发性、计算机密集型机器工作负载设计的。商业HPC工作负载管理器需要全面的容器支持，以便组织可以进行假脱机计算，并开始利用批处理调度、云突发和费用共享-所有这些都是高效HPC的关键方面。Altair首席科学家迷迭香弗朗西斯

The Rise of LLM Applications: Research on large language models will lead to new types of practical applications that can transform languages, text and even images into useful insights that can be used across a multitude of diverse organizations by everyone from business executives to fine artists. We’ll also see rapid growth in demand for the ability to customize models so that LLM expertise spreads to languages and dialects far beyond English, as well as across business domains, from generating catalog descriptions to summarizing medical notes. – KARI BRISKI. Vice President, AI and HPC Software, [NVIDIA](https://www.nvidia.com/)

The rise of generative AI is poised to change the enterprise: Generative AI is emerging as a game-changing technology. James Currier from nfx defines it as a rocketship for the human mind. I believe generative AI can be a rocketship for the Enterprise. This ability of machines to generate, summarize, and perfect enterprise content and communications will digitally transform every function of the enterprise, from finance and legal to marketing or customer services, in 2023 and beyond. If we zoom into commerce next year, we’ll see generative AI further blurring the lines between offline and online/digital commerce. Brands will be able to generate personalized language, images, and even videos, and combine those with personal multimedia experiences that are the closest we have ever seen to walking into a store/branch and getting the most powerful, relevant sales and service interaction. – Assaf Baciu, co-founder and COO, [Persado](https://www.persado.com/)

Generative AI needs maturing: Generative AI will continue to become more powerful and more prominent, but it still needs to develop and mature before it can be used appropriately in industries where the accuracy of statements are critical, such as in finance or medicine. The field includes natural language generators such as [GPT-3](https://s2.bl-1.com/h/drQHr274?url=https://en.wikipedia.org/wiki/GPT-3) language models, which generate natural language using an initial prompt. At Intuit, generative AI may play a pivotal role in helping us create personalized conversational systems to provide financial advice and guidance directly to our customers. But we’ll need to make significant advances in the technology to provide the right advice and guidance at scale. For example, in the ideal scenario, generative AI could provide our human experts financial insights on areas such as cash flow and money movement, along with narratives that would be factually correct and useful for the customer. We’ll also explore using generative AI to help small businesses engage with their customers and help solve their financial problems. – Ashok Srivastava, Senior Vice President & Chief Data Officer at Intuit

Large language models (LLMs) will help people be more creative: We’re likely going to see more solutions like GitHub Co-Pilot where large language models (LLMs) are able to assist people in meaningful ways. These tools are not going to get everything right but they will help solve that initial writer’s block. When you’re staring at a blank page, it’s often hard to get started. But if you can describe the prompt or problem and the model outputs something, it may give you a good starting point and show you something you can use — even if it’s not entirely what you want. Prompt engineering (i.e. instructing models using the right starting text) will become a new way of writing programs, using natural language. I think AI will help in this or similar ways in a lot of domains and it’s very interesting. People thought the big hold-up for AI would be creativity, but ironically it may be the reverse. It may be that AI will actually help us become _more_ creative — by seeding us with initial ideas that we can build upon and refine. – Varun Ganapathi, Ph.D., CTO and co,-founder at [AKASA](http://akasa.com/)

Generative AI Changed How We Create Pictures. Emerging 3D Generative AI Will Simulate the World: Generative AI enabled the creation of 2D images from text prompts, creating new opportunities for artistic expression. Over the next year, we’ll see the technology spur even more transformation as companies take these models one step further to generate 3D models. This emerging capability will change the way games are built, visual effects are produced, and immersive 3D environments are developed. For industrial uses, democratizing this technology will create significant opportunities for digital twins and simulations to train complex computer vision systems, such as autonomous vehicles. – Yashar Behzadi, CEO and Founder of [Synthesis AI](https://synthesis.ai/)

Advances in Generative AI will lead to the democratization of creativity across consumers and businesses. Just as we saw an explosion of user-generated content a decade or so ago we will see an explosion of AI-generated images, videos, art work, blogs, summaries of articles, and articles. This will also change and challenge creative artists to work with AI to produce truly augmented art and creative work. Creative artists will focus more on aesthetics that appeal to certain groups of people and let the AI generate the art that fits the aesthetics. – Anand Rao, Global AI Lead; US Innovation Lead, Emerging Technology Group, PwC

AI will become more accessible across organizations and functions: The recent spike in popularity in [ChatGPT](https://openai.com/blog/chatgpt/) has been heralded as a major breakthrough in delivering safe and useful AI systems that non-technical users can access in a conversational way. In 2023, we can expect more models to be unveiled, as data between the user and the AI assistant will find ways to improve how departments – from marketing, sales, HR and others – will work. – Keshav Pingali, co-founder and CEO of [Katana Graph](https://katanagraph.com/)

With the introduction of Generative AI comes the increase of content on the internet. As user-generated content grows, the need to search for this content effectively will only become greater. The best way of engaging with all this new content is through text, which will be the widely used interface to describe images, videos and audio in the near future. The same neural networks that assist Generative AI in creating content will also help change and transform our engagement with this influx of new information through the summarization, categorization, and language translation of content across the internet. Organizations will seek pipelines for extracting, storing, and servicing this content within existing web applications and analytic interfaces. As a result, semantic processing and serving engines will become an integral part of modern application architectures, sitting in front of, behind, and/or on top of data lakes, data warehouses, and application data pipelines. – Ed Albanese, Chief Operating Officer at [Vectara](https://vectara.com/)

Generative AI results are both spectacular and concerning. They are spectacular because they appear structurally and semantically coherent even in long dialogs. They are concerning because they generate words and phrases to fill in gaps not founded on truth, fact, evidence, or even logical consistency. As the popularity of this powerful but easily misunderstood technology spreads, we will see a push to enforce more legislation surrounding best practices in artificial intelligence. This type of legislation will require that AI systems be hybrid systems, that they may find statistical patterns in the data but also use other AI techniques that interpret the data with respect to rational and transparent models of values, rules, and judgments. The result is a system that does not just blindly follow the data but can subject the implicit trends to a rational process. These types of hybrid AI systems are necessary for the broader acceptance, transparency, and responsible integration of AI in human decision processes. – Dr. David Ferrucci CEO and Founder of [Elemental Cognition](https://ec.ai/)

These last few weeks of the year, we’ve seen the power of generative AI take off and grab the attention of the public. ChatGBT and AI-powered artistry wow people as they see what’s possible via artificial intelligence. As we enter 2023, I anticipate we’ll see large language models (LLMs) move to the forefront of the conversation of what can be possible not only for consumers, but in an enterprise setting. AI-powered and deep learning based LLMs have allowed computers to better understand human language. Instead of training models to observe the structure of sentences, neural networks have allowed them to understand more complex semantics. As this technology continues to develop, we’ll see how it can impact job functions across every department and industry, transforming how knowledge workers approach their roles and ultimately aiding people in becoming smarter, faster and better at work. – Arvind Jain, CEO and co-founder of [Glean](http://glean.com/)

Generative AI becomes a marketer’s best friend: Now that generative AI can create compelling text, images, and videos, marketers will need to decide the extent to which they implement the technology. At the very least, AI can support existing content creation workflows, but in the near future, it could become responsible for new content creation processes that won’t require any support from humans. – Thomas Peham, VP of Marketing, Storyblok

Deep learning capabilities will edge further into the mainstream as more popular consumer use cases are adopted such as image recognition for authentication, video processing and object detection for security use. This is thanks to the increased efficiency of convolutional neural networks (CNN). Such technology will make way for semantic segmentation and even more real time use cases like self-driving cars, computing emotions during e-commerce purchases or enterprise sales calls, and improved health care support.  – Bal Heroor, CEO of [Mactores](https://mactores.com/)

**Graph**

I’ve always been a proponent of graphs, and it appears that the industry has finally come around to graph technology (database and compute) over the past year. Many contemporary data challenges can be solved with graphs at the data engineering, data science, and user levels. Graphs were previously utilized in a small number of critical systems, including the manufacturing and transportation of medicines during the pandemic, but I predict graph usage to increase in the coming year and become more widespread. While the pattern will be similar, it will be more broadly democratized. – Jim Webber, Chief Scientist, [Neo4j](https://neo4j.com/)

Causal Knowledge Graphs will Emerge: The next few years will see growth in Causal AI starting with the creation of Knowledge Graphs that discover causal relationships between events. Healthcare, pharma, financial services, manufacturing and supply chain organizations will link domain-specific knowledge graphs with causal graphs and conduct simulations to go beyond correlation-based machine learning that relies on historical data. Causal predictions have the potential to improve the explainability of AI by making cause-and-effect relationships transparent. – Jans Aasman, Ph.D., an expert in Cognitive Science and CEO of [Franz Inc](https://franz.com/).

Graph neural networks will be particularly influential in AI applications: Whether it’s halting information fraud or security in real time, or uncovering more effective healthcare treatments, innovations in graph can identify relationships in data that users otherwise wouldn’t see. Solutions focused on extrapolating insights from unstructured data will further support a range of enterprise use cases. – Keshav Pingali, co-founder and CEO of [Katana Graph](https://katanagraph.com/)

One hot topic in AI tech right now is knowledge graphs, which basically adds another layer to data sets and allows you to describe properties and relationships between entities. This technology will have practical applications in various industries, but we might see it used in social media and digital marketing in 2023. One example is the ability to detect and even predict the real impact of an online influencer or opinion leader based on the data of their network and interactions. We’ll also be able to predict whether a piece of content will go viral. – [Erudit](https://www.erudit.ai/)’s Chief Science Officer & Co-founder, Ricardo Michel Reyes

**Hardware**

AI Becomes Cost-Effective With Energy-Efficient Computing: In 2023, inefficient, x86-based legacy computing architectures that can’t support parallel processing will give way to accelerated computing solutions that deliver the computational performance, scale and efficiency needed to build language models, recommenders and more. Amidst economic headwinds, enterprises will seek out AI solutions that can deliver on objectives, while streamlining IT costs and boosting efficiency. New platforms that use software to integrate workflows across infrastructure will deliver computing performance breakthroughs — with lower total cost of ownership, reduced carbon footprint and faster return on investment on transformative AI projects — displacing more wasteful, older architectures. – CHARLIE BOYLE, Vice President, DGX systems, [NVIDIA](https://www.nvidia.com/)  

人工智能通过节能计算变得具有成本效益：到2023年，无法支持并行处理的低效、基于x86的传统计算架构将给予于加速计算解决方案，这些解决方案提供构建语言模型、推荐器等所需的计算性能、规模和效率。在经济逆风中，企业将寻求能够实现目标的人工智能解决方案，同时简化IT成本并提高效率。使用软件集成跨基础设施的工作流的新平台将带来计算性能的突破-降低总拥有成本，减少碳足迹，并加快变革性AI项目的投资回报-取代更浪费的旧架构。- NVIDIA DGX系统副总裁CHARLIE波义耳

Green Computing for a Sustainable Future: As the threat of the global energy crisis and recession continue and companies become more mindful of their carbon footprint, more and more enterprises—especially the mid-to higher-end—will significantly accelerate their investment in cloud adoption to securely and efficiently manage both modern and legacy applications. While the cloud is not perfect when it comes to sustainability, it is more eco-friendly than traditional data centers. And with more companies shifting workloads to the cloud, cloud providers will continue to invest in renewable energy sources to enable environmentally friendly cloud-native applications. – Prashant Ketkar, Chief Technology and Product Officer at [Alludo](https://www.alludo.com/en/)  

绿色计算为可持续未来：随着全球能源危机和经济衰退的威胁继续存在，企业越来越关注碳足迹，越来越多的企业（尤其是中高端企业）将大幅加快对云采用的投资，以安全高效地管理现代应用和传统应用。虽然云在可持续性方面并不完美，但它比传统数据中心更环保。随着越来越多的公司将工作负载转移到云端，云提供商将继续投资于可再生能源，以实现环保的云原生应用。- Prashant Ketkar，Alludo首席技术和产品官

The foundation for our future is the implementation of composable infrastructure. This technology advancement will become critical in 2023, allowing enterprises to succeed and grow despite economic downturns and dwindling resources. Composable infrastructure reduces our reliance on technical experts, removes bottlenecks, and allows innovation from everyone involved. The modularity afforded by this model brings  greater compartmentalization and specialization, with digital capabilities embedded throughout the business. Our efforts to liberate quick innovation supports Moore’s law, in which computational progress  becomes significantly faster, smaller, and more efficient over time. Enterprises that don’t keep up with the quick changes coming will fall behind. According to Gartner, organizations that adopt a composable approach in 2022 will [outpace their competition by 80%](https://www.gartner.com/en/newsroom/press-releases/2021-10-18-gartner-identifies-the-top-strategic-technology-trends-for-2022) in new feature implementation. As adoption of composable infrastructure grows, we will see a shift towards a more centralized IT model. While IT won’t disappear, the old system will change. Instead, more responsibility will rest within the business where we’ll see the hiring of technical people, developers, and others who support and embrace the new approach. – Tam Ayers, Field CTO, North America at [Digibee](https://www.digibee.com/)  

我们未来的基础是实现可组合的基础设施。这种技术进步将在2023年变得至关重要，使企业能够在经济低迷和资源减少的情况下取得成功和增长。可组合的基础设施减少了我们对技术专家的依赖，消除了瓶颈，并允许每个参与者进行创新。该模型提供的模块化带来了更大的划分和专业化，数字化功能嵌入到整个业务中。我们为解放快速创新所做的努力支持摩尔定律，即随着时间的推移，计算进程变得更快、更小、更高效。不能跟上即将到来的快速变化的企业将落后。根据Gartner的数据，在2022年采用可组合方法的组织将在新功能实施方面超过竞争对手80%。 随着可组合基础设施的采用不断增长，我们将看到向更集中的IT模式转变。虽然IT不会消失，但旧的系统会改变。相反，更多的责任将落在业务中，我们将看到技术人员、开发人员和其他支持和拥抱新方法的人的雇佣。 - Tam Ayers，Digibee北美区Field CTO

The AI computing war will reach a fever pitch: The [race](https://techcrunch.com/2022/11/16/microsoft-and-nvidia-team-up-to-build-new-azure-hosted-ai-supercomputer/) for evermore powerful AI supercomputers will shift into high gear and will introduce a new problem, being able to feed data fast enough with higher bandwidth and low latency. – Tony Pialis, CEO of [Alphawave](https://www.awaveip.com/en/home/)  

AI计算战争将达到白热化程度：对更强大的人工智能超级计算机的竞争将进入高速发展阶段，并将引入一个新的问题，即能够以更高的带宽和更低的延迟足够快地馈送数据。- Tony Pialis，Alphawave首席执行官

As Generative AI and its resulting content explodes, the energy consumption and load on hardware chips will only increase and accelerate: Generative AI is taking the internet by storm. Now publicly accessible, new AI technology, such as AI-generated portraits and artwork, is proliferating across social platforms. This sudden increase in access and popularity will have a direct impact on the energy consumption load placed onto hardware chips. Already, current AI models running on traditional chips require massive computing power from data centers. Given the demand for AI and ML, its compounding annual growth rates, and the ever-increasing need for compute power, we’re already facing a crisis. In 2023, hyperscalers will need to factor in this energy consumption as AI and ML continue to see explosive growth through content creation of generative AI. – Nicholas Harris, CEO and founder of [Lightmatter](https://lightmatter.co/)  

随着Generative AI及其产生的内容爆炸式增长，硬件芯片的能耗和负载只会增加和加速：生成性AI正在掀起互联网风暴。现在，新的人工智能技术，如人工智能生成的肖像和艺术品，正在社交平台上激增。接入和普及的这种突然增加将对置于硬件芯片上的能耗负载产生直接影响。目前，在传统芯片上运行的人工智能模型已经需要数据中心的巨大计算能力。鉴于对AI和ML的需求，其复合年增长率，以及对计算能力的不断增长的需求，我们已经面临危机。到2023年，超大规模者将需要考虑这种能源消耗，因为AI和ML通过生成AI的内容创建继续实现爆炸式增长。- - Nicholas Harris，Lightmatter首席执行官兼创始人

**IoT and Edge Computing 物联网和边缘计算**

IoT will become more accessible for IT: Companies need to ensure they have the same tools, APIs, and infrastructures from the cloud to the edge to ensure their teams don’t have to re-learn things. Providers need to make tools/devices more uncomplicated, more accessible for companies to innovate and leverage them, and easier to enter the market as the adoption of IoT technologies continue to grow. Many companies will start leveraging IoT technologies to drive business and operational transformation by extending the benefits of the cloud to the edge. It is important to bring the agility, elasticity, economics, scale, and security of the cloud to the edge. – Yasser Alsaied, VP of IoT at AWS  

物联网将变得更容易为IT：公司需要确保他们从云到边缘都拥有相同的工具、API和基础设施，以确保他们的团队不必重新学习。供应商需要使工具/设备更简单，更容易让公司创新和利用它们，并且随着物联网技术的采用继续增长，更容易进入市场。许多公司将开始利用物联网技术，通过将云的优势扩展到边缘来推动业务和运营转型。将云的敏捷性、弹性、经济性、规模和安全性带到边缘非常重要。- AWS物联网副总裁Yasser Alsaied

In 2023, it will become clearer that succeeding in the IoT space is all about working in an ecosystem of applications instead of a singular application. An IoT platform means you’re able to bring in more third-party sensors and devices to add to your arsenal of sensing, and you’re also able to push out the data you’re collecting to other platforms using APIs. – Sammy Kolt, Chief Product Officer, [SmartSense](https://www.smartsense.co/) by Digi®, a business unit of Digi International   

到2023年，物联网领域的成功将变得更加清晰，这一切都是关于在应用程序生态系统中工作，而不是单个应用程序。物联网平台意味着您可以引入更多的第三方传感器和设备来添加到您的传感库中，并且您还可以使用API将您收集的数据推送到其他平台。- Sammy Kolt，Digi International业务部门SmartSense by Digi®首席产品官

Connected device visibility and security will be a major area of focus for most organizations: IoT-connected devices have been deployed by most organizations over the years, but often without adequate security governance.  As the number of IoT-, OT-, ICS- and IIoT-connected devices grows, the attack surface for the networks and ecosystems to which they’re connected grows as well, creating exponentially more security, data, and privacy risks. Leading organizations will focus in the year ahead on connected device cyber practices by establishing or updating related policies and procedures, updating inventories of their IoT-connected devices, , monitoring and patching devices, honing both device procurement and disposal practices with security in mind, correlating IoT and IT networks, monitoring connected devices more closely to further secure those endpoints, manage vulnerabilities, and respond to incidents. – Wendy Frank, Deloitte’s US Cyber IoT leader  

互联设备可见性和安全性将是大多数组织关注的主要领域：多年来，大多数组织已经部署了物联网连接设备，但通常没有足够的安全治理。 随着物联网、OT、ICS和IIoT连接设备数量的增长，它们所连接的网络和生态系统的攻击面也在增长，从而带来了呈指数级增长的安全、数据和隐私风险。领先的组织将在未来一年通过以下方式关注连接设备网络实践：建立或更新相关政策和程序，更新其物联网连接设备的库存，监控和修补设备，在考虑安全性的情况下完善设备采购和处置实践，将物联网和IT网络相关联，更密切地监控连接设备以进一步保护这些端点，管理漏洞，并对事故作出反应。- - Wendy Frank，德勤美国网络物联网负责人

Edge Data: 2023 will increase opportunities for cloud and network convergence and force a rethinking of IT architectures, especially at the edge and for mobile environments where it meets the physical world. The explosive growth of edge data, driven by IIoT adoption and 5G, will allow companies to quickly process and analyze data where it lives and where quick responses are required. – Bjorn Andersson, senior director of global digital innovation marketing and strategy, Hitachi Vantara  

边缘数据：2023年将增加云和网络融合的机会，并迫使人们重新思考IT架构，特别是在边缘和与物理世界相遇的移动的环境中。在IIoT采用和5G的推动下，边缘数据的爆炸性增长将使公司能够快速处理和分析数据，并在需要快速响应的地方进行快速处理和分析。- Hitachi Vantara全球数字创新营销和战略高级总监Bjorn Andersson

Distributed communication and data processing will become a new trend: With a movement towards edge computing, more resources are available on the edge. As 2022 comes to a close, many companies have started deploying edge infrastructure. The need to balance costs has resulted in a tradeoff. The newly gained computing powers come at the expense of reduced centralized resources. This new distribution of computing creates a new challenge: Effectively using the “enterprise-wide data center” for workload execution. A distributed — but low-power — infrastructure requires new models of workload management and leads to needs around distributed data processing and better means of near-real-time communication across distributed platforms. As those needs grow, new and advanced technology solutions will enter a new market to address this demand. We will see a resurrection of torrent-like P2P Networking models and blockchain-based validation algorithms will emerge and establish themselves. – Ekim Maurer, director of product management, [**NS1**](http://www.ns1.com/)  

分布式通信和数据处理将成为新趋势：随着向边缘计算的发展，更多的资源在边缘上可用。随着2022年即将结束，许多公司已经开始部署边缘基础设施。平衡成本的需要导致了一种权衡。新获得的计算能力是以减少集中资源为代价的。这种新的计算分布带来了新的挑战：有效地利用“企业范围的数据中心”执行工作负载。分布式但低功耗的基础设施需要新的工作负载管理模型，并导致对分布式数据处理和跨分布式平台近实时通信的更好手段的需求。随着这些需求的增长，新的和先进的技术解决方案将进入一个新市场，以满足这一需求。我们将看到类似洪流的P2P网络模型的复活，基于区块链的验证算法将出现并建立自己。 - Ekim Maurer，NS 1产品管理总监

Analytics at the Edge Will Go Mainstream: Analytics at the edge may not be a new concept, but 2023 will see more happening at the edge than ever before. Today’s terminal devices are almost as powerful as a low-end server, and the increasing availability of 5G networks has enabled the transmission of more data at higher speeds. As more data is pushed to the edge, it will enable real-time decision making in the field, shorten response times, and reduce the compute, storage, and network costs of cloud infrastructure. For these reasons, along with lower technical barriers, we are sure to see greater adoption of analytics at the edge in 2023. – James Li, CEO of [CelerData](http://www.celerdata.com/)

The Edge will remain a nebulous and disputed concept: Edge is a bad name for a distributed compute paradigm. There is simultaneously no edge to the Internet, and many Edges, depending on your perspective. The debate will continue to rage about where the Edge is and whether some distributed systems are more or less “Edge-y” than others. What will not be disputed is that distribution of applications to wider hosting footprints has advantages with respect to elements such as latency, reliability, redundancy and data backhaul cost. So maybe a new phrase will emerge with a focus on application distribution rather than Edge. – Stewart McGrath, co-founder and CEO of [Section](https://www.section.io/) 

IoT will become a universal business decision and will be an expectation rather than an exception: Many businesses and industries will continue to invest in IoT because it provides business and operational value. For example, agriculture companies use IoT technology to expand their business by adding precision agriculture tools into their vehicles and improving their factory operations with digital twins. We are consistently seeing new customer segments, like the retail industry, unlocking the value of IoT. Customers are trying to formulate a unified experience that traverses easily between online and offline (O2O), resulting in the convergence with mobile, social media, and the Internet of Things (IoT) that can serve wherever and whenever they desire. Customers are also broadening their sustainability initiatives to go beyond emission reduction to create a smart building or smart city environment leveraging IoT to monitor energy performance, reduce waste, and align facility operations with occupancy trends. – Yasser Alsaied, VP of IoT at AWS

As sensor technologies become embedded in enterprises across industries, IoT strategies have started fueling the products and services that shape our world today. However, IoT’s growth is also causing enterprises to amass data at an unmanageable rate. IoT data is increasingly becoming trapped in edge environments, limiting enterprises’ ability to derive its full value. Throughout 2023, enterprises will realize that they are not only losing money at the edge but also insights that can guide organizational decision-making, fuel new partnerships and reveal new business models. As the scale of this loss becomes clearer, enterprises will experiment with ways to move IoT data to the cloud, and solutions for large-scale and continuous IoT migrations will become mission-critical. – Paul Scott-Murphy, Chief Technology Officer of [WANdisco](https://wandisco.com/)

**Kubernetes**

Organizations will prioritize easy-to-maintain technology to bridge the skills gap: Accelerated digital transformation has led to more distributed IT infrastructures, with Kubernetes becoming the de facto standard for managing containerized environments. Although there are many benefits to using Kubernetes in hybrid and multi-cloud environments, Kubernetes is a complex technology that requires deep technical skills to deploy and manage. Because Kubernetes is a relatively new technology, the talent pool of skilled Kubernetes engineers is limited. This is why we expect to see organizations gradually abandon DIY Kubernetes projects and put their budgets toward training and technology for their Kubernetes deployments and projects. Considering the economic uncertainty over the next year, CIOs and business decision-makers are being forced to look at their budgets closely and be more selective on which technology investments to move forward with. One critical factor during this time is the growing skills gap in emerging technology sectors. In an effort to bridge this gap, technology and tools that are both impacting the business’s bottom line and are easy to deploy and maintain will rise to top priority. – Tobi Knaup, CEO and co-founder of [D2iQ](https://d2iq.com/)

AI and ML workloads running in Kubernetes will overtake non-Kubernetes deployments: AI and ML workloads are picking up steam but the dominant projects are still currently not on Kubernetes. We expect that to shift in 2023. There has been a massive amount of focus put into adapting Kubernetes in the last year+ with new projects that make it more attractive for developers. These efforts have also focused on adapting Kubernetes offerings to allow for the compute intensive needs of AI and ML to run on GPUs to maintain quality of service while hosted on Kubernetes. – Patrick McFadin, [DataStax](https://www.datastax.com/)’s VP of Developer Relations

Edge burns white-hot: Kubernetes may have gained popularity as the operating system for the data center, but its real value may prove to be at the edge, where its portable and resilient application workloads can power an almost infinite variety of digital business processes and customer experiences. Our [research](https://thenewstack.io/new-research-shows-the-future-is-bright-for-edge-kubernetes/) has found that already 35% of production Kubernetes users are running Kubernetes at the edge, and many many more plan to do so in the next 12 months. The use cases are incredibly varied, from fruit-picking drones to AI on MRI machines, and many of them have the potential to drive revenue and competitive differentiation for the companies that get them right. But the challenges are equally immense, from manageability to security. 2023 is the tipping point, when the challenges get hit head-on, and edge truly goes mainstream.

More large-scale analytics and AI workloads will be containerized, but the talent pool is a bottleneck: In the cloud-native era, Kubernetes has become the de facto standard, with a variety of commercial platforms available on the market. Organizations are increasingly deploying large-scale analytics and AI workloads in containerized environments. While containers provide many benefits, the transition to containers is very complex. As a result, in 2023 the main bottleneck to container adoption will be the shortage of talent with the necessary skill set for tools like Kubernetes. – Haoyuan Li, Founder and CEO, [Alluxio](https://www.alluxio.io/)

The rise of Kubernetes as a Service: Kubernetes has been described as an operating system for containers. As workload management continues to expand to serverless and virtual machines, and the operations ecosystem (e.g., security and observability) matures and hardens, we will see Kubernetes more abstracted from users. No developer working on building an application really needs (or probably wants) to understand and manage Kubernetes. What they really want is the benefits of Kubernetes when managing their applications in production. In the same way, no developer wants to manage Linux or even the servers on which it runs, so cloud computing gave us compute as a service. Kubernetes is one layer above that compute, and a natural fit for an “as a service” offering; in 2023 we’ll see that take off. – Stewart McGrath, co-founder and CEO of [Section](https://www.section.io/)

Kubernetes goes mission-critical: Over the last 24 months, Kubernetes has become mainstream. Containers are now being adopted in mission critical environments, meaning that the application environment and the underlying data in these environments now needs protection. Now, ownership of these containers and the protection of them has become more complex, creating silos and confusion over if it’s the backup admin or the DevOps admin that’s responsible. At the same time, organizations are struggling to identify which containers to back up and how to do so, which will likely lead to more investment in training to help close the Kubernetes skills gap. In 2023, IT departments will continue to navigate how to adequately protect and backup their Kubernetes environments. – Deepak Mohan, EVP of Engineering at [Veritas Technologies](https://www.veritas.com/)

Kubernetes’ complexity will continue to be an issue: Kubernetes is one of those technologies that everyone uses because they have to but nobody likes – sort of like Maven during the heyday of Java. There have been a number of attempts to build something like Kubernetes, but simpler, including K3S, MDSO, and others. However, none of these technologies seem to be gaining significant traction. In 2023, people will keep trying to build simpler technologies and someone may succeed. This is the kind of product I would expect Hashicorp to do well. – Mike Loukides, Vice President of Emerging Tech Content at [O’Reilly Media](http://www.oreilly.com/)

2023 Will See The Taming of Kubernetes Chaos: The “great K8s irony” is that the very technology that was created to streamline the management of cloud applications is, itself, incredibly difficult to manage. Enterprise adoption of Kubernetes is often stalled by the staggering amount of disparate tools and software addons that need extensive integration and maintenance, especially as the number of workloads and clusters increase. Consequently, enterprises struggle to maintain the increasing time, cost and resources needed to manage this “Kubernetes jigsaw puzzle.” In 2023, leaders will realize that platform teams are essential to solving the Kubernetes jigsaw puzzle and tame the Kubernetes chaos. Eliminating the complexities of Kubernetes from developers’ workloads, platform teams bring an operational mindset to internal tools and workflows that enable them to help manage and operate Kubernetes at scale. – Mohan Atreya, SVP product and solutions, [Rafay Systems](https://rafay.co/)

**Low-code/No-code**

No-code / no-brain AI. Advanced machine learning technologies will enable no-code developers to innovate and create applications never seen before. This evolution may pave the way for a new breed of development tools. – Esko Hannula, Sr. VP of Product Management at [Copado](http://www.copado.com/)

Rise of low-code and no-code AutoML: In 2023, there will be greater availability of industrialized AI through low-code and no-code automated machine learning (AutoML). The models will be provided through self-service marketplaces and can be enhanced with packaged services for customization and deployment. – Jason Mann, Vice President of IoT, SAS

An emergence of low-code CX: The past few years have highlighted the need for enterprises to pivot to meet the ever-shifting landscape of customer needs efficiently. Next year, we’ll see an increase in user-friendly, low-code processes and systems to create a seamless customer experience across a myriad of touchpoints and systems. Vendors will embrace Industry-standard APIs to allow enterprises to integrate their CX ecosystem connecting internal and external systems painlessly. – Dr. Prateek Kapadia, Chief Technology Officer at [Flytxt](https://www.flytxt.com/) 

Low-code will be a top priority for democratizing automation and AI. Simple-to-use tools help both experienced and beginner technical workers do more with more of their technology. With low-code, business users unfamiliar with analytics can still tap into their knowledge and expertise to train sophisticated AI models to solve for challenges. – Ted Kummert, Executive Vice President of Products & Engineering at [UiPath](https://www.uipath.com/)

Low code/no code applications will create compliance issues: Low code/no code application development has been instrumental in democratizing application development across companies. In 2023, low code/no code adoption will become mainstream, and non-technical employees (citizen developers) across any organization will have the power to create their own app. While this will significantly alleviate the burden on IT teams, it will also create a big compliance risk for organizations. Because citizen developers don’t have the same experience in implementing security and privacy, most of the applications they develop won’t be adequately protected and protection policies may be inaccurately applied. As a result, not only will organizations face compliance issues, their applications may also create new vulnerabilities for bad actors to exploit. – Deepak Mohan, EVP of Engineering at [Veritas Technologies](https://www.veritas.com/)

Modern no-code and low-code solutions will follow a bottom-up approach: No-code and low-code platforms like AirTable have been instrumental in democratizing company data. However, while they provide highly intuitive facades for non-technical business users, their top-down architecture is extremely limiting or inaccessible to engineers. While quickly adoptable, these band-aide services have an unconsidered backend that is unable to scale, and therefore needs to be replaced over time. In the coming years, modern NC/LC solutions will follow a bottom-up approach that lays a foundational data layer comprised of powerful developer tools, performant APIs, tailored data stores, and an unopinionated tech stack. True data democratization can’t be achieved without equally enabling both non-technical and highly technical users. – Ben Haynes, co-founder/CEO of [Directus](http://www.directus.io/)

2023 will be low-code’s time to shine as the developer shortage continues. The real mark of a great developer is not the project they do, it’s the selection of the projects among many. Organizations will need to deploy their technological talent very smartly. No one can afford to deploy them on a haphazard basis. – Gordon Allott, CEO of [BroadPeak Partners](https://getk3.com/)

AI will be brought more heavily into the low-code equation: Artificial intelligence will increasingly enable software development processes that are more proactively guided and written by other software. This will allow business users to create new applications using text prompts with the assistance of the application development tools. While this prospect may cause professional developers to feel anxious, the shift promises to create new opportunities within IT, rather than eliminate old ones. Software developers will become adept at enabling this evolution by learning how to provide the right prompts to an AI tool to generate the code that a no-code application developer will need.  Also, generally, at a fundamental level AI, AR+VR and simulation software are going to rule. To support this necessary backbone, trends in improving compute network and storage are going to take an exponential leap in the next 3-5 years. So, tech changes will be driven at compute, storage and network level! IT departments will increasingly rely on the “business technologist”: Low-code options have created a new persona in the workplace: the business technologist—also known as “citizen developer”—who can participate in the application development process. As of now, the IT department still does the heavy lifting of application development, but in 2023 and beyond, business users will increasingly be able to create applications end-to-end with relatively little intervention from developers. This shift will allow developers to focus on maintaining large-scale strategic projects, while monitoring the long tail of the applications being built by business technologists. – Lloyd Adams, President, SAP North America  

AI将被更大程度地引入低代码方程式：人工智能将越来越多地支持软件开发过程，这些过程更主动地由其他软件指导和编写。这将允许业务用户在应用程序开发工具的帮助下使用文本提示创建新的应用程序。虽然这种前景可能会让专业开发人员感到焦虑，但这种转变有望在IT领域创造新的机会，而不是消除旧的机会。软件开发人员将通过学习如何向AI工具提供正确的提示来生成无代码应用程序开发人员所需的代码，从而熟练地实现这种演变。 此外，一般来说，在基础层面，AI、AR+VR和仿真软件将占据主导地位。为了支持这一必要的主干，计算网络和存储的改进趋势将在未来3-5年内实现指数级飞跃。 因此，技术变革将在计算、存储和网络层面推动！IT部门将越来越依赖“业务技术专家”：低代码选项在工作场所创造了一个新的角色：业务技术人员-也称为“公民开发人员”-可以参与应用程序开发过程。到目前为止，IT部门仍然承担着应用程序开发的重任，但在2023年及以后，业务用户将越来越多地能够在开发人员相对较少的干预下创建端到端应用程序。这种转变将使开发人员能够专注于维护大型战略项目，同时监控业务技术人员构建的应用程序的长尾。 - Lloyd亚当斯，SAP北美区总裁

Economic uncertainty will make low-code tools an enterprise necessity: In today’s rapidly changing environment, businesses are moving faster than ever before to innovate and gain market traction amid inflation, a looming economic recession, tightening budgets and continued supply chain issues. This means that enterprises can no longer afford to wait for months to get engineering and IT resources to update their systems. A well-built low- or no-code platform gives businesses the ability to quickly build applications that solve an even broader range of use cases. When seeking new low-code tools, companies should make sure they can integrate seamlessly with their existing systems. Low-code tools should be easy to configure, ensuring faster implementation and time to value. Low-code tools also need the ability to grow with a company. This requires the tools to have a stable platform, reliable performance and the ability to process data at scale. With these features in mind, low-code tools will soon become a requirement for any business looking to modernize their business processes. – Lu Cheng, Co-founder and CTO, [Zip](https://ziphq.com/)  

经济的不确定性将使低代码工具成为企业的必需品：在当今快速变化的环境中，企业正在比以往任何时候都更快地进行创新，并在通货膨胀、经济衰退迫在眉睫、预算紧缩和供应链问题持续不断的情况下获得市场牵引力。这意味着企业再也不能等待数月才能获得工程和IT资源来更新其系统。构建良好的低代码或无代码平台使企业能够快速构建解决更广泛用例的应用程序。在寻求新的低代码工具时，公司应该确保它们可以与现有系统无缝集成。低代码工具应该易于配置，确保更快的实现和更快的价值实现。低代码工具还需要与公司一起成长的能力。这就要求这些工具具有稳定的平台、可靠的性能以及大规模处理数据的能力。 考虑到这些特性，低代码工具将很快成为任何希望实现业务流程现代化的企业的必需品。 - -Zip联合创始人兼CTO陆成

**Machine Learning 机器学习**

The data science and ML community will actively embrace more standardization: Today’s data science and machine learning market is still very fragmented, while the pace of innovation remains rapid. In 2023, we will see the desire for standardization led by two key driving forces — the traditional Python community focusing more on successful productization of Python code, and a growing group of enterprises who are fast becoming important stakeholders in Python. Both groups are eager to realize a long-time stable, trusted platform on which they can build. We see ML standardization already in progress with the four leading ML frameworks: Sci-Kit Learn, XGBoost, PyTorch, and TensorFlow.  Any innovator will naturally use one of these very popular broadly adopted frameworks versus another alternative. I expect the data science and ML community will continue to move towards standardization, which is very healthy for the entire market space as we’ve seen previously play out for other areas, for example, in the Linux community. – Torsten Grabs, Director of Product Management, Snowflake   

数据科学和ML社区将积极拥抱更多的标准化：今天的数据科学和机器学习市场仍然非常分散，而创新的步伐仍然很快。到2023年，我们将看到标准化的愿望由两个关键驱动力主导--传统的Python社区更专注于Python代码的成功产品化，以及越来越多的企业正在迅速成为Python的重要利益相关者。这两个群体都渴望实现一个长期稳定的、值得信赖的平台，他们可以在此基础上进行建设。我们看到ML标准化已经在四个领先的ML框架中进行：Sci-Kit Learn、XGBoost、PyTorch和TensorFlow。 任何创新者都会自然地使用这些非常流行的广泛采用的框架之一，而不是另一种替代方案。 我预计数据科学和机器学习社区将继续朝着标准化方向发展，这对整个市场空间来说是非常健康的，正如我们之前在其他领域看到的那样，例如在Linux社区。 - Snowflake产品管理总监Torsten Grabs

The uptake of digital technologies in manufacturing in 2022 was surprising. In 2023, we’ll see manufacturers continue to invest in machine learning for factory optimization, specifically white-box (transparent) machine learning so that they can generate ROI from data harmonization efforts. In addition, infrastructure sectors (steel, cement) will see more activity as last year’s Infrastructure Bill is tapped into. Within these sectors, there will be increasing interest in AI and machine learning as they pursue decarbonization solutions. – Berk Birand, co-founder and CEO of [Fero Labs](https://www.ferolabs.com/)

While we have seen more attention to correcting gender bias, machine learning will continue reducing the bias. In conversational AI, systems that “know the customer” by leveraging information about that particular person will also reduce bias. – [Language I/O](https://languageio.com/) Chief Technology Officer Diego Bartolome

Automating ML workflows will become more essential: Although we’ve seen plenty of top technology companies announce layoffs in the latter part of 2022, it’s likely none of these companies are laying off their most talented machine learning personnel. However, to fill the void of fewer people on deeply technical teams, companies will have to lean even further into automation to keep productivity up and ensure projects reach completion. We expect to also see companies that use ML technology put more systems into place to monitor and govern performance and make more data-driven decisions on how to manage ML or data science teams. With clearly defined goals, these technical teams will have to be more KPI-centric so leadership can have a more in-depth understanding of machine learning’s ROI. Gone are the days of ambiguous benchmarks for ML. – Moses Guttmann, CEO and Co-Founder of [ClearML](https://clear.ml/)

Data needs a seat at the table as AI grows: As AI and machine learning continue to grow and become more commonplace, the data fueling these applications will need a seat at the decision maker’s table. In 2023, we will see continued development of data teams and data leadership roles.  The Chief Data Officer position will continue to expand, furthering its rise as the fastest growing CxO position amongst Global 2000 enterprises. – Stijn Christiaens, Co-Founder & Chief Data Citizen at [Collibra](https://www.collibra.com/us/en)

SaaS will be all about specialization: Most cloud providers have become comparable in basic capabilities and there is very little to differentiate them. The journey from here is going to be about specialization. Companies will need to start diving a little deeper into the key value they are looking for and which cloud provider can provide it best. For example, for some AI and ML capabilities, there may be a specific cloud that has a significant upper hand or for PaaS there could be another cloud which delivers a significant discount based on previous usage. For organizations to drive the value needed to stay competitive it will be critical to have the right infrastructure and tools in place to effectively manage data & operations in a multi-cloud environment. – Amit Rathi, VP of Engineering, [Virtana](https://www.virtana.com/)

AutoML synergies will help to ease tensions between citizen and hardcore data scientists: In 2023, we will see the breaking down of the artificial barrier that has existed between two former factions — the early emerging citizen data scientists versus the hardcore data scientists and ML engineers. The conflict over the merits of Automated Machine Learning (AutoML) as opposed to traditional hand-coded ML models will disappear in favor of synergy between the two camps and the two types of ML. We’ll see hardcore data scientists and ML engineers change their view of AutoML, and adopt it as a quick start to reach an initial draft of a ML model by an order of magnitude over their prior hand-coded approach. AutoML will be the car that contains the ML engine. So while citizen data scientists use AutoML, the data scientists and ML engineers will be able to crack open the hood of the AutoML car to be able to fine tune the complex ML engine inside. – Torsten Grabs, Director of Product Management, Snowflake

Hoarding ML talent is over: Recent layoffs, those working with machine learning specifically, are likely the most recent hires as opposed to the more long-term staff that have been working with ML for years. Since ML and AI has become a more common technology in the last decade, many big tech companies began hiring these types of workers because they could handle the financial cost and keep them away from competitors – not necessarily because they were needed. From this perspective, it’s not surprising to see so many ML workers being laid off considering the surplus within larger companies. However, as the era of ML talent hoarding ends, it could usher in a new wave of innovation and opportunity for startups. With so much talent now looking for work, we will likely see many of these folks trickle out of big tech and into small and medium-sized businesses or startups. – Moses Guttmann, CEO and Co-Founder of [ClearML](https://clear.ml/)

End User Experience Becomes A Top Priority: As deep integrations of data platforms become standard, the reduced complexity will usher a focus on end user experience. The data platform will become abstracted even further to end users. Instead of worrying about the underlying engines and data structures, end users will be able to easily and seamlessly leverage powerful underlying engines for interactive, batch, real-time, streaming and ML workloads. – Steven Mih, Co-founder and CEO, [Ahana](http://www.ahana.io/)

Most ML Projects Still Fail: This is not a maturity issue, and it’s not a failing of available tools (though technology is often blamed). Organizations are going to have to give a closer look at their teams. He can also discuss why some ML teams within the same company are underperforming while others are absolutely crushing it, or what companies do to ensure that teams are asking the right questions and building models that deliver business value with the capabilities available to them. – Gideon Mendels, CEO and co-founder of MLOps platform [Comet](http://comet.ml/)

Organizations will realize the need to invest in AI/ML platforms for reusability, scale, and faster delivery: Organizations have struggled to scale their AI/ML model deployment in production due to complex data dependencies, manual processes, lack of expert AI/ML skills, and siloed engineering teams. In 2023, organizations will look to invest in AI/ML platform teams and services which can simplify dependencies, improve data and model discoverability, manage dataset access and governance, and make model building and deployment easily repeatable. MLOps platforms which can provide these benefits will gain traction. – Preethi Srinivasan, Director of Innovation at Druva

Rise of Real-Time Machine Learning: With all the real-time data being collected, stored, and constantly changing, the demand for real-time ML will be on the rise in 2023. The shortcomings of batch predictions are apparent in the user experience and engagement metrics for recommendation engines, but become more pronounced in the case of online systems that do fraud detection, since catching fraud 3 hours later introduces very high risk for the business. In addition real-time ML is proving to be more efficient both in terms of cost and complexity of ML operations. While some companies are still debating whether there’s value in online inference, those who have already embraced it are seeing the return on their investment and surging ahead of their competitors. – Dhruba Borthakur, co-founder and CTO at [Rockset](https://rockset.com/)

ML project prioritization will focus on revenue and business value: Looking at ML projects in-progress, teams will have to be far more efficient given the recent layoffs and look towards automation to help projects move forward. Other teams will need to develop more structure and determine deadlines to ensure projects are completed effectively. Different business units will have to begin communicating more, improving collaboration, and sharing knowledge so these now smaller teams can act as one, cohesive unit. In addition, teams will also have to prioritize which types of projects they need to work on to make the most impact in a short period of time. I see machine learning projects boiled down to two types: sellable features that leadership believes will increase sales and win against the competition, and revenue optimization projects that directly impact revenue. Sellable feature projects will likely be postponed, as they’re hard to get out quickly, and instead, the now-smaller ML teams will focus more on revenue optimization as it can drive real revenue. Performance, in this moment, is essential for all business units and ML isn’t immune to that. – Moses Guttmann, CEO and Co-Founder of [ClearML](https://clear.ml/)  

ML项目优先级将侧重于收入和业务价值：看看正在进行的ML项目，鉴于最近的裁员，团队将不得不提高效率，并期待自动化以帮助项目向前发展。其他团队将需要制定更多的结构，并确定最后期限，以确保项目有效完成。不同的业务部门将不得不开始更多的沟通，改善协作，共享知识，这样这些现在较小的团队就可以作为一个有凝聚力的单元发挥作用。此外，团队还必须优先考虑他们需要开展哪些类型的项目，以便在短时间内产生最大影响。我认为机器学习项目可以归结为两种类型：领导层认为可以增加销售并在竞争中获胜的可销售功能，以及直接影响收入的收入优化项目。 可销售的功能项目可能会被推迟，因为它们很难快速推出，相反，现在规模较小的ML团队将更多地关注收入优化，因为它可以推动真实的收入。在这一刻，性能对所有业务部门都至关重要，ML也不能幸免。 - Moses Guttmann，ClearML首席执行官兼联合创始人

2023 will be a year of acceleration for the operationalization of widespread usage of analytics and ML in all functions of enterprises. For years, early adopters have already been building out systems to automate a host of mundane tasks and to focus on higher-value activities: this has included everything from financial reporting, to data cleansing and document parsing. They’ve also combined automation with traditional analytics and AI or ML activities. The benefits can be significant, with companies reporting greater efficiencies and improved quality control, with time to focus on developing the next great ideas and products. Moving on to more profound work also delivers a higher sense of accomplishment: it makes people feel that their job has more value and sense. All of this together creates a strong incentive for more conservative companies to heavily invest in these practices, which are more often than not accelerated by employees eager for more automation, more analytics, and more insight. When it’s grassroots-driven like this, you get buy-in from across the organization. The success of these initiatives relies on appropriate tooling and standard processes (MLOps, data ops, sometimes called XOps) in order to disseminate such power across organizations, while retaining appropriate controls and governance. – Clément Stenac, Co-founder and CTO, [Dataiku](https://www.dataiku.com/)  

2023年将是分析和ML在企业所有职能中广泛使用的加速一年。多年来，早期采用者已经建立了系统，以自动化大量平凡的任务，并专注于更高价值的活动：这包括从财务报告到数据清理和文件分析的一切。他们还将自动化与传统分析和AI或ML活动相结合。好处可能是显著的，公司报告效率更高，质量控制得到改善，有时间专注于开发下一个伟大的想法和产品。继续从事更深刻的工作也会带来更高的成就感：让人觉得自己的工作更有价值和意义。 所有这一切都为更为保守的公司带来了强烈的动力，促使他们大力投资这些实践，而员工渴望更多的自动化、更多的分析和更多的洞察力，这往往会加速这些实践。当它像这样由基层驱动时，你会得到整个组织的支持。这些计划的成功依赖于适当的工具和标准流程（MLOps，数据操作，有时称为XOps），以便在组织中传播这种力量，同时保留适当的控制和治理。 - Clément Stenac，Dataiku联合创始人兼CTO

Data powers every major decision in organizations today. In 2023, organizations will continue to collect vast amounts of data from the physical world – through sensors and instruments – as well as from the digital world of online transactions. To organize these intermingled data sets, developers will increasingly tag data, not only with time-stamps, but also “location-stamps”. To extract value from this data tagged with geospatial context, data scientists and developers will work together to build and use specialized machine learning models and analytical queries. Much like DevOps transformed the software landscape two decades ago, MLOps services purpose-built for specialized data, models, and queries will increase the agility and productivity of developers building intelligent services. Developers who take advantage of these emerging platform capabilities to deliver a new class of mobile applications and cloud services enriched with geospatial data will drive the next wave of growth in the industry. – Vin Sharma, VP of Engineering at Foursquare  

数据支持当今组织中的每一个重大决策。到2023年，组织将继续通过传感器和仪器从物理世界以及在线交易的数字世界收集大量数据。为了组织这些混杂的数据集，开发人员将越来越多地标记数据，不仅使用时间戳，而且使用“位置戳”。为了从这些标记有地理空间背景的数据中提取价值，数据科学家和开发人员将共同构建和使用专门的机器学习模型和分析查询。就像20年前DevOps改变了软件环境一样，专为专门数据、模型和查询构建的MLOps服务将提高开发人员构建智能服务的敏捷性和生产力。 开发人员利用这些新兴平台功能，提供丰富地理空间数据的新型移动的应用和云服务，将推动该行业的下一波增长。 - Vin Sharma，Foursquare工程副总裁

Modernization efforts will increasingly rely on automation to curb costs, accelerate project completion, and help address challenges sourcing programmers in the current market. AI and ML algorithms will become more intelligent, and the number of modernization success stories will mount as processes become more standardized and human errors are reduced. – [EvolveWare](http://evolveware.com/) CEO Miten Marfatia  

现代化工作将越来越多地依赖于自动化来控制成本，加快项目完成，并帮助解决当前市场中程序员采购的挑战。AI和ML算法将变得更加智能，随着流程变得更加标准化和人为错误的减少，现代化成功案例的数量将增加。EvolveWare首席执行官Miten Marfatia

Open source ML tools will gain greater market share: It’s clear that next year MLOps teams, that specifically focus on ML operations, management, and governance, will have to do more with less. Because of this, businesses will adopt more off-the-shelf solutions because they are less expensive to produce, require less research time, and can be customized to fit most needs. MLOps teams will also need to consider open-source infrastructure instead of getting locked into long term contracts with cloud providers. While organizations doing ML at hyperscale can certainly benefit from integrating with their cloud providers, it forces these companies to work the way the provider wants them to work. At the end of the day, you might not be able to do what you want, the way you want, and I can’t think of anyone who actually relishes that predicament. As well, you are at the mercy of the cloud provider for cost increases, upgrades, and will suffer if you are running experiments on local machines. On the other hand, open source delivers flexible customization, cost savings, and efficiency – and you can even modify open source code yourself to ensure it works exactly the way you want. Especially with teams shrinking across tech, this is becoming a much more viable option. – Moses Guttmann, CEO and Co-Founder of [ClearML](https://clear.ml/)  

开源ML工具将获得更大的市场份额：很明显，明年专门关注ML运营、管理和治理的MLOps团队将不得不用更少的资源做更多的事情。正因为如此，企业将采用更多的现成解决方案，因为它们的生产成本更低，需要的研究时间更少，并且可以定制以满足大多数需求。MLOps团队还需要考虑开源基础设施，而不是与云提供商签订长期合同。虽然在超大规模上进行机器学习的组织肯定可以从与云提供商的集成中受益，但它迫使这些公司按照提供商希望的方式工作。在一天结束的时候，你可能不能做你想做的事，你想的方式，我想不出有谁真正享受这种困境。此外，您还将受云提供商的摆布，增加成本和升级，如果您在本地机器上运行实验，您将遭受损失。 另一方面，开源提供了灵活的定制、成本节约和效率-您甚至可以自己修改开源代码，以确保它完全按照您想要的方式工作。特别是随着技术团队的萎缩，这正在成为一个更加可行的选择。 - Moses Guttmann，ClearML首席执行官兼联合创始人

Companies with more than one machine learning use case in production will shift toward an MLOps “Continuous X” culture. This means that such companies will implement Continuous Integration (CI), Continuous Delivery (CD), Continuous Training (CT), Continuous Monitoring (CM) within their practices. Companies with zero machine learning cases in production will need to develop a collaborative approach between their business, technology, and product teams in order to define a clear MVP and land their first win. – Bal Heroor, CEO of [Mactores](https://mactores.com/)  

在生产中拥有多个机器学习用例的公司将转向MLOps“连续X”文化。这意味着这些公司将在其实践中实施持续集成（CI）、持续交付（CD）、持续培训（CT）、持续监控（CM）。在生产中没有机器学习案例的公司需要在其业务、技术和产品团队之间制定一种协作方法，以定义明确的MVP并赢得第一场胜利。- Bal Heroor，Mactores首席执行官

**Metaverse**

Quiet times for the Metaverse and NFTs: They’re not dead, but we won’t be seeing any major milestones in 2023. – Dan Parsons, CPO and co-founder of [Thoughtful](https://www.thoughtful.ai/) 

Metaverse Technologies Will Remain Just Hype, While the Adoption of Digital Transformation Technologies Trends Higher and Higher: While there might be flashes of jazzy product introductions around Metaverse technologies, there will not be any mass adoption or game-changing impact in 2023 stemming from Metaverse. These technologies will remain just hype for the foreseeable future until more and more enterprises gain a better understanding of this space and its impact. Technologies accelerating digital transformation, with a focus on cost reduction, will gain steam in 2023. The digital transformation trend that started during the Covid pandemic will only continue to accelerate as enterprises look for new ways to extract efficiencies in systems and processes. – Shiva Nathan, Founder & CEO of [Onymos](https://onymos.com/) 

Metaverse technologies are still too immature to provide the psychological safety required for high-quality coaching. While some practitioners will continue experimenting in the space, there won’t be any large-scale adoptions of coaching using metaverse technology in 2023. – [CoachHub](https://www.coachhub.com/) Global Director of Consulting Sam Isaacson

Start Thinking Ahead to Cybersecurity Concerns in the Metaverse: The metaverse, digital twins, and similar advanced technologies will present new security challenges for organizations and individual users. Artificial intelligence solutions will be needed to validate the legitimacy of identities and controls. When we think of the metaverse today, we often envision immersive gaming environments such as Fortnite. However, the metaverse will eventually reach beyond gaming into nearly all aspects of business and society. This new type of digital interface will present unforeseen security risks when avatars impersonate other people and trick users into giving away personal data. We are already seeing significant attack patterns that compromise users who click on a bad file or a malicious link. It could be a credential-harvesting ploy conducted through a spoofed URL, or a social engineering attack launched through a natural language message that triggers malware or ransomware. Then there are doctored videos of synthetic media “deep fakes” which can cause viewers to question whether someone or something they see is real or fake. We also find this trend with digital twins that allow users to conduct physical facility maintenance remotely through a digital environment. We can expect to see more of these holographic-type phishing attacks and fraud scams as the metaverse develops. In turn, folks will have to fight AI with stronger AI because we can no longer rely solely on the naked eye or human intuition to solve these complex security problems. – Patrick Harr, Chief Executive Officer, SlashNext 

Digital and synthetic twins take center stage: The next generation of the analytics life cycle will see a focus on simulating complex systems to help prepare for any possible scenario or disruptive event with digital and synthetic twins. Introducing rare events into our modelling and simulation will be key to understanding the highest probabilities of outcomes when the past is not a predictor of the future. From there, businesses can make rapid and resilient decisions to minimize risk and maximize profits. – Bryan Harris, Executive Vice President and Chief Technology Officer, SAS 

Digital twins will save thousands of lives in 2023: Improvements in IoT sensors, AI/ML, and 3D printing mean that digital twins, as a facet of synthetic biology, have arrived to make a major impact in the lives of thousands of humans – and animals. We now have the technology to fully model biological organs, recreating anything from a heart to a nose to skin in cyberspace. Not only does this enable doctors to more quickly diagnose current diseases and predict possible future health outcomes, but it also means that we are getting closer to ending animal testing, forever. Using a digital skin, for instance, a cosmetics company could test new skincare solutions for toxicity in cyberspace, instead of testing solutions on animals in a lab. Between the impact on humans and animals, digital twins will make a measurable impact to improve lives in 2023. – Frank Diana, Principal Futurist at Tata Consultancy Services

In the next five years, technologies like the metaverse, AI and automation, and biometrics will make huge leaps, and customers will expect their financial institutions to engage with them using these technologies. In order to meet them there, banks must be thinking now about how to maximize these opportunities, and they must be prepared to adapt to change more quickly than ever before both culturally and technologically. Those who choose to invest in resources that identify and solve problems such as removing bias in machine learning will come out the other end ready to capture the market and prevail as the real winners. – Chief Transformation and Operations Officer at Arvest Bank, Laura Merling

I don’t believe in the winner-take-all metaverse future. It will likely be a mix of companies and platforms that make up the metaverse, just like social media. You’re going to have different levels of immersive experiences, similar to how TikTok and Instagram require different forms of content. These future subtleties will require a metaverse brand manager. – Sami Khan, CEO of [ATLAS: EARTH](https://www.atlasearth.com/)

For now, we are far from the version of the Metaverse that will give us an immersive digital world to traverse. Instead, I see the use of augmented reality (AR) and virtual reality (VR) increasing drastically in the next few years. These extended reality experiences can help tech teams to learn and innovate by augmenting human vision and the human mind. Things like Google Glass were ahead of their time in this regard, but I do see there being a place for these types of technologies to become common for technology teams. – [Pluralsight](https://www.pluralsight.com/) CEO Aaron Skonnard

Deep Learning Meets the Metaverse: The sky’s the limit when it comes to the benefits of deep learning. It could be applied to anything that requires large amounts of data and decision making with high levels of accuracy. One such example that’s anticipated to explode in coming years is the Metaverse. Given the massive amounts of personal and valuable data involved, security will be a paramount concern and deep learning technology will be an extraordinary tool that can be used to help mitigate any security issues along the way. – Matthew Fulmer, Manager of Cyber Intelligence Engineering at [Deep Instinct](https://www.deepinstinct.com/)

Web access will bring more visitors into the metaverse: In 2023, we will see more virtual worlds vie for your attention on the browser. One of the biggest blockers to the proliferation of the metaverse is accessibility. VR adoption is still in its infancy and many users are unwilling to download dedicated apps when their attention could be spent elsewhere with significantly less effort (read: friction). This presents a conundrum for metaverse developers, as the potential for more genuine online interpersonal interactions is an oft-touted value proposition for spending time in virtual worlds. Although some examples of web-based 3D virtual worlds are out there, we expect that 2023 will see established and new players offering browser access to their metaverse destinations to grow their user bases. – Shawn Zhong, CTO at [Agora](https://www.agora.io/en/)

**NLP**

Natural Language Processing and Computer Vision Will Play an Important Role: Enterprise adoption of automation of processes involving text or voice data using Natural Language Processing (NLP) and Computer Vision (CV) technologies will greatly enhance in 2023. Large language models with high complexity will increase the sophistication of NLP applications. For example, AI-based virtual assistants are becoming essential to most organizations’ customer service lifecycle and engagement strategies. This allows customers, vendors, and employees to ask questions that can be easily answered through automated processes, as in a chatbot. But there are more sophisticated uses as well. For instance, broadcast editors who used to struggle to match timestamps with subtitles for a newly posted video can now utilize NLP and context analysis to provide subtitles and generate near-perfect translations. While designing a solution, recommendation and search engines are powerful tools in bringing relevant content to visibility. With CV and NLP, it is now possible to scan documents and retrieve relevant information instantaneously. AI has enabled quality assurance teams by analyzing inputs, outputs, and simulated data for anomalies. Based on wide data, data from multiple sources, AI can also help predict business outcomes, allowing companies to make rapid decisions. In addition, NLP-based systems to help organizations to meet regulatory compliance requirements. – Anand Mahukar, CEO, Findability

SQL workloads will explode as more NLP (Natural Language Processing) and other Machine Learning (ML) applications generate SQL: While data analysts and scientists continue to uncover insights using SQL, increasingly we’ll see apps that “speak SQL” drive a large portion of the analytical compute. Natural Language Processing (NLP) applications are enabling citizen data analysts and demand more compute on data platforms. Similarly, ML applications can dig into datasets in new ways which will blow through today’s level of demand for analytic compute. SQL is not only the ‘lingua franca’ of data analysis, SQL is the ‘lingua franca’ of ML and NLP too. –  Steven Mih, Co-founder and CEO, [Ahana](http://www.ahana.io/)  

随着更多的NLP（自然语言处理）和其他机器学习（ML）应用程序生成SQL，SQL工作负载将爆炸式增长：虽然数据分析师和科学家继续使用SQL发现洞察力，但我们将越来越多地看到“说SQL”的应用程序驱动着大部分分析计算。自然语言处理（NLP）应用程序正在支持公民数据分析，并要求在数据平台上进行更多的计算。同样，机器学习应用程序可以以新的方式挖掘数据集，这将突破当今对分析计算的需求水平。SQL不仅是数据分析的“弗兰卡语言”，也是ML和NLP的“通用语言”。- Steven Mih，Ahana联合创始人兼首席执行官

Growing acceptance of hybrid NLP: It’s fairly common knowledge that hybrid NLP solutions that mix machine learning and classic NLP techniques like white lists, queries and sentiment dictionaries mixed with deep learning models typically provide better business solutions than straight Machine Learning solutions. The benefit of these hybrid solutions means that they will become a checkbox item in corporate evaluations of NLP vendors. – Jeff Catlin, Head of [Lexalytics](https://www.lexalytics.com/), an InMoment Company  

对混合NLP的接受度越来越高：众所周知，混合NLP解决方案混合机器学习和经典NLP技术，如白色名单，查询和情感字典与深度学习模型混合，通常提供比直接机器学习解决方案更好的业务解决方案。这些混合解决方案的好处意味着它们将成为NLP供应商企业评估中的复选框。- Jeff Catlin，Lexalytics负责人，InMoment公司

Dynamic data searching will become essential: Organizations will prioritize the management of unstructured conversation content. As the volume of dynamic chat, voice, video, and text data exponentially increases, accessing, searching, and retrieving this data will be more important than ever. Whether for forensics, financial reporting, internal investigations, or litigation, the ability to understand the contents of complex communication data, organize it, and retrieve it will need to become a core competency. Any inability to manage data could have profound regulatory and other, more serious, consequences. – Devin Redmond, CEO and co-founder, Theta Lake  

动态数据搜索将变得至关重要：组织将优先管理非结构化对话内容。随着动态聊天、语音、视频和文本数据的数量呈指数级增长，访问、搜索和检索这些数据将比以往任何时候都更加重要。无论是取证、财务报告、内部调查还是诉讼，理解、组织和检索复杂通信数据内容的能力都需要成为核心竞争力。任何无法管理数据的情况都可能产生深远的监管和其他更严重的后果。- 迪文雷德蒙，Theta Lake首席执行官兼联合创始人

Natural language processing (NLP) + object recognition will bring search to the next level: While most people write scrapers today to get data off of websites, this may soon be replaced by further advancements in NLP. You will just have to describe in natural language what you want to extract from a given web page and it would pull it for you.  For example, you could say, “search this travel site for all the flights from San Francisco to Boston and put all of them in a spreadsheet, along with price, airline, time, and day of travel.” It’s a hard problem but we could actually solve it in the next year. As another example on the healthcare side, I think we’ll be able to predict — automatically — the notes and documentation a doctor might write for a given diagnosis or treatment, which would be a huge achievement. It could save healthcare workers valuable time. Generally, we’ll be able to tie object detection — where we train algorithms to predict what is in an image — to natural language processing. This would be a big step forward as it will allow us to simply describe what output we want and it would figure out how to build a classifier to deliver it. For example, you could say “does this image contain an animal with four feet and tails?” and that would be “programming” a classifier. While we can do this to some extent now, it will become more advanced in the coming year and allow us to go one level deeper — only describing _attributes_ of what we want to find rather than providing labeled examples of the object itself. We may also develop new methods for combining prompt engineering and supervised labeled examples into a coherent whole. – Varun Ganapathi, Ph.D., CTO and co,-founder at [AKASA](http://akasa.com/)  

自然语言处理（NLP）+对象识别将使搜索更上一层楼：虽然现在大多数人编写抓取器来从网站上获取数据，但这可能很快就会被NLP的进一步进步所取代。你只需要用自然语言描述你想从给定的网页中提取什么，它就会为你提取出来。例如，你可以说：“在这个旅游网站上搜索从弗朗西斯科到波士顿的所有航班，并将所有航班沿着价格、航空公司、时间和旅行日期一起放入电子表格中。”这是一个棘手的问题，但我们可以在明年解决它。作为医疗保健方面的另一个例子，我认为我们将能够自动预测医生可能为给定的诊断或治疗编写的笔记和文档，这将是一个巨大的成就。它可以保存医护人员宝贵的时间。 一般来说，我们将能够将对象检测（我们训练算法来预测图像中的内容）与自然语言处理联系起来。这将是向前迈出的一大步，因为它将允许我们简单地描述我们想要的输出，并将弄清楚如何构建一个分类器来提供它。例如，你可以说：“这个图像包含一个有四只脚和尾巴的动物吗？”“这就是“编程”分类器。虽然我们现在可以在某种程度上做到这一点，但在未来一年它将变得更先进，并允许我们更深入一个层次-只描述我们想要找到的东西的属性，而不是提供对象本身的标记示例。我们还可以开发新的方法，将即时工程和监督标记的例子结合成一个连贯的整体。- Varun Ganapathi博士，CTO和合伙人-AKASA创始人

Large Language Models for NLP (like BERT, GPT, and derivatives) will keep improving, and their use will become more pervasive. Also one pretrained model will be able to be used with little modification for many functions (sentiment analysis, summarization, word sense disambiguation, etc.). It’s aim is to learn representations of data by contrasting between similar and dissimilar samples. Transformers, text-to-Image, and diffusion models, require large-scale datasets and supervised pre-training of large models is extremely expensive. The self-supervised Contrastive Learning can be used to leverage vast amounts of unlabeled data in order to efficiently pre-train large models. Furthermore, contrastive search is a related technique which has been shown to significantly improve the output of large language models when used for text generation tasks. – Adi Andrei, Head of Data at SpaceNK  

NLP的大型语言模型（如BERT、GPT和衍生工具）将不断改进，它们的使用将变得更加普遍。此外，一个预训练的模型将能够用于许多功能（情感分析，摘要，词义消歧等）几乎没有修改。它的目的是通过对比相似和不相似的样本来学习数据的表示。Transformers，文本到图像和扩散模型需要大规模的数据集，并且大型模型的监督预训练非常昂贵。自监督对比学习可以用于利用大量未标记数据，以便有效地预训练大型模型。此外，对比搜索是一种相关的技术，当用于文本生成任务时，已被证明可以显着提高大型语言模型的输出。- Adi Andrei，SpaceNK数据主管

**Observability**

Observability is the most under-recognized technology to advance cybersecurity solutions: We’re starting to realize that understanding an organization’s data makes a difference in being able to thwart cyberattacks and prevent breaches. That’s why, observability has the biggest opportunity to change how we advance cybersecurity detection and remediation. Through observability solutions**,** security teams are empowered to take action and tie technology performance to specific business outcomes. By layering observability with identity management, security teams have access to more data on identity-based threats to remediate incidents in real-time and improve their security defenses. – Dan Conrad, AD Security and Management Team Lead, One Identity

Most of the AI trends now have to do a lot with Natural Language Processing, Transformers, the attention mechanism, and how you can use it to make your AI models better. As this evolves, businesses will make better sense of all their stored textual data and pursue the objective of being a data-driven organization. If businesses found themselves collecting more and more raw, organic communications data in the past years, 2023 will see a surge of AI tools that help businesses convert their company data into actionable insights. – [Erudit](https://www.erudit.ai/)’s Chief Science Officer & Co-founder, Ricardo Michel Reyes

Natural Language Understanding Will Become Part of AI Models: In 2023 we will start to see natural language understanding become possible for AI applications. There will be a transition from simple pattern matching to language understanding within the underlying model. By starting with taxonomies, ontologies, speech technology and new rule based approaches – it will be possible to take natural language understanding and instantly turn it into triples that describe the pragmatics of the world. These triples become the underlying ontological description of the world, which is essential to produce high-quality AI using natural language. – Jans Aasman, Ph.D., an expert in Cognitive Science and CEO of [Franz Inc](https://franz.com/).  

自然语言理解将成为AI模型的一部分：到2023年，我们将开始看到自然语言理解成为人工智能应用的可能。在底层模型中，将有一个从简单模式匹配到语言理解的过渡。通过从分类学、本体论、语音技术和基于规则的新方法开始-将有可能采取自然语言理解并立即将其转化为描述世界语用学的三元组。这些三元组成为世界的底层本体论描述，这对于使用自然语言产生高质量的人工智能至关重要。- Jans Aasman博士认知科学专家和Franz Inc.的首席执行官。

Data observability will become a critical industry: In today’s economy, it’s critical to constantly calculate ROI and prioritize ways that we can do more with less. I believe engineering teams have an opportunity to lean in and work towards increasing the capacity of the company to win. I predict that we’ll increasingly see engineers and data teams becoming facilitators of enabling companies to make data-driven decisions by building the infrastructure and providing tools needed to enable other teams (especially non-technical teams). One of the ways they’ll enable this shift is to help teams understand how to access their data in a self-serving manner, rather than being constantly at the center of answering questions. Instead of hiring more data scientists, I expect data teams to increase data engineering roles in order to build lasting infrastructures that enable folks on all sides of the business to answer questions independently. – Shadi Rostami, SVP of engineering, [Amplitude](https://amplitude.com/)  

数据可观测性将成为关键产业：在当今的经济环境中，不断计算投资回报率，并优先考虑我们可以用更少的资源做更多的事情是至关重要的。我相信工程团队有机会向前迈进，努力提高公司赢得胜利的能力。我预测，我们将越来越多地看到工程师和数据团队通过构建基础设施和提供支持其他团队（尤其是非技术团队）所需的工具，成为帮助企业做出数据驱动决策的促进者。他们实现这一转变的方法之一是帮助团队了解如何以自我服务的方式访问他们的数据，而不是一直处于回答问题的中心。我希望数据团队不会雇佣更多的数据科学家，而是增加数据工程的角色，以建立持久的基础设施，使业务各方的人员能够独立回答问题。- Shadi Rostami，振幅工程高级副总裁

Save all data or delete what ages out? That’s every data management policy challenge. In today’s world, everyone is watching their budgets while looking for creative ways to cut costs and maintain productivity. In 2023, data observability — one of the most valuable ways for companies to derive insights from data to drive critical business decisions — will improve from collection, retention, summarization, and context building to enable organizations to do a lot more with less. – Kit Merker, Chief Growth Officer, [Nobl9](https://www.nobl9.com/)  

保存所有数据或删除过时的数据？这是所有数据管理策略的挑战。在当今世界，每个人都在关注自己的预算，同时寻找创造性的方法来削减成本并保持生产力。到2023年，数据可观察性-公司从数据中获得洞察力以推动关键业务决策的最有价值的方式之一-将从收集、保留、总结和上下文构建方面得到改善，使组织能够以更少的资源完成更多的工作。- Kit Merker，Nobl 9首席增长官

Having deep observability coupled with MELT (metrics, events, logs, traces) can help discover rogue activities coming from users, cloud app developers, or bad actors such as running P2P applications, crypto-mining servers, etc. In fact, Google’s recent Threat Horizons report shows that once threat actors gained access to a system, 65% of them engaged in crypto-mining, so spotting such activity can be mission-critical for security teams in the year to come. MELT has been the staple tool for data ingestion and application monitoring for two decades now, and we’ve seen these make their way into observability tools for cloud workloads now. As the architecture and landscape become increasingly complex in 2023, with activities such as crypto-mining, etc., complementing MELT with the “network perspective” that deep observability provides, security teams will have more insight into observability reporting and monitoring capabilities. – Bassam Khan, Vice President of Product and Technical Marketing Engineering, [Gigamon](https://www.gigamon.com/)  

具有深度可观察性与MELT（指标、事件、日志、跟踪）相结合，可以帮助发现来自用户、云应用开发人员或不良行为者（如运行P2P应用程序、加密挖掘服务器等）的流氓活动。事实上，谷歌最近的Threat Horizons报告显示，一旦威胁参与者获得了系统的访问权限，其中65%的人参与了加密挖掘，因此发现此类活动对安全团队来说可能是一项至关重要的任务。20年来，MELT一直是数据摄取和应用程序监控的主要工具，我们已经看到这些工具现在进入了云工作负载的可观察性工具。随着建筑和景观在2023年变得越来越复杂，随着加密采矿等活动的不断增加通过深度可观察性所提供的“网络视角”来补充MELT，安全团队将对可观察性报告和监控能力有更深入的了解。 - Bassam Khan，Gigamon产品和技术营销工程副总裁

Observability: What companies can expect to see in 2023: Water systems make an excellent analogy for understanding the world of data. Data lakes are enormous centralized repositories, while data streams flow freely at high speeds and high volumes. The water analogy also extends to observability, where teams analyze an ever-growing number of logs, metrics and traces to ensure systems are working at their peak levels. Just as the water gets analyzed and tested for safety in two places (at the reservoir and in the pipelines), observability data needs to be analyzed and acted on while it is still flowing through the pipeline. Waiting for the data to arrive in the data lake is insufficient, and failure to maintain constant insight into the quality of water (and data) could lead to disaster. As businesses in every industry become more data-driven, the amount of data generated will continue to increase. The [IDC Global DataSphere](https://www.idc.com/getdoc.jsp?containerId=US49018922), a measure of how much new data is created, captured, replicated, and consumed each year, is expected to double in size from 2022 to 2026. That’s leading to a growing demand for observability tools and some emerging best practices for implementing them. Here’s what 2023 has in store for observability professionals. – Eduardo Silva, founder and CEO of [Calyptia](https://calyptia.com/) and the founder and creator of [FluentBit](https://fluentbit.io/)  

可观察性：2023年企业可以看到什么：水系统是理解数据世界的绝佳类比。数据湖是巨大的集中存储库，而数据流以高速大容量自由流动。水的类比也延伸到可观察性，团队分析不断增长的日志、指标和跟踪，以确保系统在其峰值水平工作。就像水在两个地方（水库和管道中）进行安全分析和测试一样，当水仍在管道中流动时，也需要对可观测性数据进行分析和处理。等待数据到达数据湖是不够的，如果不能持续洞察水（和数据）的质量，可能会导致灾难。随着每个行业的企业变得更加数据驱动，所产生的数据量将继续增加。 IDC Global DataSphere是衡量每年创建、捕获、复制和消费的新数据量的指标，预计从2022年到2026年将翻一番。这导致了对可观察性工具和一些新兴的实现它们的最佳实践的需求不断增长。以下是2023年为可观察性专业人士准备的。 - - Eduardo Silva，Calyptia创始人兼首席执行官，FluentBit创始人兼创始人

Observability, security, and business analytics will converge as organizations begin to tame the data explosion: The continued explosion of data from multi cloud and cloud-native environments, coupled with the increased complexity of technology stacks, will lead organizations to seek new, more efficient ways to drive intelligent automation in 2023. It’s not just the huge increase in payloads transmitted, but the exponential volumes of additional data, which can be harnessed to gain better observability, enhanced security, and deeper business insights. However, the prevalence of siloed monitoring tools that offer insights into a single area of the technology stack or support an isolated use case has impeded progress in accessing this value, making it difficult to retain the context of data. It also results in departmental silos, as each team remains focused on its own piece of the puzzle, rather than combining data to reveal the bigger picture. To address this, observability, security, and business analytics will converge as organizations consolidate their tools and move from a myriad of isolated and hard to manage DIY tools to multi-use, AI-powered analytics platforms that offer BizDevSecOps teams the insights and automation they need. This will help to tame clouds and the data explosion and drive intelligent automation across multiple areas, from cloud modernization to regulatory compliance and cyber forensics. – [Dynatrace](https://www.dynatrace.com/) founder and chief technology officer Bernd Greifender  

随着组织开始驯服数据爆炸，可观察性、安全性和业务分析将趋于一致：来自多云和云原生环境的数据持续爆炸式增长，再加上技术堆栈复杂性的增加，将促使组织寻求新的、更有效的方法来推动2023年的智能自动化。这不仅仅是传输的有效载荷的大幅增加，还有指数级的额外数据，可以利用这些数据获得更好的可观察性、增强的安全性和更深入的业务洞察。然而，孤立的监控工具的流行，这些工具提供了对技术堆栈的单个领域的见解或支持孤立的用例，阻碍了获取这一价值的进展，使得难以保留数据的上下文。它还导致了部门孤岛，因为每个团队仍然专注于自己的拼图，而不是结合数据来揭示更大的图景。 为了解决这个问题，随着组织整合他们的工具，并从无数孤立的和难以管理的DIY工具转向多用途的人工智能分析平台，可观察性，安全性和业务分析将融合，为BizDevSecOps团队提供他们所需的洞察力和自动化。这将有助于驯服云计算和数据爆炸，并推动多个领域的智能自动化，从云计算现代化到监管合规和网络取证。 - Dynatrace创始人兼首席技术官Bernd Greifender

Data Observability investments are immune against the economic environment: While inflation and recession hit the global economy and stock markets plunge, funds will keep investing in the data observability industry, which is already worth billions in valuation. This new category solution focuses on helping data teams better understand data usage and faster troubleshoot data incidents, saving money and ensuring data teams are more efficient and free to focus on revenue-generating initiatives. – Andy Petrella, founder and CPO of [Kensu](https://www.kensu.io/)数据可观察性投资不受经济环境影响：在通胀和衰退打击全球经济、股市暴跌的同时，基金将继续投资于数据可观测性行业，该行业的估值已经达到数十亿美元。这一全新类别解决方案专注于帮助数据团队更好地了解数据使用情况，更快地排除数据事件，节省资金，并确保数据团队更高效、更自由地专注于创收计划。- Andy Petrella，Kensu创始人兼首席执行官  

Observability will become the watchword in 2023: AI, ML and observability solutions that take AI to the next level, so that organisations are getting more actionable insights and predictions out of their data for improved reporting and analytical purposes, will be paramount. This is where we will see true AI solutions shine – ones that bring in intelligence and richer observability instead of simple monitoring. Observability is more about the correlation of multiple aspects, context gathering and behavioural analysis. Observability correlation enables applications to operate more efficiently and identify when a site’s operations are sub-optimal, with this context delivered to the right person at the right time. This means a high volume of alerts is transformed into a small volume of actionable insights. Without a doubt 2023 will be a challenging year, but there will also be opportunity for innovation and growth in certain sectors.  This is where working with a cost-effective partner will be critical; a trusted partner that can rapidly pivot, innovate and adapt as requirements and market conditions evolve. – Mark Cooke, COO of Xalient  

可观察性将成为2023年的口号：AI，ML和可观察性解决方案将AI提升到一个新的水平，以便组织从其数据中获得更多可操作的见解和预测，以改善报告和分析目的，将是至关重要的。这就是我们将看到真正的人工智能解决方案闪耀的地方--那些带来智能和更丰富的可观察性而不是简单的监控。可观察性更多地是关于多个方面的相关性，背景收集和行为分析。可观察性相关性使应用程序能够更有效地运行，并识别站点何时运行不是最优的，并在正确的时间将此上下文交付给正确的人。这意味着大量的警报被转化为少量的可操作见解。毫无疑问，2023年将是充满挑战的一年，但某些行业也将有创新和增长的机会。 在这方面，与一个具有成本效益的伙伴合作至关重要;值得信赖的合作伙伴，能够根据需求和市场条件的变化快速调整、创新和适应。 - Mark Cooke，Xalient首席运营官

**Quantum Computing**

The crossover from quantum to classical computing is going to yield new techniques in data science. In particular, the transition from discrete linear algebra as the underpinning math of neural nets to more algebraic topology and quantum foundations could create a third wave in AI! – [Moogsoft](https://www.moogsoft.com/) co-founder and CEO, Phil Tee

Quantum Matures and Consolidates: Companies will merge to fill gaps in their hardware and software offerings and seek firmer financial footings. We’ll say goodbye to some familiar names, but rather than representing a Quantum Winter, it will indicate a necessary maturation and evolution of the industry. – Bob Sutor, Vice President and Chief Quantum Advocate at [ColdQuanta](http://www.coldquanta.com/)

Building the Foundation for Quantum: After decades-long hype around quantum computing and quantum systems, the industry will start to realize its potential for creating new opportunities in fields spanning cybersecurity, materials creation, financial analysis and military receivers. Proactive companies will start investing in quantum, fostering quantum talent within the next generation of workers through university partnerships, hackathons and other projects. This will create an ancillary boost to DEI initiatives resulting in much-needed diversity in the tech workforce. Recent research revealed that 74% of companies believe they will fall behind if they fail to adopt quantum. As a result, organizations will begin to shift their thinking that quantum is a futuristic technology and begin addressing key challenges, including financial resources and operations, and developing real enterprise applications of quantum by 2026, if not sooner. – Dr. Eric Holland, Director of Quantum Engineering Solutions, [Keysight Technologies](http://keysight.com/)

Quantum Sensing Will Support AI – and Vice Versa: Machine learning will be used to optimize the performance of quantum sensors, while quantum sensors will enable new classes of machine learning algorithms for discovery within, and adaptation to, the sensors’ environment. Very different from the Big Data applications of machine learning and quantum computing, machine learning together with quantum sensing will bring about new capabilities in real-time sensing and signal processing. – Bob Sutor, Vice President and Chief Quantum Advocate at [ColdQuanta](http://www.coldquanta.com/)

An exciting trend in AI is quantum computing, which has been around for around 7 years but will have applications in the next 25 years or so. They’re even more powerful than supercomputers in solving complex problems. Today’s computers started development in the 1940s, but look at us now! Quantum computers will do the same for the future. – [Erudit](https://www.erudit.ai/)’s Chief Science Officer & Co-founder, Ricardo Michel Reyes  

人工智能的一个令人兴奋的趋势是量子计算，它已经存在了大约7年，但将在未来25年左右得到应用。它们在解决复杂问题方面比超级计算机更强大。今天的计算机是在20世纪40年代开始发展的，但看看我们现在！量子计算机也将在未来做同样的事情。Erudit首席科学官兼联合创始人Ricardo Michel Reyes

Quantum implications are here and will be painful to adapt to in 2023: Making infrastructures quantum-resilient is going to be more difficult than imagined, both for the public and private sectors. One major area of concern when it comes to quantum is national security. Governments have secrecy policies that last for decades…those policies are going to be threatened by quantum computing as the technology evolves, with much of the information under these policies being transmitted (and potentially captured in encrypted form) with algorithms that may not be quantum safe. Within the next 5-10 years, quantum technology will likely become commercially available, making it a very real threat to past and outdated encryption algorithms – many of which are used to conceal the nation’s top secrets. Quantum computing is going to be able to overcome complex roadblocks at speeds that will render multiple forms of current encryption useless. For the private sector, trade secrets, intellectual property, financial data and more are at the same risk if a bad actor gets their hands on quantum computing capabilities and breaks the encryption keeping critical assets under lock and key. Building cyber resilience in preparation for quantum technology should have been an effort started a decade ago…but now is the second best time. In 2023, we’ll see both the private and public sector’s increased awareness around the challenges associated with quantum resilience, and we’ll see efforts begin to take hold more significantly to prepare for quantum computing. Much of the encryption infrastructure in communication networks that keeps information safe now is deeply embedded, i.e., certificates, and will take years to transition to quantum resilient algorithms, posing a timeline issue for changeover before the general availability of quantum computing. – Chief Information Security Officer of [(ISC)²](https://www.isc2.org/) Jon France   

量子含义就在这里，并且在2023年适应将是痛苦的：使基础设施具有量子弹性将比想象的要困难，无论是公共部门还是私营部门。在量子领域，一个主要关注领域是国家安全。随着技术的发展，这些政策将受到量子计算的威胁，这些政策下的大部分信息是通过可能不是量子安全的算法传输的（并可能以加密形式捕获的）。在未来5-10年内，量子技术可能会成为商业可用的，使其对过去和过时的加密算法构成非常真实的的威胁，其中许多算法被用来隐藏国家的最高机密。量子计算将能够克服复杂的障碍，速度将使当前多种形式的加密变得无用。 对于私营部门来说，商业秘密、知识产权、金融数据等都面临着同样的风险，如果一个不良行为者掌握了量子计算能力，并破坏了将关键资产锁定的加密机制。为量子技术做准备，建立网络弹性应该是十年前就开始的努力......但现在是次好的时机。到2023年，我们将看到私营部门和公共部门对量子弹性相关挑战的认识有所提高，我们将看到为量子计算做准备的努力开始变得更加重要。通信网络中保持信息安全的许多加密基础设施现在都是深嵌入的，即，证书，并将需要数年的时间来过渡到量子弹性算法，这在量子计算普遍可用之前提出了转换的时间轴问题。 - （ISC）² Jon France首席信息安全官

Preparedness for a post-quantum future: Given the proliferation of data today and the rise of data breaches, security is top of mind for everyone, everywhere. As a result, in 2023 more attention will be given to the threats and the implications of a future quantum world. For enterprises, specifically, that means starting to ensure your infrastructure is “quantum-resistant” by taking measures now to secure your networks, protect your backend services, and so on. CISOs will begin to take notice and put the necessary processes in place. Practical solutions are still somewhat tricky as standardization of post-quantum cryptography is ongoing. CISOs need to be diligent and opt for “hybrid” deployments, where even if new algorithms are discovered to be weak, security against classic attacks is still ensured. – Yaron Sheffer, VP of Technology at Intuit   

为后量子未来做好准备：鉴于当今数据的激增和数据泄露事件的增加，安全性是每个人的首要考虑。因此，在2023年，人们将更多地关注未来量子世界的威胁和影响。对于企业来说，这意味着开始确保您的基础设施是“抗量子”的，现在就采取措施来保护您的网络安全，保护您的后端服务等等。CISO将开始注意到并落实必要的流程。实际的解决方案仍然有些棘手，因为后量子密码学的标准化正在进行中。CISO需要勤奋，选择“混合”部署，即使发现新算法很弱，仍然可以确保抵御经典攻击的安全性。- Yaron Sheffer，Intuit技术副总裁

With quantum computing gaining traction, and both governments and businesses investing heavily in quantum research, we‘ll witness computing power that enables us to solve complex problems previously thought “unsolvable” in a matter of minutes. From new drug discovery, to weather predictions, to easing traffic congestion the practical use cases in certain industries will be game-changing. – Hillary Ashton, Chief Product Officer, Teradata  

随着量子计算的发展，以及政府和企业对量子研究的大量投资，我们将见证计算能力，使我们能够在几分钟内解决以前被认为“无法解决”的复杂问题。从新药发现到天气预报，再到缓解交通拥堵，某些行业的实际用例将改变游戏规则。- Teradata首席产品官Hillary Ashton

**RPA, Automation, Robotics  

RPA，自动化，机器人**

The Rise and Fall of Everything-as-Code. In 2023, as budgets likely continue to tighten, a trend will emerge towards seeking optimization and productivity. Rather than continuing to grow teams, companies that are forced to do more with less will look towards ways to automate data processes that they once did manually. That is good news for platforms and tools that enable automation, are simple to use, and free up time spent on repetitive tasks to focus instead of creating impact for the business. – Satish Jayanthi, CTO and co-founder of [Coalesce](https://coalesce.io/)  

《万物如代码的兴衰》2023年，随着预算可能继续收紧，寻求优化和提高生产力的趋势将出现。被迫以更少的资源做更多的事情的公司不会继续发展团队，而是寻求自动化数据处理的方法，而他们曾经手动完成。这对于能够实现自动化、易于使用、并且可以释放用于重复性任务的时间来集中精力而不是对业务产生影响的平台和工具来说是个好消息。- Satish Jayanthi，Coalesce首席技术官兼联合创始人

In 2023, organizations will lean heavily on process orchestration tools to meet full automation potential: Business processes will continue to grow more complex at the same tie that the number of endpoints involved increases. Legacy systems, microservices, manual tasks, RPA bots, AI/ML tools and IoT devices that already adequately automate individual tasks in a process must be reconciled. In order to guarantee that these various tasks run smoothly within a process and can carry out appropriate analyzes and optimizations, process orchestration tools will be critical. This is because they coordinate the end-to-end process and integrate a wide variety of endpoints. If companies don’t manage to orchestrate their processes end-to-end, they only automate and optimize locally and don’t exploit the full potential that automation offers. In addition, process orchestration supports companies in gradually migrating from legacy systems to modern, microservice-based architectures. A good orchestration tool is software and device agnostic, works within an organization’s existing tech stack, and allows individual tasks to be gradually automated outside of a legacy system. Another trend is the increased use of “low-code” in process orchestration. Low-code tools are typically applied to automate simple processes. A smarter way of doing low-code is to use flexible and extensible tools, often in a domain specific way, which allow to apply low-code to more complex scenarios in process orchestration, counteracting the lack of skilled software developers for core and mission critical processes. – Bernd Ruecker, Co-Founder and Chief Technologist, [Camunda](https://camunda.com/)  

到2023年，组织将严重依赖流程编排工具，以满足完全自动化的潜力：业务流程将随着端点数量的增加而继续变得更加复杂。遗留系统、微服务、手动任务、RPA机器人、AI/ML工具和物联网设备已经在流程中充分自动化了各个任务，必须进行协调。为了保证这些不同的任务在流程中顺利运行，并能够进行适当的分析和优化，流程编排工具将是至关重要的。这是因为它们协调了端到端的流程并集成了各种各样的端点。如果公司不能管理好端到端的流程编排，他们只能在本地进行自动化和优化，而不能充分利用自动化提供的全部潜力。此外，流程编排支持公司逐步从遗留系统迁移到现代的基于微服务的架构。 一个好的编排工具与软件和设备无关，在组织现有的技术堆栈中工作，并允许单个任务在遗留系统之外逐渐自动化。另一个趋势是在流程编排中越来越多地使用“低代码”。低代码工具通常用于自动化简单流程。实现低代码的一种更聪明的方法是使用灵活和可扩展的工具，通常以特定领域的方式，这允许将低代码应用于流程编排中更复杂的场景，抵消了核心和使命流程缺乏熟练的软件开发人员的问题。 - Bernd Ruecker，Camunda联合创始人兼首席技术专家

Artificial intelligence has continued to rise in adoption across many types of technologies and industries over the past year. Looking forward to 2023, there are many exciting AI use-cases that will continue to gain popularity, and AI’s convergence with robotic process automation (RPA) to generate intelligent automation is near the top of the list. RPA is already a common technology implemented in many businesses; however, intelligent automation, or the intersection of AI and RPA, empowers teams to accelerate their overall digital transformation with quicker speeds, sharper insights, and less stress. Typical RPA software bots are programmed to execute certain tasks, so that’s what they do — end of story. With the infusion of AI, the bots are able to automate certain predictions and decisions based on both structured and unstructured input. Essentially, intelligent automation up-levels RPA’s ability to work in tandem with humans — perceiving, learning, and anticipating processes from the available data to create smarter and more efficient outcomes. Additionally, data captured from intelligent automation can then be utilized by different departments who become more connected across their entire tech stack. In 2023 I think we’ll see more organizations across various industries dive into intelligent automation as they fully appreciate its value proposition. – Dave Dabbah, CMO, [Robocorp](https://robocorp.com/)  

在过去的一年里，人工智能在许多类型的技术和行业中的采用率持续上升。展望2023年，有许多令人兴奋的AI用例将继续获得普及，AI与机器人过程自动化（RPA）融合以产生智能自动化的趋势接近榜首。RPA已经是在许多企业中实施的通用技术;然而，智能自动化，或AI和RPA的交叉，使团队能够以更快的速度，更敏锐的洞察力和更少的压力加速整体数字化转型。典型的RPA软件机器人被编程为执行某些任务，所以这就是他们所做的-故事结束。随着人工智能的注入，机器人能够基于结构化和非结构化输入自动化某些预测和决策。 从本质上讲，智能自动化提升了RPA与人类协同工作的能力--从可用数据中感知、学习和预测流程，以创造更智能、更高效的结果。此外，从智能自动化捕获的数据可以被不同的部门利用，这些部门在整个技术堆栈中变得更加紧密。在2023年，我认为我们将看到更多来自不同行业的组织投入智能自动化，因为他们充分认识到智能自动化的价值主张。 - Dave Dabbah，Robocorp首席营销官

Rise of AI-Assistance: Working Smarter, More with Less: Software architects don’t have a lot of tools designed for their needs. Sure, there are a plethora of lower-level developer tools, IDEs, graphing, and profilers that most architects grew up on, but purpose-built tooling that truly helps an architect, well “architect,” really doesn’t exist – to do things like help identify architectural dependencies, recognize natural domain service clusters, define service boundaries and entry points, split services, build commons libraries, and recognize architectural drift. That’s where AI-assistance comes in, much like robot-assisted surgery, to help the expert do their actual job faster, smarter, with lower risk, more efficiently, and much more precisely. – [vFunction](https://vfunction.com/) Chief Ecosystem Officer, Bob Quillin   

AI辅助的崛起：更聪明，事半功倍：软件架构师并没有太多为他们的需求而设计的工具。当然，大多数架构师成长过程中有大量的低级开发工具、IDE、图形和分析器，但是真正帮助架构师（好吧，“架构师”）的专门构建的工具并不存在-帮助识别架构依赖关系、识别自然域服务集群、定义服务边界和入口点、拆分服务、构建公共库以及识别架构漂移。这就是人工智能辅助的作用，就像机器人辅助手术一样，帮助专家更快、更聪明、更低风险、更高效、更精确地完成实际工作。- vFunction首席生态系统官Bob Quillin

2023 will see more organizations relying on existing processes as opposed to architecting new ones: Process automation will begin focusing on optimizing existing processes, rather than designing or architecting new ones. Companies should focus on auditing processes, services, and data to run faster and leaner. Transitioning to reusable components and connectors/plugin architectures allows for fast implementations and integrations. One size doesn’t fit all. Any out-of-the-box solutions need to be flexible with availability- for example, APIs, SDKs, and other programmatic implementations. – Amara Graham, Head of Developer Experience, [Camunda](https://camunda.com/)  

2023年，更多的组织将依赖现有流程，而不是构建新流程：流程自动化将开始专注于优化现有流程，而不是设计或架构新流程。公司应该专注于审计流程、服务和数据，以使其运行得更快、更精简。过渡到可重用组件和连接器/插件架构允许快速实现和集成。一个尺码不适合所有人。任何开箱即用的解决方案都需要具有灵活的可用性-例如，API、SDK和其他编程实现。- 阿马拉Graham，Camunda开发者体验负责人

The future is long-term workforce shortages across industries, not a recovery – organizations will need to understand how to combat workforce shortages using automation for redundant tasks. With one in five Americans being 65 or older by 2030, and a workforce shortage caused by COVID as well as the Great Resignation, organizations need to prepare now for a continued, long-term effect on the workforce. This year organizations already adjusted their workforce models to support these shortages, but next year we will begin to see more implementation of digital automation. With the growth in digital channels, organizations will have to deal with many more customer interactions without growing their headcount. This is where AI can help. Instead of being viewed as the enemy that is replacing an employee, automation will help deal with this extra workload by centralizing and streamlining simple tasks in a self-service mode. Organizations can also use automation to surface relevant insights and guidance in real-time to help employees handle tasks and support customers more efficiently and effectively. – Brett Weigl, SVP & GM, Digital and AI, Genesys  

未来是各行业的长期劳动力短缺，而不是复苏-组织将需要了解如何使用自动化来应对冗余任务的劳动力短缺。到2030年，五分之一的美国人年龄在65岁或以上，加上新冠病毒病和大辞职导致的劳动力短缺，企业现在需要做好准备，以应对对劳动力的持续长期影响。今年，企业已经调整了他们的劳动力模型，以支持这些短缺，但明年我们将开始看到更多数字自动化的实施。随着数字渠道的增长，企业将不得不在不增加员工人数的情况下处理更多的客户互动。这就是AI可以提供帮助的地方。自动化不会被视为取代员工的敌人，而是通过在自助服务模式中集中和简化简单任务，帮助处理这些额外的工作量。 组织还可以使用自动化来实时提供相关见解和指导，以帮助员工更高效地处理任务并为客户提供支持。 - Brett Weigl，Genesys数字和人工智能高级副总裁兼总经理

The last of the data-generating or data-consuming companies that haven’t already adopted AI will do so next year. In an era where data is growing so fast, a business will become obsolete if it does not have tools to automate repetitive decisions, process internal data, and/or take advantage of external data. At the end of the day, the role of automation is not only to accelerate existing processes, but to enable the maximum potential of human productivity. In 2023, when a turbulent economic climate will continue to force enterprises to reduce their workforces, intelligent automation will mitigate the onus on remaining talent, transforming operations and creating more engaged employees. Moreover, companies will see incredible value on the customer side, with intelligent automation enabling heightened demand predictive capabilities and more efficient data pipelines. The key to adopting this critical technology is to ensure all users understand how the automated decisions are being made, creating trust in the system and optimizing implementation. – Farshad Kheiri, Head of AI and Data Science at [Legion Technologies](http://legion.co/)  

最后一家尚未采用人工智能的数据生成或数据消费公司将于明年采用人工智能。在一个数据增长如此之快的时代，如果企业没有工具来自动化重复决策、处理内部数据和/或利用外部数据，它将变得过时。最终，自动化的作用不仅是加速现有流程，而且是最大限度地发挥人类生产力的潜力。在2023年，动荡的经济环境将继续迫使企业减少劳动力，智能自动化将减轻剩余人才的负担，转变运营并创造更多敬业的员工。此外，企业将在客户端看到难以置信的价值，智能自动化实现了更高的需求预测能力和更高效的数据管道。 采用这项关键技术的关键是确保所有用户都了解如何做出自动化决策，从而在系统中建立信任并优化实施。 - Farshad Kheiri，Legion Technologies人工智能和数据科学主管

Very similar to what we saw at the start of the pandemic, the 2023 recession environment will force organizations to figure out how to scale through technology like automation and AIOps and not through headcount. As companies implement hiring freezes and are forced to work with flat budgets, in addition to cutting staff, companies must identify ways to support existing employees and create a less stressful work environment for their IT, SRE and DevOps teams to avoid employee burnout. Effective, automated solutions that address these challenges will become a must-have. – Mohan Kompella at BigPanda  

与我们在疫情开始时看到的情况非常相似，2023年的经济衰退环境将迫使组织找出如何通过自动化和AIOps等技术来扩展，而不是通过员工数量。随着公司实施招聘冻结并被迫以固定预算工作，除了裁员外，公司还必须找到支持现有员工的方法，并为IT、SRE和DevOps团队创造一个压力较小的工作环境，以避免员工倦怠。解决这些挑战的有效、自动化的解决方案将成为必不可少的。- Mohan Kompella在BigPanda

Automation rewriting automation: [47% of developers](https://www.nuxeo.com/blog/low-code-essential/) don’t have access to the tools they need to build applications fast enough to meet deadlines. We can expect the next wave of automation to automate its _own_ development to fill this gap. Code will be written by AI engines, intelligently generating its own code. We’ll see more maturity, more time saved (cutting down development time by 90%), fewer errors and faster development. – Prasad Ramakrishnan, CIO, [Freshworks](https://www.freshworks.com/)  

自动化重写自动化：47%的开发人员无法获得所需的工具，以足够快的速度构建应用程序以满足最后期限。我们可以期待下一波自动化浪潮将自动化自己的开发来填补这一空白。代码将由AI引擎编写，智能地生成自己的代码。我们将看到更成熟、更节省的时间（将开发时间缩短90%）、更少的错误和更快的开发。- Prasad Ramakrishnan，Freshworks首席信息官

Automation’s Silent Revolution Becomes Loud and Mainstream: Automation has been a “silent revolution,” with companies slowly increasing adoption over time. Amidst the global economic downturn, adoption of automation will be fast tracked as companies look to cut costs while boosting productivity and collaboration. In 2023, automation will burst on to the scene as a key solution for businesses to scale and expand without breaking the bank. – Aytekin Tank, CEO, [Jotform](https://www.jotform.com/)  

自动化的无声革命成为主流：自动化一直是一场“无声的革命”，随着时间的推移，公司逐渐增加采用率。在全球经济低迷的情况下，自动化的采用将迅速发展，因为公司希望削减成本，同时提高生产力和协作。到2023年，自动化将作为企业在不破坏银行的情况下进行规模和扩张的关键解决方案突然出现。- Aytekin Tank，Jotform首席执行官

**Security 安全性**

Conversations about data security are expected and highlighted during Cybersecurity Awareness Month, but it’s critical that they continue every month, throughout every year, into the foreseeable future. Companies across every vertical are trying to become more data-driven and to democratize data within their organization, but that’s difficult to do securely if you have to constantly move data around to meet business objectives—moving data sets from your data lake into a data warehouse, then subsets into BI extracts, creating cubes and lots of copies. Companies lose visibility into who’s accessing which datasets. Worse still, since access controls don’t necessarily travel with data copies, it’s likely that those aren’t being adequately protected over time, which exposes data and creates risk. It’s imperative for enterprises to shift gears and implement an open and secure data architecture, where data is its own tier. With a lakehouse, companies no longer need to copy and move data from object storage into data warehouses to analyze it. Lakehouses bring engines directly to the data—and allow processing and analysis against a single source of truth. This gives data teams full visibility into who’s accessing what data in their lake, so they don’t have to worry about rogue copies of data that could threaten corporate security and governance rules. In turn, companies can take advantage of all the technical innovation that’s happening with data lakehouses and offer their business units genuine self-service with data. – Tomer Shiran, Co-Founder and CPO, [Dremio](https://www.dremio.com/)网络安全意识月期间预计会有关于数据安全的对话，但至关重要的是，这些对话必须在可预见的未来每个月、每年都继续进行。各个垂直领域的公司都在试图变得更加数据驱动，并在其组织内实现数据民主化，但如果你必须不断地移动数据以满足业务目标，这就很难做到安全-将数据集从数据湖移动到数据仓库，然后将子集移动到BI提取中，创建多维数据集和大量副本。公司无法了解谁在访问哪些数据集。更糟糕的是，由于访问控制不一定与数据副本一起传播，很可能随着时间的推移，这些副本没有得到充分的保护，这会暴露数据并产生风险。企业必须转变方向，实施开放和安全的数据架构，其中数据是自己的层。 有了lakehouse，公司不再需要将数据从对象存储复制和移动到数据仓库中进行分析。Lakehouses将引擎直接带到数据中，并允许针对单一的真实来源进行处理和分析。这使数据团队可以完全了解谁正在访问他们的湖中的数据，因此他们不必担心可能威胁公司安全和治理规则的数据恶意副本。反过来，公司可以利用数据湖边发生的所有技术创新，为他们的业务部门提供真正的数据自助服务。 - Tomer Shiran，Dremio联合创始人兼首席执行官    

Data Security Strategies: As rising international tensions lead to more frequent cyberattacks and more laws take effect that impose harsh penalties for mishandling data, executives in charge of data will begin to interrogate the assumptions on which they’ve built data security strategies. This will include creating a comprehensive inventory of the data they have on hand, questioning whether the data they store is necessary to accomplish their goals, and raising awareness of data security best practices throughout the organization. – Stephen Cavey, co-founder and Chief Evangelist of [Ground Labs](https://www.groundlabs.com/)  

数据安全策略：随着国际紧张局势的加剧，网络攻击越来越频繁，越来越多的法律生效，对不当处理数据施加严厉惩罚，负责数据的高管将开始质疑他们建立数据安全战略的假设。这将包括创建一个全面的现有数据清单，质疑他们存储的数据是否是实现目标所必需的，以及提高整个组织对数据安全最佳实践的认识。- Stephen Cavey，Ground Labs联合创始人兼首席布道者

Weaponizing deepfakes: in October 2022, a [deepfake of U.S. President Joe Biden](https://apnews.com/article/fact-check-biden-baby-shark-deepfake-412016518873) singing ‘Baby Shark’ instead of the national anthem was circulated widely.  Was this a joke, or an attempt to influence the important U.S. mid-term elections?  Deepfakes technology will be increasingly used to target and manipulate opinions, or to trick employees into giving up access credentials. Deepfakes will go mainstream with hacktivists and cybercriminals leveraging video and voicemails for successful phishing and ransomware attacks. – Mark Ostrowski, Office of the CTO, [Check Point Software](https://www.checkpoint.com/)  

将deepfakes武器化：2022年10月，一份Deepfake的美国。美国总统乔·拜登（Joe Biden）演唱的《鲨鱼宝宝》（Baby Shark）而不是国歌的歌曲广为流传。这是一个玩笑，还是企图影响美国重要的。中期选举？Deepfakes技术将越来越多地被用于定位和操纵意见，或者欺骗员工放弃访问凭证。Deepfakes将成为主流，黑客活动家和网络犯罪分子利用视频和语音邮件成功进行网络钓鱼和勒索软件攻击。- Mark Ostrowski，Check Point Software首席技术官办公室

Most organizations will continue to tackle data security with a patchwork of technology that covers only small portions of their data estate, leaving the majority of data unmonitored and unprotected. While regulations will continue to expound on the need for specific types of data monitoring and fundamental protection for that type of data, further exacerbating the siloed or targeting security practices_._ – Terry Ray, SVP Data Security, [Imperva](https://www.imperva.com/)  

大多数组织将继续通过拼凑的技术来解决数据安全问题，这些技术仅覆盖其数据资产的一小部分，使大多数数据不受监控和保护。虽然法规将继续阐述对特定类型的数据进行监测和对这类数据的基本保护的必要性，这进一步加剧了孤立或针对安全做法的情况。- Terry Ray，Imperva数据安全高级副总裁

Deep Fakes Replicate Digital Humans – The Digital DNA Theft: In 2023, Deep Fakes will become so authentic that not only will we see our digital identities being stolen, but also digital versions of our DNA. Exposing our Digital DNA on the internet will enable Deep Fakes to replicate and create Digital Humans. If you have ever seen the movie “The 6<sup data-immersive-translate-effect="1" data-immersive_translate_walked="faeae5c3-1b04-4703-b7e3-d453339acb05">th</sup> Day,” we are on the same path for replicas of our digital selves. Humans sync our physical lives on social media with constant uploads of photos, videos, audio and personal preferences with enough data points and some enhanced algorithms. It is only a matter of time before attackers can create lifelike digital avatars of anyone, and it will be incredibly difficult to identify the difference without technology to analyze the source data. – Joseph Carson, Chief Security Scientist and Advisory CISO at [Delinea](https://delinea.com/)  

深度伪造复制数字人类-数字DNA盗窃：到2023年，Deep Fakes将变得如此真实，我们不仅会看到我们的数字身份被窃取，还会看到我们的DNA的数字版本。在互联网上暴露我们的数字DNA将使Deep Fakes能够复制和创造数字人类。如果你看过电影人类通过不断上传照片、视频、音频和个人偏好，并通过足够的数据点和一些增强的算法，在社交媒体上同步我们的物理生活。攻击者可以创建任何人的栩栩如生的数字化身只是时间问题，如果没有技术来分析源数据，识别差异将是难以置信的困难。- Joseph卡森，Delinea首席安全科学家兼顾问CISO

Using AI and machine learning to combat ransomware attacks can help strengthen a company: Ransomware, phishing attacks, and data breaches have become all too familiar among organizations, and while these attacks are not new concerns, it has and will consistently take its toll on industries. What’s more, bad actors show no sign of stopping. To combat these ongoing and evolving attacks, AI and machine learning will be beneficial and organizations look towards these tools as we approach another hyperactive cyberthreat landscape in 2023. When implemented, AI can protect individual projects and core ecosystem services, while identifying deployed open-source programs and applying an automated security analysis. – Rick Vanover, Senior Director Product Strategy at Veeam  

使用AI和机器学习来打击勒索软件攻击可以帮助增强公司：勒索软件、网络钓鱼攻击和数据泄露在组织中已经变得非常熟悉，虽然这些攻击不是新问题，但它已经并将持续对行业造成影响。更重要的是，坏演员没有停止的迹象。为了对抗这些持续不断的攻击，人工智能和机器学习将是有益的，随着我们在2023年接近另一个超活跃的网络威胁格局，组织将寻求这些工具。在实施时，AI可以保护单个项目和核心生态系统服务，同时识别已部署的开源程序并应用自动化安全分析。- Rick Vanover，Veeam产品战略高级总监

Investing in AI to combat fraudulent and synthetic identities: In 2023, fraudsters will devise new ways to hack into accounts, including new ways to spoof biometrics, new ways to create fraudulent identity documents, and new ways to create synthetic identities. Organizations will need to invest in artificial intelligence (AI) and machine learning (ML) anti-fraud technology to counter new attack vectors and effectively fight fraud as hacker methods evolve. – Ricardo Amper, CEO and founder of [Incode](https://incode.com/)投资人工智能以打击欺诈和合成身份：到2023年，欺诈者将设计新的方法来入侵账户，包括伪造生物识别技术的新方法、创建欺诈身份文件的新方法以及创建合成身份的新方法。组织将需要投资于人工智能（AI）和机器学习（ML）反欺诈技术，以应对新的攻击载体，并随着黑客方法的发展有效地打击欺诈。- - Ricardo Amper，Incode首席执行官兼创始人   

AI will completely transform security, risk and fraud: We’re seeing AI and powerful data capabilities redefine the security models and capabilities for companies. Security practitioners and the industry as a whole will have much better tools and much faster information at their disposal, and they should be able to isolate security risks with much greater precision. They’ll also be using more marketing-like techniques to understand anomalous behavior and bad actions. In due time, we may very well see parties using AI to infiltrate systems, attempt to take over software assets through ransomware and take advantage of the cryptocurrency markets. – Ashok Srivastava, Senior Vice President & Chief Data Officer at Intuit  

AI将彻底改变安全、风险和欺诈：我们看到人工智能和强大的数据功能重新定义了企业的安全模型和能力。安全从业人员和整个行业将拥有更好的工具和更快的信息，他们应该能够更精确地隔离安全风险。他们还将使用更多类似营销的技术来了解异常行为和不良行为。在适当的时候，我们很可能会看到各方使用人工智能渗透系统，试图通过勒索软件接管软件资产，并利用加密货币市场。- Ashok Srivastava，Intuit高级副总裁兼首席数据官

CISOs Tackle Security in The Data Lake: Now that companies recognize the value of data, they are keeping all of it, just in case, and their preferred storage is the data lake. With various analysts and data scientists accessing the data lake for so many purposes, it is harder than ever to configure permissions. Who can take what action on data in the lake?  The folks in IT who receive requests for access feel pressure to respond. After hundreds of requests, it’s hard to not start clicking “allow.” The inevitable result is that companies will collect “access debt.” In 2023, CISOs will start looking for ways to monitor and trim the access debt. – Tarun Thakur, Co-Founder & CEO of [Veza](https://www.veza.com/)  

CISO解决数据湖中的安全问题：现在，公司认识到了数据的价值，他们保留了所有数据，以防万一，他们首选的存储是数据湖。随着各种分析师和数据科学家出于多种目的访问数据湖，配置权限比以往任何时候都困难。谁能对湖里的数据采取什么行动？收到访问请求的IT人员会感到响应的压力。在数百次请求之后，很难不开始点击“允许”必然的结果是，企业将收取“准入债”到2023年，CISO将开始寻找监控和削减接入债务的方法。- Tarun Thakur，Veza联合创始人兼首席执行官

APIs Are Data Pipelines That Will Attract More Attackers: While traditional databases allow users to find, store and maintain data, application programming interfaces (APIs) enable users to access and review the data as it transfers between the company, customers, and third parties. Software code has come under attack in innovative and deeply troubling ways as APIs have become the critical pipeline in modern organizations, and because of this, we can expect to continue to see API hacking as a major threat vector when it comes to critical data. Whether it be through a mobile application or website, APIs interact with business logic and allow adversaries to understand exactly how a company is processing information and data, making APIs a major area of vulnerability for organizations. We expect 2023 to be the year that the risk becomes so apparent that companies can no longer ignore it. – Dor Dankner, Head of Research at [Noname Security](https://nonamesecurity.com/)  

API是将吸引更多攻击者的数据管道：传统数据库允许用户查找、存储和维护数据，而应用程序编程接口（API）允许用户在公司、客户和第三方之间传输数据时访问和查看数据。随着API已成为现代组织中的关键管道，软件代码受到了创新和令人深感不安的攻击，正因为如此，当涉及到关键数据时，我们可以预期API黑客将继续视为主要威胁载体。无论是通过移动的应用程序还是网站，API都与业务逻辑交互，并允许对手准确了解公司如何处理信息和数据，使API成为组织的主要漏洞领域。我们预计，2023年将是风险变得如此明显的一年，企业无法再忽视它。- Dor Dankner，Noname Security研究主管

“Generative AI” will become a buzzword in the cyber security space: “Generative AI” will transform the AI use cases from “classification, translation, recommendation” to “creation”. In the cybersecurity world, this means threats are even more personalized and more deceiving, but at the same time it means we will have more creative tools to help us to combat the bad guys. – Howie Xu, Vice President of ML/AI at [Zscaler](http://www.zscaler.com/).   

“生成式AI”将成为网络安全领域的流行语：“生成式AI”将AI用例从“分类、翻译、推荐”转变为“创造”。在网络安全领域，这意味着威胁更加个性化，更具欺骗性，但同时这意味着我们将拥有更多创造性的工具来帮助我们打击坏人。- Howie Xu，Zscaler ML/AI副总裁。

Data context-driven automation will emerge as a priority for organizations looking to mature basic AIOps into more precise AISecOps: Organizations will increasingly realize that to be effective, the platforms they use to automate software delivery pipelines and support AIOps need to be data context-driven. That means they need the ability to unify data in a single source of truth, where it can be transformed into precise answers and intelligent automation. This will be key to ensuring the AI that powers automation can distinguish between cause and effect to make more intelligent and timely decisions. However, organizations are struggling to maintain this context as the growing complexity of dynamic cloud architectures and increasingly distributed digital journeys has led to an explosion of data and disparate analytics tools. In the coming year, organizations will seek to address this by shifting their focus from consolidating tools to drive efficient AIOps, to embracing platforms that support more advanced AISecOps. This will enable them to break down the silos between observability, business, and security data and bring it together with topology and dependency mapping. As a result, they will be able to retain the relationship between data streams and unlock the full context needed to drive more powerful and precise automation, so they can deliver seamless digital experiences. – [Dynatrace](https://www.dynatrace.com/) founder and chief technology officer Bernd Greifender  

数据上下文驱动的自动化将成为希望将基本AIOps成熟为更精确的AISecOps的组织的优先事项：组织将越来越多地意识到，为了提高效率，他们用于自动化软件交付管道和支持AIOps的平台需要是数据上下文驱动的。这意味着他们需要能够将数据统一到单一的真相来源中，并将其转化为精确的答案和智能自动化。这将是确保为自动化提供动力的人工智能能够区分因果关系以做出更智能和及时决策的关键。然而，随着动态云架构的日益复杂性和日益分布式的数字旅程，企业正在努力维护这种环境，导致数据和不同分析工具的爆炸式增长。 在未来的一年里，组织将通过将重点从整合工具以推动高效AIOps转移到支持更高级AISecOps的平台来解决这一问题。这将使他们能够打破可观察性、业务和安全数据之间的孤岛，并将其与拓扑和依赖关系映射结合在一起。因此，他们将能够保留数据流之间的关系，并解锁驱动更强大和更精确的自动化所需的完整上下文，从而提供无缝的数字体验。 - Dynatrace创始人兼首席技术官Bernd Greifender

IAM Teams Look to Adopt AI and Machine Learning but Only for Specific Instances: As more enterprises adopt an identity-first approach to their security strategy, they are challenged with how to manage the increasing number of entitlements and permissions connected to  applications that live in a variety of environments (on-premises, private cloud, public cloud, etc.) and create a lot of  data about events, logs, users and more. In addition, the explosion of demand for cloud infrastructure and entitlement management (CIEM) solutions has resulted in creating more predictable models about users, entitlements and provisions. As a result, in 2023 enterprises  mature in their implementation of these areas will consider leveraging artificial intelligence or machine learning to further scale these strategies. However, AI and ML adoption by IAM teams will likely remain constrained to those targeted areas as enterprises continue to mature their IAM strategies. – [Axiomatics](http://www.axiomatics.com/)’ Chief Product Officer, Mark Cassetta  

IAM团队希望采用AI和机器学习，但仅限于特定实例：随着越来越多的企业在其安全策略中采用身份优先的方法，他们面临着如何管理与各种环境（本地、私有云、公共云等）中的应用程序相连的日益增多的授权和权限的挑战。并创建大量关于事件、日志、用户等的数据。此外，对云基础设施和授权管理（CIEM）解决方案需求的爆炸式增长导致了关于用户、授权和供应的更可预测的模型。因此，到2023年，在这些领域实施成熟的企业将考虑利用人工智能或机器学习来进一步扩展这些战略。然而，随着企业不断成熟其IAM战略，IAM团队采用AI和ML可能仍将局限于这些目标领域。 Axiomatics首席产品官Mark Cassetta

It’s never too late for policy to evolve; in 2023, it finally might: As biometric and AI-driven healthcare technologies become more pervasive, we will need a federal policy that governs how personal data is collected, managed, and used. It’s unsettling that mobile app creators can collect health-related data that does not have federal data protection. The current administration has announced new guidelines, though many of these policy updates are incremental steps that don’t go far enough in protecting data. The policy must evolve at the same rate technology, and cyber threats do. With that in mind, any CISO will tell you it’s never too late to mature the current approaches since the next threat or attack is around the corner. – Chris Bowen, Founder and CISO at ClearDATA  

政策的发展永远不会太晚;到2023年，它终于可以：随着生物识别和人工智能驱动的医疗保健技术变得越来越普遍，我们将需要一个联邦政策来管理个人数据的收集、管理和使用方式。令人不安的是，移动的应用程序创建者可以收集没有联邦数据保护的健康相关数据。现任政府已经宣布了新的指导方针，尽管这些政策更新中的许多是渐进的步骤，在保护数据方面做得不够。该政策必须以技术和网络威胁相同的速度发展。考虑到这一点，任何CISO都会告诉你，现在成熟当前的方法永远不会太晚，因为下一个威胁或攻击就在眼前。- Chris Bowen，ClearDATA创始人兼首席信息官

Artificial Intelligence Will Continue to Play a Prominent in Detecting Data Breaches: In 2023, more workers will still telework and utilize individual gadgets to connect to work networks remotely. Connecting to networks with non-secured remote or cloud-based devices may unwittingly fall prey to more phishing attacks and hacking of credentials. Improved artificial intelligence (AI) algorithms can identify and reduce systems vulnerabilities with weak security in 2023. Companies that use AI and automation to detect and respond to data breaches have better safeguards. Security vendors can effectively examine the vast amount of data moving across networks in real time with the most recent and sophisticated algorithms. – Philip Chan, PhD, Adjunct Professor, School of Cybersecurity & Information Technology, University of Maryland  

人工智能将继续在检测数据泄露方面发挥突出作用：到2023年，更多的工作者仍将远程工作，并利用个人设备远程连接到工作网络。使用不安全的远程或基于云的设备连接到网络可能会无意中成为更多网络钓鱼攻击和凭据黑客攻击的牺牲品。改进的人工智能（AI）算法可以在2023年识别和减少安全性较弱的系统漏洞。使用人工智能和自动化来检测和响应数据泄露的公司拥有更好的保护措施。安全供应商可以使用最新和最复杂的算法真实的有效地检查在网络中移动的大量数据。- Philip Chan，博士，马里兰州大学网络安全与信息技术学院兼职教授

Both Structured and Unstructured Data Are at Risk for Theft: In 2022, structured data was more at risk than unstructured data for malicious exfiltration. Attackers targeted structured data used in databases such as Oracle and Microsoft® Azure SQL Server (68%) and for analytics in web platforms such as Databricks (63%). However, attackers also searched for unstructured data used in applications (57%) such as Amazon S3, Microsoft® Azure Blob and created by users (50%) in tools such as Microsoft OneDrive, Microsoft SharePoint, and others. Moving into 2023, attackers will target structured data used for analytics (68%) over that used in databases (62%). They’ll also target unstructured data created by users (58%) over that created by applications (54%) or other sources (16%). Analytics and user data reveal corporate intent, providing a lens into strategies, plans, product launches, partnerships, and other information of interest to attackers, such as nation-states, cybercriminals and more. – [Titaniam](https://titaniam.io/), Inc.  

结构化和非结构化数据都有被盗风险：2022年，结构化数据比非结构化数据更容易被恶意泄露。攻击者的目标是Oracle和Microsoft® Azure SQL Server等数据库中使用的结构化数据（68%），以及Databricks等Web平台中用于分析的结构化数据（63%）。然而，攻击者还搜索了Amazon S3、Microsoft® Azure Blob等应用程序中使用的非结构化数据（57%），以及由用户（50%）在Microsoft OneDrive、Microsoft SharePoint等工具中创建的数据。进入2023年，攻击者将针对用于分析的结构化数据（68%），而不是用于数据库的结构化数据（62%）。他们还将针对用户（58%）创建的非结构化数据，而不是应用程序（54%）或其他来源（16%）创建的非结构化数据。分析和用户数据揭示了企业意图，提供了战略、计划、产品发布、合作伙伴关系以及攻击者感兴趣的其他信息的透镜，如民族国家、网络犯罪分子等。 - Titaniam公司

Security will dominate Big data IT buying criteria, including for data storage: Supply chain issues and economic challenges will continue to impact storage projects in 2023 — the exception being those that can show tangible ROI on ransomware protection initiatives. This will present an opportunity for big data storage solutions with the intelligence to address current gaps in multi-level security, detection and data immutability for ransomware protection and fast business recoverability. Moreover, solutions that can provide AI-based anomaly-detection capabilities for detecting ransomware attacks will become more mainstream in the near future. – Giorgio Regni, CTO, [Scality](http://www.scality.com/)  

安全性将主导大数据IT购买标准，包括数据存储：2023年，供应链问题和经济挑战将继续影响存储项目，但那些能够在勒索软件保护计划上显示出切实的投资回报率的项目除外。这将为大数据存储解决方案提供一个机会，该解决方案具有智能，以解决当前在多级安全性、检测和数据不变性方面的差距，以实现勒索软件保护和快速业务恢复。此外，能够提供基于AI的异常检测能力以检测勒索软件攻击的解决方案在不久的将来将成为主流。- Giorgio Regni，Scality首席技术官

**Storage 储存**

Organizations will be forced to look for new approaches to manage unstructured data growth in 2023. Many have already noticed that the pace of unstructured data growth is snowballing exponentially faster than it has in the past. This leads to increased costs, as companies have to buy more storage, and the introduction of risk, as the organization has less knowledge about the data as it ages in its network. Organizations need new solutions to minimize the financial impact and risk their business faces. Furthermore, much of this unstructured data is stored in network-attached storage (NAS). This is because many applications haven’t yet been redeveloped to leverage object storage. So, much of an organization’s unstructured data will continue to be stored on-premises in 2023. Because of this, public cloud providers will form more relationships with traditional on-premises NAS vendors. They will offer branded, cloud-based, managed file services. These services will benefit customers because they have a simple “on-ramp,” they preserve pre-existing documentation and processes, and they take care of the underlying hardware and operating environment for the customer. – Carl D’Halluin, CTO, [Datadobi](http://www.datadobi.com/)   

到2023年，企业将被迫寻找新的方法来管理非结构化数据的增长。许多人已经注意到，非结构化数据的增长速度正以比过去呈指数级的速度滚雪球式增长。这导致成本增加，因为公司不得不购买更多存储，并引入风险，因为组织对数据的了解越来越少，因为数据在其网络中老化。组织需要新的解决方案来最大限度地减少其业务面临的财务影响和风险。此外，大部分非结构化数据存储在网络附加存储（NAS）中。这是因为许多应用程序尚未重新开发以利用对象存储。因此，到2023年，组织的大部分非结构化数据将继续存储在本地。正因为如此，公共云提供商将与传统的本地NAS供应商建立更多的关系。他们将提供品牌化、基于云的托管文件服务。 这些服务将使客户受益，因为它们有一个简单的“入口”，它们保留了预先存在的文档和流程，并且它们照顾客户的底层硬件和操作环境。 - Carl D 'Halluin，Datadobi首席技术官

**Synthetic Data**

Ramping up Innovation While Scaling Back Costs: How Synthetic Data Drives Efficiency in AI Development: Many organizations feel the pressure to innovate, despite paring budgets and staff. During this uncertain time, it’s important to remember that scaling back does not have to stifle innovation. Organizations will need to continue investing in the tools and technology required to advance their processes, products and services––but in a much smarter and more efficient way. Over the past decade-plus, data has become a major source of competitive differentiation for businesses. As the anticipated economic fallout threatens organizations’ health, data will again play a critical role. Synthetic data will play an essential role in carrying forth this vision, as it’s 100x cheaper and faster than using real-world data. The added advantage of cost savings will enable organizations to integrate and iterate in a much faster way. Companies that master the balancing act of scaling efficiently will ultimately reap the reward of maintaining innovation during the anticipated economic downturn. – Yashar Behzadi, CEO and Founder of [Synthesis AI](https://synthesis.ai/)  

在削减成本的同时加大创新力度：合成数据如何提高人工智能开发效率：许多组织感到创新的压力，尽管削减了预算和人员。在这个不确定的时期，重要的是要记住，缩减规模并不一定会扼杀创新。组织将需要继续投资于推进其流程、产品和服务所需的工具和技术，但要以更智能、更高效的方式进行投资。在过去的十多年里，数据已经成为企业竞争差异化的主要来源。随着预期的经济后果威胁到组织的健康，数据将再次发挥关键作用。合成数据将在实现这一愿景方面发挥重要作用，因为它比使用真实世界数据便宜100倍，速度更快。节省成本的额外优势将使组织能够以更快的方式集成和迭代。 掌握了有效扩张这一平衡行为的公司最终将获得在预期的经济衰退期间保持创新的回报。 - Yashar Behzadi，Synthesis AI首席执行官兼创始人

Derivative and synthetic data are on the rise: If the last few years have taught us anything, it’s the value of investing time and resources into preparing for the unexpected, or dare I say it, unprecedented. Good data, analytics, automation and AI all enable us to react quickly, or ideally “pre-act” to forecast issues before they even start. It’s an approach that has been proven time and time again to work with issues we have a wealth of real data to model our potential futures on, like consumer demand to predict stock levels and reduce wastage. But unfortunately, as COVID-19 showed, there are still plenty of unprecedented events that the average operation doesn’t have easy access to enough real data to react to, let alone predict. These increasingly apparent gaps are why the use of derivative and synthetic data will be a key trend in 2023. In fact, the use of synthetic data [looks to completely overshadow real data in AI models by 2030.](https://www.gartner.com/en/newsroom/press-releases/2022-06-22-is-synthetic-data-the-future-of-ai) Data that is artificially created enables organizations to model innovatively for things that have never happened before, while jumping over some of the privacy, copyright and ethical hurdles associated with real data. And for anyone questioning its validity, [research suggests that models trained on synthetic data can be more accurate than others](https://news.mit.edu/2022/synthetic-data-ai-improvements-1103). Whilst derivative data allows us to repurpose data for multiple needs. It enables the crucial scenario-planning needed to prepare for future issues and crises, holding great potential for highly regulated industries like healthcare and financial services. – Dan Sommer, former Gartner analyst and Qlik’s Global Market Intelligence Lead  

衍生和合成数据呈上升趋势：如果说过去几年教会了我们什么的话，那就是投入时间和资源来为意想不到的事情做准备的价值，或者说是前所未有的事情。良好的数据、分析、自动化和人工智能都使我们能够快速反应，或者在问题开始之前就“预先行动”进行预测。这种方法已经被一次又一次地证明，可以解决我们有大量真实的数据来模拟未来的问题，比如消费者需求来预测库存水平和减少浪费。但不幸的是，正如COVID-19所显示的那样，仍然有大量前所未有的事件，一般的操作人员无法轻松获得足够的真实的数据来做出反应，更不用说预测了。这些日益明显的差距就是为什么衍生和合成数据的使用将成为2023年的一个关键趋势。事实上，到2030年，人工智能模型中合成数据的使用将完全掩盖真实的数据。 人工创建的数据使组织能够为以前从未发生过的事情进行创新建模，同时跳过与真实的数据相关的一些隐私、版权和道德障碍。对于任何质疑其有效性的人来说，研究表明，在合成数据上训练的模型可能比其他模型更准确。而衍生数据允许我们重新利用数据以满足多种需求。它能够为未来的问题和危机做好准备所需的关键场景规划，为医疗保健和金融服务等高度监管的行业提供巨大潜力。 - Dan Sommer，前Gartner分析师和Qlik全球市场情报主管

The latest innovations in AI will be used to synthesize new content from existing content. One example of this is to ingest documents or images and to produce a summary with key points to aid in comprehension. This is a time-saving innovation that will be a main focus on AI in the ECM space in 2023. Eventually, actionable highlights will be provided, which combines comprehension with judgment that may consider datasets and other factors outside of the document but put in the context of the material being analyzed. – Michael Allen, CTO at [Laserfiche](https://www.laserfiche.com/)  

AI的最新创新将用于从现有内容合成新内容。其中一个例子是摄取文档或图像，并生成具有关键点的摘要，以帮助理解。这是一项节省时间的创新，将成为2023年ECM领域AI的主要焦点。最终，将提供可操作的亮点，其将理解与判断结合起来，可以考虑文档之外的数据集和其他因素，但放在被分析的材料的上下文中。- Michael艾伦，Laserfiche首席技术官

Synthetic Data: The Key to Addressing Generative AI Ethical Concerns: Generative AI has dominated headlines, and the hype surrounding the technology continues to grow. Data remains the most critical aspect in building generative AI systems, but using real-world data poses ethical and privacy concerns, including human data to train ID verification models. Development teams will increasingly use synthetic data when creating generative AI models, as it’s artificial data created in simulated worlds and thus eliminates many biases and privacy concerns associated with datasets collected from the real world. AI adoption is steadily rising, with over [55% of organizations indicating AI as a core function](https://www.mckinsey.com/capabilities/quantumblack/our-insights/global-survey-the-state-of-ai-in-2021) in 2021, up from 50% in 2020. As innovation only continues to increase in the space, it will be imperative for organizations to invest in the tools and technologies that help mitigate bias imbalances and ensure generative AI models are built in a more ethical and privacy-compliant way. – Yashar Behzadi, CEO and Founder of [Synthesis AI](https://synthesis.ai/)  

合成数据：解决人工智能伦理问题的关键：生成式人工智能占据了头条新闻，围绕该技术的炒作继续增长。数据仍然是构建生成人工智能系统的最关键方面，但使用真实世界的数据会带来道德和隐私问题，包括训练身份验证模型的人类数据。开发团队在创建生成AI模型时将越来越多地使用合成数据，因为它是在模拟世界中创建的人工数据，从而消除了与从真实的世界收集的数据集相关的许多偏见和隐私问题。人工智能的采用率正在稳步上升，超过55%的组织表示，到2021年，人工智能是核心功能，高于2020年的50%。由于创新只会在该领域继续增加，组织必须投资于有助于缓解偏见失衡的工具和技术，并确保生成性人工智能模型以更加道德和隐私合规的方式构建。 - Yashar Behzadi，Synthesis AI首席执行官兼创始人

**Verticals 垂直**

AI will yield tremendous breakthroughs in treating medical conditions in the next few years. Just look at the 2021 Breakthrough Prize winner Dr. David Baker. Dr. Baker used AI to design completely new proteins. This ground-breaking technology will continue having huge ramifications in the life sciences, potentially developing life-saving medical treatments for diseases like Alzheimer’s and Parkinson’s. – [Moogsoft](https://www.moogsoft.com/) co-founder and CEO, Phil Tee  

人工智能将在未来几年内在治疗医疗疾病方面取得巨大突破。只要看看2021年突破奖赢家Dr.大卫·贝克。贝克博士利用人工智能设计了全新的蛋白质。这项突破性的技术将继续在生命科学领域产生巨大的影响，有可能开发出治疗阿尔茨海默氏症和帕金森氏症等疾病的挽救生命的医疗方法。Moogsoft联合创始人兼首席执行官Phil Tee

Data has become a currency for many discoveries in today’s society and we will continue to see its value grow in the next year. The integration of data sources, especially when personal identifying information (PII) or protected health information (PHI) is involved, has a significant impact on the ability of AI to learn from diverse sets of data. The problem is even more complex in medical applications, where patient data are protected by HIPAA. In the next year, we can expect to see commercial organizations overcome this problem by using approaches that can link diverse data sets for the same individuals, owned and stored by different entities, through de-identified data. Tokenization is one such approach – it allows algorithm developers to gain access to diverse sets of data that are representative of the intended use population, which can then be used to develop and validate generalizable algorithms. Tokenization also creates an effective data search and exchange platform, where organizations can make available and find datasets of different modalities for the same patients, in a privacy-preserving manner. As real world data becomes a major source for AI application development and validation, tokenization will play an increasingly bigger role. – Evangelos Hytopoulos, sr. director of data science at [iRhythm](https://www.irhythmtech.com/)  

数据已经成为当今社会许多发现的货币，我们将继续看到它的价值在明年增长。数据源的整合，特别是当涉及个人身份信息（PII）或受保护的健康信息（PHI）时，对人工智能从不同数据集中学习的能力有着重大影响。在医疗应用中，问题甚至更加复杂，患者数据受HIPAA保护。在接下来的一年里，我们可以期待看到商业组织通过使用可以通过去识别数据链接相同个体的不同数据集的方法来克服这个问题。令牌化是一种这样的方法-它允许算法开发人员访问代表预期使用群体的不同数据集，然后可以使用这些数据集来开发和验证可泛化的算法。 令牌化还创建了一个有效的数据搜索和交换平台，在该平台中，组织可以以保护隐私的方式为相同患者提供并找到不同模式的数据集。随着真实的世界的数据成为人工智能应用开发和验证的主要来源，令牌化将发挥越来越大的作用。- Evangelos Hytopoulos，sr. iRhythm数据科学总监

Bridge the Talent Gap by Preserving Institutional Knowledge: As mature workers retire and fewer young people enter the field, insurers are searching for ways to obtain talent resilience. Leveraging AI will be a key strategic initiative, as insurers look to capture seasoned professionals’ institutional knowledge, then transfer it to less experienced employees. AI can effectively serve as a co-pilot for newer employees dramatically decreasing their training time. As AI becomes more widely adopted, underwriters and adjusters will be able to amplify their capabilities, allowing them to process more policies and claims at a higher level of effectiveness. New workflows will emerge that leverage the combined strengths of AI and talented professionals. – Stan Smith, CEO, and founder of [Gradient AI](https://www.gradientai.com/)  

通过保留机构知识弥合人才差距：随着成熟员工退休，进入该领域的年轻人越来越少，保险公司正在寻找获得人才韧性的方法。利用人工智能将是一项关键的战略举措，因为保险公司希望获取经验丰富的专业人士的机构知识，然后将其转移给经验不足的员工。人工智能可以有效地充当新员工的副驾驶员，大大减少他们的培训时间。随着人工智能越来越广泛地采用，承保人和理算人将能够扩大他们的能力，使他们能够以更高的效率处理更多的政策和索赔。新的工作流程将出现，利用人工智能和有才华的专业人士的综合优势。- Stan Smith，Gradient AI首席执行官兼创始人

Intelligent and Predictive data, and not just data, is the future: The current trend in the automotive industry involves gathering more data from many, disintegrated systems that doesn’t really solve the one major problem – quicker, accurate and pointed decision making. But the challenge with data being split into multiple variables from different sources is that it’s too complex to analyze and collate. Instead, what businesses actually need is ‘Intelligent and Deterministic Data’. A hybrid model focusing on edge as well as cloud computing that would highlight the aspects that actually matter, yielding ready-to-use data to take real-time decisions with maximum impact. –  [CerebrumX](http://cerebrumx.ai/) CEO Sandip Ranjhan  

智能和预测性数据，而不仅仅是数据，才是未来：汽车行业目前的趋势涉及从许多支离破碎的系统中收集更多的数据，这些系统并不能真正解决一个主要问题-更快、准确和有针对性的决策。但是，数据被分成来自不同来源的多个变量的挑战是，它太复杂了，无法进行分析和整理。相反，企业真正需要的是“智能和确定性数据”。专注于边缘计算和云计算的混合模型将突出实际重要的方面，产生现成的数据，以做出具有最大影响的实时决策。- CerebrumX首席执行官Sandip Ranjhan

AI is mature and omnipresent in the Office of Finance: We are utterly immersed in AI, and it is already impacting our lives in powerful and exciting ways. A recent [study](https://www.jedox.com/en/resources/analyst-barc-topical-survey/) by the Business Application Research Center (BARC) revealed that in the span of just two years, the percentage of organizations relying on predictive planning technology has increased elevenfold to 44%. According to Forbes, AI is responsible for filtering irrelevant and potentially dangerous messages from our inbox. It personalizes our social media feeds and helps Amazon curate our online shopping experience. It powers the recommendation and personalization algorithms that Netflix uses to produce and serve relevant and compelling content. It populates closed captions and subtitles in PowerPoint to make presentations more accessible. From a technical perspective, AI is stable, mature, and ready to support the office of finance. From a strategic perspective, it is helping CFOs provide the sophisticated insights that business leaders and investors are demanding. – Dr. Björn Schmidt, Chief Finance Officer at [Jedox](https://www.jedox.com/en/)  

AI在财务办公室已经成熟且无处不在：我们完全沉浸在人工智能中，它已经以强大而令人兴奋的方式影响着我们的生活。商业应用研究中心（BARC）最近的一项研究显示，在短短两年的时间里，依赖预测性规划技术的组织比例增加了11倍，达到44%。据福布斯报道，人工智能负责过滤我们收件箱中不相关和潜在危险的消息。它个性化我们的社交媒体订阅，并帮助亚马逊策划我们的在线购物体验。它支持Netflix用来制作和提供相关和引人注目的内容的推荐和个性化算法。它在PowerPoint中填充隐藏式字幕和字幕，使演示文稿更易于访问。从技术角度来看，AI已经稳定、成熟，已经准备好支撑金融的办公。 从战略角度来看，它正在帮助首席财务官提供商业领袖和投资者所需要的复杂见解。- 医生 Jedox首席财务官Björn施密特

_Sign up for the free insideBIGDATA [newsletter](http://inside-bigdata.com/newsletter/).  

订阅免费的insideBIGDATA新闻通讯。_

_Join us on Twitter: [https://twitter.com/InsideBigData1](https://twitter.com/InsideBigData1)  

加入我们的Twitter：https://twitter.com/InsideBigData1_

_Join us on LinkedIn: [https://www.linkedin.com/company/insidebigdata/](https://www.linkedin.com/company/insidebigdata/)  

加入我们的LinkedIn：https://www.linkedin.com/company/insidebigdata/_

_Join us on Facebook: [https://www.facebook.com/insideBIGDATANOW](https://www.facebook.com/insideBIGDATANOW)  

加入我们的Facebook：https://www.facebook.com/insideBIGDATANOW_
